import pandas as pd
import json
import os
import glob

def calculate_expected_inflow(score):
    """ì£¼ì–´ì§„ ëª¨ë¸ ì ìˆ˜ì— ëŒ€í•´ ê¸°ëŒ€ ê²€ìƒ‰ ìœ ì…ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if score is None:
        return 0.0
    # y = -77.04xÂ² + 13.61x + 0.07
    return (-77.04 * (score**2)) + (13.61 * score) + 0.07

def format_features_md(features_dict):
    """í”¼ì²˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ë¡œ ì˜ˆì˜ê²Œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not isinstance(features_dict, dict):
        return ""
    return "\n".join([f"    * `{key}`: **{value:.4f}**" for key, value in features_dict.items()])

def summarize_results_to_markdown(file_paths, prediction_csv_path):
    """
    ì—¬ëŸ¬ ê°œì˜ edit_history.json íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ê²°ê³¼ë¥¼ Markdown ë³´ê³ ì„œë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # Load prediction data and calculate initial ranks
    try:
        prediction_df = pd.read_csv(prediction_csv_path)
        prediction_df['post_id'] = prediction_df['post_id'].astype(str) # Joinì„ ìœ„í•´ strìœ¼ë¡œ ë³€í™˜
        prediction_df['initial_rank'] = prediction_df['predicted_ctr'].rank(method='dense', ascending=False).astype(int)
        prediction_df['initial_percentile_top'] = (prediction_df['initial_rank'] / len(prediction_df)) * 100
        total_posts = len(prediction_df)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ìˆœìœ„ ê³„ì‚°ì„ ìœ„í•œ ì˜ˆì¸¡ íŒŒì¼({prediction_csv_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    report_content = "# í¬ìŠ¤íŠ¸ ê°œì„  ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ\n\n"
    report_content += "AI í¸ì§‘ ì—ì´ì „íŠ¸ì— ì˜í•´ ìë™ ê°œì„ ëœ í¬ìŠ¤íŠ¸ë“¤ì˜ ì´ˆê¸° ìƒíƒœì™€ ìµœê³  ì„±ê³¼ ë‹¬ì„± ìƒíƒœë¥¼ ë¹„êµ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n"

    for file_path in file_paths:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {file_path} - {e}")
            continue

        post_id = str(data.get('post_id')) # JSONì—ì„œ ì½ì€ IDë„ strìœ¼ë¡œ í†µì¼
        initial_data = data.get('initial', {})

        # ì´ˆê¸° ìˆœìœ„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        rank_info = prediction_df[prediction_df['post_id'] == post_id]
        if rank_info.empty:
            print(f"ê²½ê³ : ì˜ˆì¸¡ íŒŒì¼ì—ì„œ post_id {post_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìˆœìœ„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            initial_rank, initial_percentile_top = 'N/A', 'N/A'
        else:
            initial_rank = rank_info['initial_rank'].iloc[0]
            initial_percentile_top = rank_info['initial_percentile_top'].iloc[0]

        # ìµœê³  ì„±ê³¼ ë²„ì „ ì°¾ê¸°
        best_version_key = 'initial'
        best_score = initial_data.get('model_score', float('-inf')) if initial_data else float('-inf')

        for key, value in data.items():
            if key.startswith('v') and isinstance(value, dict):
                current_score = value.get('model_score', float('-inf'))
                if current_score > best_score:
                    best_score = current_score
                    best_version_key = key
        
        best_version_data = data.get(best_version_key, {})

        # ê°œì„  í›„ ì˜ˆìƒ ìˆœìœ„ ê³„ì‚°
        improved_rank = (prediction_df['predicted_ctr'] > best_score).sum() + 1
        improved_percentile_top = (improved_rank / total_posts) * 100

        # ê¸°ëŒ€ ìœ ì…ë¥  ê³„ì‚°
        initial_inflow_rate = calculate_expected_inflow(initial_data.get('model_score'))
        best_inflow_rate = calculate_expected_inflow(best_version_data.get('model_score'))
        
        # ìœ ì…ë¥  ìƒìŠ¹ë¥  ê³„ì‚°
        inflow_improvement_rate = 0.0
        if initial_inflow_rate > 0:
            inflow_improvement_rate = ((best_inflow_rate / initial_inflow_rate) - 1) * 100
        elif best_inflow_rate > 0:
            inflow_improvement_rate = float('inf') # ì´ˆê¸°ê°’ì´ 0ì¼ ê²½ìš° ë¬´í•œëŒ€ë¡œ í‘œì‹œ

        # ë³´ê³ ì„œ ì„¹ì…˜ ì¶”ê°€
        report_content += f"\n---\n\n"
        report_content += f"## ğŸš€ í¬ìŠ¤íŠ¸ ID: {post_id}\n\n"
        
        # 1. ìµœì´ˆ ìƒíƒœ
        report_content += "### 1. ìµœì´ˆ ìƒíƒœ\n"
        report_content += f"*   **ì „ì²´ ìˆœìœ„**: **{initial_rank}ìœ„ / {total_posts}ê°œ** (ìƒìœ„ {initial_percentile_top:.1f}%)\n"
        report_content += f"*   **ëª¨ë¸ ì ìˆ˜**: `{initial_data.get('model_score', 0):.4f}`\n"
        report_content += f"*   **ê¸°ëŒ€ ê²€ìƒ‰ ìœ ì…ë¥ **: **{initial_inflow_rate:.2%}**\n"
        report_content += f"*   **ì œëª©**: {initial_data.get('post_title', 'N/A')}\n"
        report_content += f"*   **ì£¼ìš” í”¼ì²˜ ê°’**:\n{format_features_md(initial_data.get('feature_values'))}\n"
        report_content += f"*   **ë³¸ë¬¸**:\n```\n{initial_data.get('post_body', '')}\n```\n\n"

        # 2. ìµœê³  ì„±ê³¼ ë‹¬ì„±
        report_content += f"### 2. ìµœê³  ì„±ê³¼ ë‹¬ì„± ({best_version_key})\n"
        report_content += f"*   **ê°œì„  í›„ ì˜ˆìƒ ìˆœìœ„**: **{improved_rank}ìœ„ / {total_posts}ê°œ** (ìƒìœ„ {improved_percentile_top:.1f}%)\n"
        if isinstance(initial_rank, (int, float)) and not pd.isna(initial_rank):
             report_content += f"*   **ìˆœìœ„ ìƒìŠ¹**: **{int(initial_rank) - improved_rank}** ê³„ë‹¨ ìƒìŠ¹ ğŸ“ˆ\n"
        report_content += f"*   **ëª¨ë¸ ì ìˆ˜**: `{best_version_data.get('model_score', 0):.4f}`\n"
        report_content += f"*   **ê¸°ëŒ€ ê²€ìƒ‰ ìœ ì…ë¥ **: **{best_inflow_rate:.2%}**\n"
        if inflow_improvement_rate == float('inf'):
            report_content += f"*   **ê¸°ëŒ€ ê²€ìƒ‰ ìœ ì…ë¥  ìƒìŠ¹ë¥ **: **+âˆ%** (ì´ˆê¸° ìœ ì…ë¥  0ì—ì„œ ì¦ê°€) ğŸš€\n"
        else:
            report_content += f"*   **ê¸°ëŒ€ ê²€ìƒ‰ ìœ ì…ë¥  ìƒìŠ¹ë¥ **: **+{inflow_improvement_rate:.1f}%** ğŸš€\n"
        report_content += f"*   **ì œëª©**: {best_version_data.get('post_title', 'N/A')}\n"
        report_content += f"*   **ì£¼ìš” í”¼ì²˜ ê°’**:\n{format_features_md(best_version_data.get('feature_values'))}\n"
        report_content += f"*   **ë³¸ë¬¸**:\n```\n{best_version_data.get('post_body', '')}\n```\n"

    output_filename = 'post_improvement_summary.md'
    output_path = os.path.join(os.path.dirname(file_paths[0]), output_filename)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
        
    print(f"ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")

if __name__ == '__main__':
    prediction_file = 'blog_automation/data/post_edit/20250722_143801_feature_with_prediction.csv'
    # ì œê³µëœ íŒŒì¼ ëª©ë¡ì„ ì§ì ‘ ì‚¬ìš©
    json_files = [
        'blog_automation/data/post_edit/20250722_153854/223155543711_edit_history.json',
        'blog_automation/data/post_edit/20250722_153854/223235174542_edit_history.json',
        'blog_automation/data/post_edit/20250722_153854/223335804761_edit_history.json',
        'blog_automation/data/post_edit/20250722_153854/223580589189_edit_history.json',
        'blog_automation/data/post_edit/20250722_153854/223620072636_edit_history.json'
    ]
    summarize_results_to_markdown(json_files, prediction_file) 