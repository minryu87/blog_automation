{
  "timestamp": "2025-07-22T04:13:26.694626",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_consistency_ratio_vs_competitors",
  "hypothesis": "우리 포스트의 제목-본문 간 의미 일관성 점수가 해당 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록 (즉, 이 피처 값이 1보다 클수록), 비브랜드 평균 CTR이 높을 것이다. 이는 제목에서 제시한 기대를 본문이 잘 충족시켜 사용자 만족도를 높였기 때문이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the SentenceTransformer model, loading it only once.\"\"\"\n    global _model\n    if _model is None:\n        # A good multilingual model for general semantic understanding.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of title-body semantic consistency of 'ours' posts \n    to the average consistency of 'competitor' posts for each representative query.\n\n    Args:\n        df: DataFrame with columns 'post_title', 'post_body', 'source', 'representative_query'.\n\n    Returns:\n        DataFrame with the new feature column 'title_body_consistency_ratio_vs_competitors'.\n    \"\"\"\n    feature_name = 'title_body_consistency_ratio_vs_competitors'\n\n    # Check for an empty DataFrame to prevent errors.\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # Ensure required columns exist\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_cols):\n        df[feature_name] = np.nan\n        return df\n\n    model = get_model()\n\n    # Preserve the original index to ensure correct alignment later.\n    original_index = df.index\n\n    # Prepare texts for encoding, handling potential missing values.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Efficiently encode all titles and bodies in batches.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate the cosine similarity between each title and its corresponding body.\n    # .diag() extracts the [i, i] element, which is sim(title_i, body_i).\n    consistency_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # Add the individual scores as a temporary column for easy grouping.\n    # Use a unique name to avoid conflicts.\n    temp_score_col = 'temp_consistency_score_xyz'\n    df[temp_score_col] = consistency_scores\n\n    # Initialize the final feature column with NaN.\n    df[feature_name] = np.nan\n\n    # Group by the representative query to perform the comparison within the same SERP context.\n    # Using a loop over groups is explicit, readable, and safe against data slicing errors.\n    for name, group in df.groupby('representative_query'):\n        ours_group = group[group['source'] == 'ours']\n        competitor_group = group[group['source'] == 'competitor']\n\n        if ours_group.empty or competitor_group.empty:\n            continue\n\n        # Calculate the average consistency score for the competitor posts in this group.\n        competitor_avg_score = competitor_group[temp_score_col].mean()\n\n        # If there are no valid competitor scores, or the average is zero,\n        # we set the ratio to 1.0, implying parity. This avoids division by zero.\n        if pd.isna(competitor_avg_score) or competitor_avg_score == 0:\n            ratio_values = 1.0\n        else:\n            our_scores = ours_group[temp_score_col]\n            ratio_values = our_scores / competitor_avg_score\n        \n        # Assign the calculated ratio to the correct rows in the original DataFrame\n        # using the preserved index.\n        df.loc[ours_group.index, feature_name] = ratio_values\n\n    # Clean up the temporary column.\n    df = df.drop(columns=[temp_score_col])\n    \n    # This feature is only meaningful for 'ours' posts, so fillna for others is acceptable.\n    # The logic already ensures competitors get NaN by default.\n\n    return df",
  "analysis": {
    "correlation": 0.10142659922188069,
    "p_value": 0.3280633958132242,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T04:31:27.665376",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 제목과 본문 간 의미적 일관성 점수가 경쟁자 그룹의 평균 점수보다 높을수록, 즉 '제목-본문 일관성 상대 비율'이 1보다 클수록 non_brand_average_ctr이 높을 것이다. 이 피처는 제목이 제시한 약속을 본문이 얼마나 잘 이행하는지를 측정하고, 이를 경쟁 환경과 비교하여 콘텐츠의 구조적 완성도를 평가한다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton instance of the SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and computes its ratio\n    against the average cohesion of competitor posts within the same representative query group.\n    \n    - A value > 1.0 means our post's title-body cohesion is better than the competitor average.\n    - A value < 1.0 means our post's title-body cohesion is worse than the competitor average.\n    - A value of 1.0 means it's on par, or there were no competitors to compare against.\n    \"\"\"\n    feature_name = 'title_body_cohesion_vs_competitors'\n    \n    # 2. Check for empty DataFrame to prevent errors.\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # 3. Ensure required columns exist.\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_cols):\n        # If essential columns are missing, return the DataFrame with an empty feature column.\n        df[feature_name] = 1.0\n        return df\n\n    model = get_model()\n\n    # 4. Prepare data for batch processing. Fill NaNs to prevent encoder errors.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 5. Encode titles and bodies in efficient batches.\n    # Using a progress bar can be helpful for debugging but is turned off for production.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 6. Calculate the cosine similarity between each title and its corresponding body.\n    # .diag() extracts the similarity scores for (title_i, body_i) pairs.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    \n    # Temporarily add cohesion scores to the DataFrame, preserving the original index.\n    df['temp_cohesion_score'] = cohesion_scores.cpu().numpy()\n\n    # 7. Calculate the average competitor cohesion score for each group.\n    # Use transform to broadcast the group mean back to each row in the group.\n    # This is more efficient than iterating.\n    \n    # First, calculate the mean only for competitors. This results in NaNs for 'ours' rows.\n    competitor_avg_scores = df[df['source'] == 'competitor'].groupby('representative_query')['temp_cohesion_score'].transform('mean')\n    df['temp_competitor_avg'] = competitor_avg_scores\n\n    # Now, propagate the calculated average to all rows within the same group, including 'ours' posts.\n    # 'first' takes the first valid (non-NaN) value in the group and applies it to all members.\n    df['temp_competitor_avg'] = df.groupby('representative_query')['temp_competitor_avg'].transform('first')\n\n    # 8. Calculate the relative cohesion ratio for our posts.\n    ours_mask = df['source'] == 'ours'\n    ours_scores = df.loc[ours_mask, 'temp_cohesion_score']\n    competitor_avg_for_ours = df.loc[ours_mask, 'temp_competitor_avg']\n\n    # Calculate the ratio. The result will be NaN if the competitor average is NaN or 0.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        relative_ratio = ours_scores / competitor_avg_for_ours\n\n    # Initialize the final feature column with a neutral default value of 1.0.\n    df[feature_name] = 1.0\n    \n    # Assign the calculated ratios to the 'ours' posts.\n    df.loc[ours_mask, feature_name] = relative_ratio\n\n    # 9. Clean up and handle edge cases.\n    # Replace inf/-inf (from division by zero) and NaN (from no competitors) with the neutral 1.0.\n    df[feature_name].replace([np.inf, -np.inf], 1.0, inplace=True)\n    df[feature_name].fillna(1.0, inplace=True)\n    \n    # Drop temporary columns.\n    df.drop(columns=['temp_cohesion_score', 'temp_competitor_avg'], inplace=True)\n\n    # 10. Return the full DataFrame with the new feature column.\n    return df",
  "analysis": {
    "correlation": 0.10142659609104629,
    "p_value": 0.328063410821786,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T04:51:49.377228",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_semantic_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a pre-trained SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model that is effective for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of title-body semantic cohesion for 'our' posts\n    relative to the average cohesion of competitor posts for the same query.\n\n    Args:\n        df: DataFrame containing post data with columns 'post_title', 'post_body',\n            'source', and 'representative_query'.\n\n    Returns:\n        DataFrame with the new feature column 'title_body_semantic_cohesion_vs_competitors'.\n    \"\"\"\n    # 2. Always check for an empty DataFrame before processing.\n    if df.empty:\n        df['title_body_semantic_cohesion_vs_competitors'] = pd.Series(dtype=float)\n        return df\n\n    # Use a copy to avoid SettingWithCopyWarning\n    df_copy = df.copy()\n\n    model = get_model()\n\n    # 3. Prepare data for efficient batch processing.\n    titles = df_copy['post_title'].fillna('').astype(str).tolist()\n    bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n    # 4. Encode all titles and bodies in batches for performance.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 5. Calculate the semantic cohesion (consistency) for each post.\n    # The diagonal of the cosine similarity matrix gives the similarity of each title to its corresponding body.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    df_copy['temp_cohesion_score'] = cohesion_scores.cpu().numpy()\n\n    # 6. Calculate the average cohesion score for competitors within each query group.\n    competitors_df = df_copy[df_copy['source'] == 'competitors'].copy()\n    \n    # Ensure temp_cohesion_score is numeric before grouping\n    competitors_df['temp_cohesion_score'] = pd.to_numeric(competitors_df['temp_cohesion_score'], errors='coerce')\n\n    # Calculate the mean, handling cases where a query group might have no competitors\n    competitor_avg_cohesion = competitors_df.groupby('representative_query')['temp_cohesion_score'].mean()\n    \n    # 7. Map the competitor average back to the main DataFrame.\n    df_copy['competitor_avg_cohesion'] = df_copy['representative_query'].map(competitor_avg_cohesion)\n\n    # 8. Calculate the final feature: the ratio of a post's cohesion to the competitor average.\n    # Replace 0 in the denominator with a very small number to avoid division by zero errors.\n    denominator = df_copy['competitor_avg_cohesion'].replace(0, 1e-9)\n    df_copy['title_body_semantic_cohesion_vs_competitors'] = df_copy['temp_cohesion_score'] / denominator\n\n    # 9. Handle edge cases:\n    # - Replace infinite values (from division by near-zero) with NaN.\n    df_copy.replace([np.inf, -np.inf], np.nan, inplace=True)\n    # - Fill NaN values with 1.0. This occurs for queries with no competitors,\n    #   implying our post's cohesion is on par with a non-existent average.\n    df_copy['title_body_semantic_cohesion_vs_competitors'].fillna(1.0, inplace=True)\n\n    # 10. Clean up temporary columns and assign the new feature to the original DataFrame.\n    df['title_body_semantic_cohesion_vs_competitors'] = df_copy['title_body_semantic_cohesion_vs_competitors']\n\n    return df"
}{
  "timestamp": "2025-07-22T04:53:22.787126",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares it to the\n    competitor average for the same representative query.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame with columns including 'post_title',\n                           'post_body', 'source', and 'representative_query'.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the new feature column 'relative_title_body_cohesion'.\n    \"\"\"\n    # 4. Check for an empty DataFrame to prevent errors.\n    if df.empty:\n        df['relative_title_body_cohesion'] = pd.Series(dtype=float)\n        return df\n\n    model = get_model()\n\n    # --- Step 1: Calculate individual cohesion score for ALL posts --- #\n\n    # Preserve original index to ensure correct alignment later\n    df_copy = df.copy()\n\n    # Prepare text data for batch processing\n    titles = df_copy['post_title'].fillna('').astype(str).tolist()\n    bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n    # 2. Use efficient batch processing for all posts at once.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate cosine similarity. .diag() gets the element-wise similarity [i,i]\n    # between title_embeddings[i] and body_embeddings[i].\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n    # Add the individual score as a temporary column. This assignment is safe\n    # because we are working on a copy that has the same index as the original df.\n    df_copy['title_body_cohesion'] = cohesion_scores.cpu().numpy()\n\n    # --- Step 2: Calculate the relative score against competitors per query group --- #\n\n    # Initialize the final feature column in the original DataFrame\n    df['relative_title_body_cohesion'] = np.nan\n\n    # Group by the representative query to compare 'ours' vs 'competitors'\n    grouped = df_copy.groupby('representative_query')\n\n    for query, group_df in grouped:\n        # Separate our posts from competitor posts within the group\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitors']\n\n        # Proceed only if there are competitors to benchmark against\n        if not competitor_posts.empty and not competitor_posts['title_body_cohesion'].isnull().all():\n            # Calculate the average cohesion score for the competitor group\n            avg_competitor_cohesion = competitor_posts['title_body_cohesion'].mean()\n\n            # Avoid division by zero\n            if avg_competitor_cohesion > 1e-6:\n                # If our posts exist in this group, calculate their relative score\n                if not ours_posts.empty:\n                    # This is the core logic that ensures variance:\n                    # Each 'ours' post's individual score is divided by the *same* competitor average for that group.\n                    # This results in a unique value for each 'ours' post, assuming their cohesion scores differ.\n                    relative_scores = ours_posts['title_body_cohesion'] / avg_competitor_cohesion\n\n                    # CRITICAL: Assign the calculated scores back to the original DataFrame using the correct index.\n                    # This prevents the misalignment and constant value errors.\n                    df.loc[ours_posts.index, 'relative_title_body_cohesion'] = relative_scores\n\n    # For posts without a competitor benchmark, fill with a neutral value of 1.0,\n    # implying they are on par with a non-existent competitor average.\n    df['relative_title_body_cohesion'].fillna(1.0, inplace=True)\n\n    # 3. Return the full DataFrame with the new column.\n    return df"
}{
  "timestamp": "2025-07-22T04:54:53.981237",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a pre-trained SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model is robust for various content types.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body cohesion score for our posts relative to the\n    average competitor cohesion score for the same representative query.\n\n    This directly fixes the previous logical error where the feature had no variance.\n    The new feature value is calculated per 'representative_query' group,\n    ensuring that each 'ours' post is compared only against its direct competitors.\n\n    A score > 1.0 means our post has better title-body alignment than the competitor average.\n    A score < 1.0 means it's worse.\n    A score of 1.0 is a neutral value assigned to competitor posts or groups without a benchmark.\n    \"\"\"\n    # Check for empty DataFrame to prevent errors.\n    if df.empty:\n        df['title_body_cohesion_vs_competitors'] = pd.Series(dtype=float)\n        return df\n\n    # Preserve the original index to ensure correct feature assignment.\n    original_index = df.index\n\n    # Initialize the model.\n    model = get_model()\n\n    # --- Step 1: Calculate individual cohesion for ALL posts ---\n    # Prepare text data, handling potential NaN values.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode in efficient batches.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate cosine similarity between each title and its corresponding body.\n    # .diag() efficiently extracts the similarity of (title_i, body_i) for all i.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # Create a temporary DataFrame for calculations, preserving the original index.\n    temp_df = pd.DataFrame({\n        'representative_query': df['representative_query'],\n        'source': df['source'],\n        '_cohesion_score': cohesion_scores\n    }, index=original_index)\n\n    # --- Step 2: Calculate the average competitor cohesion PER QUERY group ---\n    # Create a series where only competitor scores are present, others are NaN.\n    competitor_only_scores = temp_df.loc[temp_df['source'] == 'competitors', '_cohesion_score']\n\n    # Use groupby().transform() to calculate the mean for each query group and broadcast\n    # it to all members of that group. This is the key fix to the previous logical error.\n    # 'transform' ensures the output has the same index as the input DataFrame.\n    temp_df['competitor_avg_cohesion'] = temp_df.groupby('representative_query')['_cohesion_score']\\\n                                              .transform(lambda x: competitor_only_scores.reindex(x.index).mean())\n\n    # --- Step 3: Calculate the relative cohesion ratio for 'ours' posts ---\n    # The feature is the ratio of our post's cohesion to the competitor average for that query.\n    # Using .div() for safe division.\n    relative_cohesion = temp_df['_cohesion_score'].div(temp_df['competitor_avg_cohesion'])\n\n    # Replace potential inf (if avg is 0) or NaN (if no competitors) with a neutral 1.0.\n    relative_cohesion.replace([np.inf, -np.inf], np.nan, inplace=True)\n    relative_cohesion.fillna(1.0, inplace=True)\n\n    # The feature's variance should only come from 'ours' posts.\n    # Assign the calculated ratio to 'ours' posts and a neutral 1.0 to competitors.\n    feature_values = np.where(\n        temp_df['source'] == 'ours',\n        relative_cohesion,\n        1.0\n    )\n\n    # Assign the calculated feature back to the original DataFrame.\n    df['title_body_cohesion_vs_competitors'] = pd.Series(feature_values, index=original_index)\n\n    return df"
}{
  "timestamp": "2025-07-22T04:55:44.492823",
  "attempt": 4,
  "status": "success",
  "feature_name": "relative_title_body_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 동일 대표 검색어에 대한 경쟁자 그룹의 평균 점수보다 높을수록, 사용자의 기대치를 더 잘 충족시켜 non_brand_average_ctr이 높아질 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence transformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model that's effective for Korean and performs well.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and normalizes it\n    against the average cohesion of competitors for the same representative query.\n    This creates a feature with variance, addressing the previous error where all\n    posts had the same value.\n    \"\"\"\n    feature_name = 'relative_title_body_cohesion'\n\n    # 2. ALWAYS check for an empty DataFrame to prevent errors.\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # 3. Preserve the original index to ensure correct assignment later.\n    original_index = df.index\n\n    # Ensure required columns exist\n    if 'post_title' not in df.columns or 'post_body' not in df.columns:\n        raise ValueError(\"Required columns 'post_title' or 'post_body' not in DataFrame.\")\n\n    model = get_model()\n\n    # 4. Prepare data for efficient batch processing.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 5. Encode texts in a single batch for maximum efficiency.\n    # No .apply() loops.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 6. Calculate individual cohesion scores for EVERY post.\n    # .diag() efficiently gets the pairwise similarity for corresponding title/body.\n    # This is the key step to ensure each post has its own unique base score.\n    individual_cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    \n    # Use a temporary column for calculations. Assigning back to the original df ensures alignment.\n    df['temp_cohesion'] = individual_cohesion_scores.cpu().numpy()\n\n    # 7. Calculate the competitor average cohesion for each query group.\n    # Create a temporary series of cohesion scores only for competitors.\n    competitor_cohesion = df.loc[df['source'] == 'competitor', 'temp_cohesion']\n    \n    # Map competitor scores to the original df based on index to prepare for groupby\n    df['temp_competitor_cohesion'] = competitor_cohesion\n\n    # Use transform to calculate the mean for each group and broadcast it to all rows in that group.\n    # This is the correct way to create a benchmark value for each row based on its group.\n    df['competitor_avg_cohesion'] = df.groupby('representative_query')['temp_competitor_cohesion'].transform('mean')\n\n    # 8. Calculate the final relative feature.\n    # This will now produce different values for each 'ours' post because their\n    # individual 'temp_cohesion' scores differ.\n    df[feature_name] = df['temp_cohesion'] / df['competitor_avg_cohesion']\n\n    # 9. Clean up and handle potential edge cases.\n    # Fill NaN (for groups with no competitors) or inf (division by zero) with 1.0, \n    # representing parity when a benchmark is unavailable.\n    df[feature_name].replace([np.inf, -np.inf], np.nan, inplace=True)\n    df[feature_name].fillna(1.0, inplace=True)\n\n    # Drop temporary columns\n    df.drop(columns=['temp_cohesion', 'temp_competitor_cohesion', 'competitor_avg_cohesion'], inplace=True)\n    \n    # 10. Return the full DataFrame with the new feature column, ensuring original index is intact.\n    return df\n",
  "analysis": {
    "correlation": 0.10142660917550145,
    "p_value": 0.3280633480976571,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T05:11:36.610095",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton instance of the SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # A good multilingual model for general purpose semantic similarity.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between a post's title and body, and compares it\n    to the average cohesion of competitor posts for the same representative query.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame with columns 'post_title', 'post_body',\n                           'source', and 'representative_query'.\n\n    Returns:\n        pd.DataFrame: The DataFrame with a new feature column 'title_body_cohesion_vs_competitors'.\n    \"\"\"\n    feature_name = 'title_body_cohesion_vs_competitors'\n\n    # 2. Check for an empty DataFrame to prevent errors.\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # Ensure the feature column exists, initialized with NaN.\n    df[feature_name] = np.nan\n\n    # Check if necessary columns exist and data is sufficient for calculation.\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_cols):\n        # If essential columns are missing, return the dataframe with the empty feature column.\n        return df\n\n    if not ('ours' in df['source'].unique() and 'competitors' in df['source'].unique()):\n        # If there are no 'ours' or 'competitors' to compare, no ratio can be calculated.\n        df[feature_name] = 1.0 # Set to 1.0 assuming parity when no comparison is possible\n        return df\n        \n    model = get_model()\n\n    # 3. Use efficient batch processing for embedding generation.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate individual cohesion score (cosine similarity between each title and its body).\n    # .diag() correctly extracts the element-wise similarity (title_i vs body_i).\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n    \n    # Use a temporary column to store individual cohesion scores.\n    df['temp_cohesion_score'] = cohesion_scores\n\n    # Calculate the average cohesion for competitors within each query group.\n    competitor_scores = df[df['source'] == 'competitors']\n    avg_competitor_cohesion = competitor_scores.groupby('representative_query')['temp_cohesion_score'].mean().rename('avg_competitor_cohesion')\n\n    # If there are no competitors at all, no averages can be computed.\n    if avg_competitor_cohesion.empty:\n        df.drop(columns=['temp_cohesion_score'], inplace=True)\n        df[feature_name] = 1.0 # Set all to 1.0 as no comparison is possible.\n        return df\n\n    # Map the average competitor cohesion back to the main DataFrame.\n    df = df.merge(avg_competitor_cohesion, on='representative_query', how='left')\n\n    # Calculate the feature value only for 'ours' posts.\n    our_mask = df['source'] == 'ours'\n    \n    # Calculate the ratio of our cohesion vs the competitor average.\n    our_cohesion_score = df.loc[our_mask, 'temp_cohesion_score']\n    competitor_avg_score = df.loc[our_mask, 'avg_competitor_cohesion']\n    \n    relative_cohesion = our_cohesion_score / competitor_avg_score\n    \n    # Handle edge cases:\n    # - Division by zero (inf) -> replace with NaN\n    # - No competitors for a specific query (NaN) -> fill with 1.0 (parity)\n    relative_cohesion = relative_cohesion.replace([np.inf, -np.inf], np.nan).fillna(1.0)\n    \n    # Assign the calculated relative scores to the feature column for 'ours' posts.\n    df.loc[our_mask, feature_name] = relative_cohesion\n\n    # Clean up temporary columns.\n    df.drop(columns=['temp_cohesion_score', 'avg_competitor_cohesion'], inplace=True)\n\n    # 4. Return the full DataFrame with the new feature column.\n    return df"
}{
  "timestamp": "2025-07-22T05:13:47.896183",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a model that performs well for Korean semantic similarity.\n        _model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body cohesion for each post and compares it to the competitor average for the same query.\n\n    The feature corrects a previous logical error by calculating a unique ratio for each 'ours' post\n    instead of applying a single, constant ratio to all posts, thus ensuring variance in the output.\n    \"\"\"\n    feature_name = 'title_body_cohesion_vs_competitors'\n    df[feature_name] = np.nan # Initialize the column with NaN\n\n    if df.empty:\n        return df\n\n    # Ensure 'ours' and 'competitors' sources exist to avoid errors\n    if not (df['source'].isin(['ours', 'competitors'])).all():\n        # Or handle as a warning if mixed sources are possible\n        # print(\"Warning: DataFrame contains sources other than 'ours' or 'competitors'.\")\n        pass\n\n    try:\n        model = get_model()\n\n        # 2. Process all texts in batches for efficiency\n        titles = df['post_title'].fillna('').astype(str).tolist()\n        bodies = df['post_body'].fillna('').astype(str).tolist()\n\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # 3. Calculate individual cohesion score for EVERY post\n        # .diag() efficiently gets the cosine similarity between corresponding elements (title_i, body_i)\n        individual_cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n        # Create a temporary column to hold the per-post score\n        df['temp_individual_cohesion'] = individual_cohesion_scores.cpu().numpy()\n\n        # 4. Calculate the average cohesion score for ONLY competitor posts, grouped by query\n        competitor_df = df[df['source'] == 'competitors'].copy()\n        if not competitor_df.empty:\n            competitor_benchmark_map = competitor_df.groupby('representative_query')['temp_individual_cohesion'].mean()\n\n            # 5. Map the calculated competitor benchmark to each row in the original DataFrame\n            df['temp_competitor_benchmark'] = df['representative_query'].map(competitor_benchmark_map)\n\n            # 6. Calculate the final feature for 'ours' posts\n            # The feature is the ratio of an individual 'ours' post's cohesion to its query's competitor average.\n            # This ensures each 'ours' post gets a unique value, fixing the zero-variance issue.\n            ours_mask = (df['source'] == 'ours')\n            \n            # Avoid division by zero or by NaN\n            valid_benchmark_mask = df['temp_competitor_benchmark'].notna() & (df['temp_competitor_benchmark'] != 0)\n            \n            final_mask = ours_mask & valid_benchmark_mask\n\n            df.loc[final_mask, feature_name] = df.loc[final_mask, 'temp_individual_cohesion'] / df.loc[final_mask, 'temp_competitor_benchmark']\n\n            # Clean up temporary columns\n            df.drop(columns=['temp_competitor_benchmark'], inplace=True)\n\n        # Clean up the remaining temporary column\n        df.drop(columns=['temp_individual_cohesion'], inplace=True)\n\n    except Exception as e:\n        # In case of any error (e.g., model loading, empty groups), the feature column will remain NaN\n        print(f\"Error generating '{feature_name}': {e}\")\n        # Ensure temporary columns are dropped even if an error occurs mid-process\n        df.drop(columns=[col for col in ['temp_individual_cohesion', 'temp_competitor_benchmark'] if col in df.columns], inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:15:13.854481",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_semantic_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares the score\n    for 'ours' posts against the average of 'competitors' within the same query group.\n\n    The final feature is a ratio: (our_post_cohesion) / (avg_competitor_cohesion_for_query)\n    This produces a unique value for each 'our' post, solving the zero-variance issue.\n    \"\"\"\n    feature_name = 'relative_title_body_semantic_cohesion'\n    df[feature_name] = np.nan\n\n    # 2. Check for empty DataFrame to prevent errors.\n    if df.empty:\n        return df\n\n    # Ensure required columns exist\n    required_columns = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_columns):\n        # If essential columns are missing, return the DataFrame as is\n        # This prevents crashes in pipelines where data might be incomplete.\n        return df\n\n    model = get_model()\n\n    # 3. Process data in batches for efficiency.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode all titles and bodies at once\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 4. Calculate individual cohesion score for every post.\n    # util.cos_sim returns a matrix, .diag() extracts the similarity of each (title_i, body_i) pair.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n    # Use a temporary column to store the cohesion score for all posts.\n    # This ensures that each 'our' post has its own unique base score.\n    temp_cohesion_col = 'temp_cohesion_score'\n    df[temp_cohesion_col] = cohesion_scores.cpu().numpy()\n\n    # 5. Calculate the average competitor cohesion score for each query group.\n    competitors_df = df[df['source'] == 'competitors'].copy()\n    \n    # Check if there are any competitors to avoid errors on empty groupby\n    if not competitors_df.empty:\n        avg_competitor_cohesion = competitors_df.groupby('representative_query')[temp_cohesion_col].mean()\n\n        # 6. Map the competitor average back to each 'our' post based on its query.\n        # This provides the benchmark for each 'our' post to be compared against.\n        is_ours = (df['source'] == 'ours')\n        our_posts_df = df[is_ours].copy()\n        \n        if not our_posts_df.empty:\n            our_posts_df['benchmark_cohesion'] = our_posts_df['representative_query'].map(avg_competitor_cohesion)\n\n            # 7. Calculate the final feature ratio for 'ours' posts.\n            # This creates variance as each 'our' post's individual score is used.\n            # Using np.divide for safe division, filling with 1.0 (parity) if benchmark is 0 or NaN.\n            ratio = np.divide(\n                our_posts_df[temp_cohesion_col],\n                our_posts_df['benchmark_cohesion'],\n                out=np.full_like(our_posts_df[temp_cohesion_col], 1.0, dtype=float),\n                where=(our_posts_df['benchmark_cohesion'].notna()) & (our_posts_df['benchmark_cohesion'] != 0)\n            )\n            \n            # Assign the calculated ratio back to the main DataFrame's feature column\n            df.loc[is_ours, feature_name] = ratio\n\n    # 8. Clean up temporary column.\n    df.drop(columns=[temp_cohesion_col], inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:16:23.577416",
  "attempt": 4,
  "status": "success",
  "feature_name": "relative_title_body_semantic_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 경쟁자 그룹의 평균 점수보다 높을수록(즉, 상대적 비율 > 1), non_brand_average_ctr이 높을 것이다. 이 피처는 개별 '우리' 포스트마다 계산되므로, 이전 시도와 달리 값의 분산이 보장된다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each 'our' post relative to \n    the average cohesion of competitor posts for the same representative query.\n\n    The core issue in the previous attempt was calculating a single metric for the\n    entire 'ours' group vs. the 'competitors' group, resulting in a constant\n    feature value. This version corrects that by:\n    1. Calculating an individual cohesion score for EVERY post (ours and competitors).\n    2. For each query, calculating the AVERAGE cohesion of competitor posts (the benchmark).\n    3. For each 'our' post, creating the feature as the ratio of its individual score\n       to its query's competitor benchmark. This ensures variance across 'our' posts.\n    \"\"\"\n    # 2. Check for empty DataFrame to prevent errors.\n    if df.empty:\n        return df\n\n    feature_name = 'relative_title_body_semantic_cohesion'\n    df[feature_name] = np.nan\n\n    # 3. Ensure 'ours' and 'competitors' exist to create a benchmark.\n    ours_mask = df['source'] == 'ours'\n    competitors_mask = df['source'] != 'ours'\n    if not ours_mask.any() or not competitors_mask.any():\n        return df # Cannot compute feature without both groups.\n\n    model = get_model()\n\n    # 4. Prepare data in batches for efficient processing.\n    # Preserving the original index is crucial for correct assignment later.\n    original_index = df.index\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 5. Encode all titles and bodies into embeddings.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 6. Calculate individual cohesion scores for all posts.\n    # The diagonal of the similarity matrix gives the cohesion for each title-body pair.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # 7. Add scores to a temporary column for easier grouping.\n    # Assigning to a temporary series with the original index prevents alignment issues.\n    df_temp_cohesion = pd.Series(cohesion_scores, index=original_index)\n\n    # 8. Calculate the competitor benchmark for each query group.\n    competitor_avg_cohesion = df.loc[competitors_mask].join(df_temp_cohesion.rename('temp_cohesion'))\\\n                                                      .groupby('representative_query')['temp_cohesion'].mean()\n    \n    # If no valid benchmarks could be calculated, return.\n    if competitor_avg_cohesion.empty:\n        return df\n\n    # 9. Map the competitor benchmark to each 'our' post based on its query.\n    our_posts_df = df.loc[ours_mask]\n    our_competitor_benchmark = our_posts_df['representative_query'].map(competitor_avg_cohesion)\n\n    # 10. Calculate the relative cohesion ratio for each 'our' post.\n    # This row-wise calculation ensures the final feature has variance.\n    our_individual_cohesion = df_temp_cohesion[ours_mask]\n\n    # Use np.divide for safe division, yielding NaN if benchmark is 0 or missing.\n    relative_scores = np.divide(\n        our_individual_cohesion.values,\n        our_competitor_benchmark.values,\n        out=np.full(our_individual_cohesion.shape, np.nan),\n        where=(our_competitor_benchmark.notna()) & (our_competitor_benchmark != 0)\n    )\n\n    # 11. Assign the calculated scores back to the original DataFrame.\n    df.loc[ours_mask, feature_name] = relative_scores\n\n    # Assume parity (ratio=1.0) if a benchmark was missing or zero.\n    df.loc[ours_mask, feature_name] = df.loc[ours_mask, feature_name].fillna(1.0)\n\n    return df",
  "analysis": {
    "correlation": 0.10142659609104629,
    "p_value": 0.328063410821786,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T05:37:22.050199",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_semantic_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # A lightweight, multilingual model suitable for Korean and general use.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for our posts relative to the competitor average for the same query.\n\n    The feature measures how well a post's body fulfills the semantic promise of its title,\n    benchmarked against the average performance of competitors.\n\n    - A value > 1.0 indicates our post has better title-body cohesion than the competitor average.\n    - A value < 1.0 indicates our post has worse cohesion.\n    - A value = 1.0 indicates it's on par with the average or there are no competitors to compare against.\n    \"\"\"\n    # 2. Always check for an empty DataFrame to prevent errors.\n    if df.empty:\n        df['relative_title_body_semantic_cohesion'] = pd.Series(dtype=float)\n        return df\n\n    # 3. Get the model.\n    model = get_model()\n\n    # 4. Prepare data for batch processing. This is much faster than .apply().\n    # Ensure data is string type and handle potential None/NaN values.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 5. Generate embeddings for all titles and bodies in efficient batches.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 6. Calculate the pairwise cosine similarity for each post's title and body.\n    # .diag() efficiently extracts the similarity score for (title_0, body_0), (title_1, body_1), etc.\n    df['temp_cohesion_score'] = util.cos_sim(title_embeddings, body_embeddings).diag().tolist()\n\n    # 7. Calculate the average cohesion score for competitors within each 'representative_query' group.\n    competitor_df = df[df['source'] == 'competitors'].copy()\n    if not competitor_df.empty:\n        competitor_avg_cohesion = competitor_df.groupby('representative_query')['temp_cohesion_score'].mean().rename('competitor_avg_cohesion')\n        # 8. Merge the competitor average back into the main DataFrame.\n        df = df.merge(competitor_avg_cohesion, on='representative_query', how='left')\n    else:\n        # Handle case where there are no competitors at all in the dataframe\n        df['competitor_avg_cohesion'] = np.nan\n\n    # 9. Calculate the final feature: our cohesion score relative to the competitor average.\n    # This is calculated for all rows initially.\n    df['relative_title_body_semantic_cohesion'] = df['temp_cohesion_score'] / df['competitor_avg_cohesion']\n\n    # Replace inf (from division by zero-cohesion competitors) and NaN (from groups with no competitors)\n    # with 1.0, representing parity or no basis for comparison.\n    df['relative_title_body_semantic_cohesion'].replace([np.inf, -np.inf], 1.0, inplace=True)\n    df['relative_title_body_semantic_cohesion'].fillna(1.0, inplace=True)\n\n    # 10. The feature is only meaningful for 'ours' posts. Set competitors' values to NaN.\n    df.loc[df['source'] == 'competitors', 'relative_title_body_semantic_cohesion'] = np.nan\n\n    # 11. Clean up temporary columns before returning.\n    df.drop(columns=['temp_cohesion_score', 'competitor_avg_cohesion'], inplace=True, errors='ignore')\n\n    return df\n"
}{
  "timestamp": "2025-07-22T05:38:09.516786",
  "attempt": 2,
  "status": "success",
  "feature_name": "title_body_semantic_cohesion",
  "hypothesis": "게시물의 제목과 본문 간 의미적 일관성(cohesion)이 높을수록, 즉 제목이 제시한 주제를 본문이 충실하게 설명할수록 사용자 의도를 더 잘 만족시켜 'non_brand_average_ctr'이 높아질 것이다. 이전 시도의 피처 값이 모두 동일했던 문제를 해결하기 위해, 그룹별 상대 비교가 아닌 각 게시물 고유의 절대적인 일관성 점수를 계산하여 모든 행이 독립적인 값을 갖도록 수정한다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\nimport torch\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton instance of the SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a powerful multilingual model suitable for Korean text.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between each post's title and body.\n\n    This feature computes the cosine similarity between the embedding of the\n    post_title and the embedding of the post_body for each row independently.\n    This approach calculates an absolute cohesion score for every post, ensuring\n    that each row receives a unique value, thus resolving the previous issue\n    where a relative comparison led to a constant feature value for all 'ours' posts.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame containing post data.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the new 'title_body_semantic_cohesion' column added.\n    \"\"\"\n    # 2. ALWAYS check for empty DataFrames before processing.\n    if df.empty:\n        df['title_body_semantic_cohesion'] = pd.Series(dtype=float)\n        return df\n\n    try:\n        model = get_model()\n\n        # 3. Process data in batches for efficiency. Handle potential NaN values.\n        titles = df['post_title'].fillna('').astype(str).tolist()\n        bodies = df['post_body'].fillna('').astype(str).tolist()\n\n        # Encode titles and bodies into embeddings.\n        # The model handles batch processing efficiently.\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # 4. Calculate cosine similarity. Use .diag() for pairwise comparison.\n        # util.cos_sim produces a similarity matrix. The diagonal contains the\n        # similarity of title[i] to body[i], which is what we need.\n        cosine_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n        # Move scores to CPU and convert to a list for DataFrame assignment.\n        df['title_body_semantic_cohesion'] = cosine_scores.cpu().tolist()\n\n    except Exception as e:\n        # In case of an error (e.g., model loading failure), fill with a neutral value.\n        print(f\"Error calculating title_body_semantic_cohesion: {e}\")\n        df['title_body_semantic_cohesion'] = np.nan\n\n    # 5. Return the full DataFrame with the new feature column.\n    return df",
  "analysis": {
    "correlation": 0.2515497740320771,
    "p_value": 0.013931492331653162,
    "interpretation": "약한 양의 상관관계(0.2515)를 발견했습니다. 이 결과는 통계적으로 유의미합니다(p-value: 0.0139)."
  }
}{
  "timestamp": "2025-07-22T05:58:41.054749",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_semantic_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 제목과 본문 간 의미적 일관성 점수가 동일 대표 검색어 그룹 내 경쟁 포스트들의 평균 점수보다 높을수록, 사용자가 제목에서 기대한 바를 본문이 잘 충족시킨다고 판단하여 더 높은 클릭률(non_brand_average_ctr)로 이어질 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and computes its ratio \n    against the average cohesion of competitors within the same query group.\n\n    The feature represents how well a post's body fulfills the promise of its title,\n    relative to its direct competitors.\n    \"\"\"\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n\n    # 2. Always check for an empty DataFrame to prevent errors.\n    if df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # Ensure required columns are present\n    required_cols = ['post_title', 'post_body', 'representative_query', 'source']\n    if not all(col in df.columns for col in required_cols):\n        df[feature_name] = np.nan\n        return df\n\n    # 3. Preserve original index to prevent misalignment issues upon feature assignment.\n    # This is a critical step for correctness.\n    original_index = df.index\n\n    # Prepare text data for batch processing\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 4. Use efficient batch processing for embedding, not .apply()\n    model = get_model()\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate cosine similarity between each title and its corresponding body\n    # .diag() correctly extracts the pairwise similarity scores [sim(T1,B1), sim(T2,B2), ...]\n    cosine_scores = util.cos_sim(title_embeddings, body_embeddings)\n    df['temp_consistency_score'] = cosine_scores.diag().cpu().tolist()\n\n    # Initialize the feature column with a default value (NaN)\n    df[feature_name] = np.nan\n\n    # Group by representative query to calculate relative scores\n    grouped = df.groupby('representative_query')\n\n    for name, group in grouped:\n        our_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        # Skip if no 'ours' posts or no competitors in the group\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # Calculate the average consistency score for competitors\n        competitor_avg_consistency = competitor_posts['temp_consistency_score'].mean()\n        \n        # Avoid division by zero\n        if competitor_avg_consistency > 0:\n            # Calculate the ratio for our posts against the competitor average\n            our_scores = our_posts['temp_consistency_score']\n            relative_scores = our_scores / competitor_avg_consistency\n            \n            # 5. Assign the calculated feature back using original indices to ensure correct alignment\n            df.loc[our_posts.index, feature_name] = relative_scores\n\n    # Clean up the temporary column\n    df = df.drop(columns=['temp_consistency_score'])\n    \n    # For 'ours' posts that couldn't be scored (e.g., no competitors),\n    # fill with a neutral value of 1.0, assuming they are on par.\n    df[feature_name] = df[feature_name].fillna(1.0)\n\n    # 6. Return the full DataFrame with the new feature column.\n    return df",
  "analysis": {
    "correlation": 0.10142660490691904,
    "p_value": 0.3280633685603432,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T06:12:25.795068",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_semantic_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between post title and body, and compares\n    this cohesion score for 'ours' posts against the average of 'competitor' posts\n    for the same representative query.\n\n    The feature measures if our content's title-body alignment is better or worse\n    than the competition for a given query.\n    \"\"\"\n    # 0. Handle empty DataFrame\n    if df.empty:\n        return df\n\n    model = get_model()\n    \n    # 1. Calculate individual title-body cohesion for all posts\n    # Ensure no NaN values and convert to list for batch processing\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode in batches for efficiency\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate cosine similarity. .diag() gets the similarity between title_i and body_i\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    \n    # Add as a temporary column to the DataFrame for easier grouping\n    # This preserves the original index alignment.\n    df['temp_cohesion_score'] = cohesion_scores.cpu().numpy()\n\n    # 2. Calculate the relative cohesion score against competitors per query\n    feature_name = 'relative_title_body_semantic_cohesion'\n    df[feature_name] = np.nan # Initialize the feature column\n\n    # Group by query to compare 'ours' vs 'competitors' within the same search context\n    # Using .groupby preserves the original DataFrame's index within each group\n    for query, group_df in df.groupby('representative_query'):\n        \n        # Separate 'ours' from 'competitors' using their original indices\n        ours_posts_indices = group_df[group_df['source'] == 'ours'].index\n        competitor_posts_indices = group_df[group_df['source'] == 'competitors'].index\n\n        # Ensure there are competitors to create a benchmark\n        if not competitor_posts_indices.empty:\n            # Calculate the average cohesion score for the competitor group\n            competitor_avg_cohesion = df.loc[competitor_posts_indices, 'temp_cohesion_score'].mean()\n\n            # Avoid division by zero and only proceed if there are 'ours' posts to score\n            if competitor_avg_cohesion > 0 and not ours_posts_indices.empty:\n                # Get the scores for 'ours' posts\n                ours_scores = df.loc[ours_posts_indices, 'temp_cohesion_score']\n                \n                # Calculate the ratio relative to the competitor average\n                relative_score = ours_scores / competitor_avg_cohesion\n                \n                # Assign the calculated relative score back to the main DataFrame\n                # using the preserved indices, which prevents any data misalignment.\n                df.loc[ours_posts_indices, feature_name] = relative_score\n\n    # 3. Clean up and return\n    df.drop(columns=['temp_cohesion_score'], inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T06:14:32.744482",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_semantic_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence-transformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares it to the\n    competitor average for the same representative query.\n\n    The feature measures how well our post's body fulfills the promise of its title,\n    relative to the competition. This approach ensures variance across 'ours' posts\n    by calculating a unique score for each, fixing the issue of a constant feature value.\n    \"\"\"\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n    \n    # Check for empty or invalid DataFrame\n    if df.empty or 'post_title' not in df.columns or 'post_body' not in df.columns or 'source' not in df.columns or 'representative_query' not in df.columns:\n        # Create the column with NaNs if it doesn't exist, to ensure schema consistency\n        if feature_name not in df.columns:\n            df[feature_name] = np.nan\n        return df\n\n    model = get_model()\n\n    # Preserve original index for safe assignment later, preventing misalignment.\n    original_index = df.index\n\n    # Prepare data for encoding\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode titles and bodies in batches for efficiency\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate the cosine similarity between each title and its corresponding body.\n    # .diag() correctly extracts the element-wise similarity: sim(title_i, body_i).\n    absolute_cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # Create a temporary working DataFrame to perform calculations safely.\n    work_df = df[['source', 'representative_query']].copy()\n    work_df['absolute_cohesion'] = absolute_cohesion_scores\n\n    # For each query group, calculate the average cohesion of ONLY the competitors.\n    # This creates a specific benchmark for each query.\n    is_competitor = work_df['source'] == 'competitors'\n    competitor_avg_cohesion_map = work_df[is_competitor].groupby('representative_query')['absolute_cohesion'].mean()\n    work_df['competitor_avg_cohesion'] = work_df['representative_query'].map(competitor_avg_cohesion_map)\n\n    # Calculate the relative cohesion score for 'ours' posts against their group's competitor average.\n    # This creates a variable score for each 'ours' post, solving the logical error.\n    is_ours = work_df['source'] == 'ours'\n    # Denominator must be non-zero and not NaN to prevent division errors.\n    valid_denominator = (work_df['competitor_avg_cohesion'].notna()) & (work_df['competitor_avg_cohesion'] > 0)\n    \n    # The conditions under which the feature can be calculated.\n    calculable_mask = is_ours & valid_denominator\n\n    # Initialize the feature column in the original DataFrame.\n    df[feature_name] = np.nan\n\n    # Calculate and assign the feature value only for the valid rows.\n    relative_cohesion = work_df.loc[calculable_mask, 'absolute_cohesion'] / work_df.loc[calculable_mask, 'competitor_avg_cohesion']\n    df.loc[original_index[calculable_mask], feature_name] = relative_cohesion\n\n    return df"
}{
  "timestamp": "2025-07-22T06:15:41.156220",
  "attempt": 3,
  "status": "success",
  "feature_name": "relative_title_body_semantic_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 동일 검색어에 대한 경쟁자 그룹의 평균 점수보다 높을수록 (즉, 상대적 일관성 비율이 1보다 클수록), 사용자의 검색 의도를 더 명확하게 충족시킬 것으로 예상되어 `non_brand_average_ctr`이 높을 것입니다. 이 피처는 각 포스트의 개별 점수를 그룹 평균과 비교하므로, 그룹 내에서도 분산이 발생하여 유의미한 상관관계 분석이 가능합니다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    global _model\n    if _model is None:\n        # Using a well-regarded multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares it to the competitor average for the same query.\n\n    The logic is as follows:\n    1.  For every post (ours and competitors), calculate a 'cohesion_score' which is the cosine similarity\n        between its title and body embeddings.\n    2.  For each 'representative_query' group, calculate the average cohesion_score of all 'competitor' posts.\n    3.  For each of our posts ('source' == 'ours'), the final feature is its individual 'cohesion_score' divided\n        by the competitor average for its query group.\n    4.  This per-post calculation ensures variance across our posts, even within the same query group,\n        addressing the previous error where all posts received the same value.\n    \"\"\"\n    feature_name = 'relative_title_body_semantic_cohesion'\n\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=np.float64)\n        return df\n\n    model = get_model()\n\n    # Ensure original index is kept for correct final assignment.\n    df_copy = df.copy()\n\n    # 2. Use efficient batch processing for all posts.\n    titles = df_copy['post_title'].fillna('').astype(str).tolist()\n    bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n    # Encode in batches and convert to tensor for similarity calculation.\n    title_embeddings = model.encode(titles, convert_to_tensor=True)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True)\n\n    # 3. Calculate individual cohesion score for every post using the diagonal of the similarity matrix.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n    df_copy['cohesion_score'] = cohesion_scores\n\n    # 4. Calculate the average competitor cohesion for each query group.\n    # We calculate the mean for competitors' scores within each group.\n    competitor_scores = df_copy[df_copy['source'] == 'competitors']\n    if not competitor_scores.empty:\n        competitor_avg_by_query = competitor_scores.groupby('representative_query')['cohesion_score'].mean().rename('competitor_avg_cohesion')\n        # Merge the competitor average back to the main dataframe.\n        df_copy = df_copy.merge(competitor_avg_by_query, on='representative_query', how='left')\n    else:\n        # Handle case with no competitors in the entire dataset.\n        df_copy['competitor_avg_cohesion'] = np.nan\n\n    # 5. Calculate the relative feature ONLY for our posts.\n    # Initialize the feature column with NaN.\n    df[feature_name] = np.nan\n    ours_mask = df_copy['source'] == 'ours'\n\n    # Get the indices of 'ours' posts from the original DataFrame.\n    ours_indices = df.index[ours_mask]\n\n    # Safely calculate the ratio for 'ours' posts.\n    # The .loc on df_copy uses the original index to align data correctly.\n    our_cohesion = df_copy.loc[ours_indices, 'cohesion_score']\n    competitor_avg_cohesion = df_copy.loc[ours_indices, 'competitor_avg_cohesion']\n\n    # The division creates the feature value. np.divide handles division by zero.\n    relative_cohesion = np.divide(our_cohesion, competitor_avg_cohesion, out=np.full_like(our_cohesion, np.nan, dtype=float), where=competitor_avg_cohesion!=0)\n\n    # Assign the calculated values back to the original DataFrame.\n    df.loc[ours_indices, feature_name] = relative_cohesion\n\n    # 6. Handle missing values. If a group had no competitors or competitor avg was 0,\n    # the ratio would be NaN or inf. We fill these with 1.0, implying our post's\n    # cohesion is on par with the (non-existent or zero) average.\n    df[feature_name].replace([np.inf, -np.inf], np.nan, inplace=True)\n    # Only fill NaNs for the rows where the feature is applicable ('ours').\n    df.loc[ours_indices, feature_name] = df.loc[ours_indices, feature_name].fillna(1.0)\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T06:32:09.967500",
  "attempt": 1,
  "status": "success",
  "feature_name": "relative_title_body_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수(코사인 유사도)가 동일 대표 검색어 그룹 내 경쟁 포스트들의 평균 점수보다 높을수록, 사용자가 제목에서 기대한 내용을 본문에서 충족할 확률이 높아져 이탈률이 감소하고 평균 클릭률(non_brand_average_ctr)이 상승할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence-transformer model, loading it only once.\"\"\"\n    global _model\n    if _model is None:\n        # A good multilingual model for general semantic similarity.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and then computes its ratio\n    against the average cohesion of competitors within the same representative query group.\n\n    The feature is defined as:\n    - For 'ours' posts: (Our Cohesion) / (Competitor Average Cohesion)\n    - For 'competitor' posts: NaN (as the feature is relative to them)\n    \"\"\"\n    feature_name = 'relative_title_body_cohesion'\n    df[feature_name] = np.nan\n\n    # 2. Check for empty DataFrame to prevent errors.\n    if df.empty:\n        return df\n\n    try:\n        model = get_model()\n\n        # 3. Preserve original index for safe merging later.\n        # Create a working copy to avoid SettingWithCopyWarning.\n        work_df = df[['post_title', 'post_body', 'source', 'representative_query']].copy()\n\n        # 4. Process data in batches for efficiency.\n        titles = work_df['post_title'].fillna('').astype(str).tolist()\n        bodies = work_df['post_body'].fillna('').astype(str).tolist()\n\n        # Encode all titles and bodies in batches\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # 5. Calculate pairwise cosine similarity (cohesion score) for each post.\n        # .diag() correctly extracts the element-wise similarity between title_i and body_i.\n        cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n        work_df['temp_cohesion'] = cohesion_scores.cpu().numpy()\n\n        # 6. Calculate the average cohesion for competitors within each query group.\n        competitors_only = work_df[work_df['source'] == 'competitor'].copy()\n        if not competitors_only.empty:\n            avg_cohesion_by_query = competitors_only.groupby('representative_query')['temp_cohesion'].mean().rename('competitor_avg_cohesion')\n\n            # 7. Merge the competitor average back to the main working DataFrame.\n            # Use a left merge to ensure all original rows are kept.\n            work_df = work_df.merge(avg_cohesion_by_query, on='representative_query', how='left')\n\n            # 8. Calculate the final relative feature for 'ours' posts only.\n            our_posts_mask = (work_df['source'] == 'ours')\n            \n            # Isolate the relevant series for the calculation\n            our_cohesion = work_df.loc[our_posts_mask, 'temp_cohesion']\n            competitor_avg = work_df.loc[our_posts_mask, 'competitor_avg_cohesion']\n\n            # Calculate the ratio. Replace division by zero or NaN competitor avg with a neutral value of 1.0.\n            # A NaN competitor_avg means the group has no competitors.\n            relative_score = (our_cohesion / competitor_avg).fillna(1.0)\n\n            # 9. Assign the calculated feature back to the original DataFrame using the preserved index.\n            df.loc[work_df.index[our_posts_mask], feature_name] = relative_score\n\n    except Exception as e:\n        # In case of any error (e.g., model loading), fill with a neutral value.\n        print(f\"Error generating {feature_name}: {e}\")\n        df[feature_name] = 1.0\n\n    # 10. Return the original DataFrame with the new feature column.\n    return df\n",
  "analysis": {
    "correlation": 0.10142659609104629,
    "p_value": 0.328063410821786,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T06:56:03.539087",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a pre-trained SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model that performs well with Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and computes its ratio\n    against the average cohesion of competitors within the same query group.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame with columns 'post_title', 'post_body',\n                           'representative_query', and 'source'.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the new feature column 'relative_title_body_cohesion'.\n    \"\"\"\n    # 0. Handle empty DataFrame gracefully.\n    if df.empty:\n        df['relative_title_body_cohesion'] = pd.Series(dtype=float)\n        return df\n\n    feature_name = 'relative_title_body_cohesion'\n    \n    # Initialize the feature column with a neutral value of 1.0.\n    # This ensures that posts without competitors are not penalized.\n    df[feature_name] = 1.0\n\n    try:\n        model = get_model()\n\n        # 2. Prepare data for efficient batch processing.\n        titles = df['post_title'].fillna('').astype(str).tolist()\n        bodies = df['post_body'].fillna('').astype(str).tolist()\n\n        # 3. Encode all titles and bodies in batches.\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # 4. Calculate title-body cohesion for all posts at once.\n        # The diagonal of the cosine similarity matrix gives the similarity of each title\n        # to its corresponding body.\n        cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n        \n        # Add as a temporary column for grouped calculations.\n        df['temp_cohesion'] = cohesion_scores.cpu().numpy()\n\n        # 5. Group by query to perform relational calculation.\n        # Preserving the original index during grouping is crucial.\n        grouped = df.groupby('representative_query')\n\n        for _, group in grouped:\n            # Identify 'ours' and 'competitors' posts within the group.\n            ours_mask = group['source'] == 'ours'\n            competitors_mask = group['source'] == 'competitors'\n            \n            # Get the original DataFrame indices for correct assignment.\n            ours_indices = group.index[ours_mask]\n            competitor_indices = group.index[competitors_mask]\n            \n            # Skip if there are no 'ours' posts or no 'competitors' to compare against.\n            if ours_indices.empty or competitor_indices.empty:\n                continue\n\n            # Calculate the average cohesion for competitors in the group.\n            avg_competitor_cohesion = group.loc[competitor_indices, 'temp_cohesion'].mean()\n            \n            # Avoid division by zero or by NaN.\n            if pd.isna(avg_competitor_cohesion) or avg_competitor_cohesion == 0:\n                # Keep the default neutral value of 1.0 for our posts in this group.\n                continue\n\n            # Get the cohesion score for our post(s).\n            our_cohesion = group.loc[ours_indices, 'temp_cohesion']\n            \n            # Calculate the ratio and assign it back to the main DataFrame.\n            ratio = our_cohesion / avg_competitor_cohesion\n            df.loc[ours_indices, feature_name] = ratio\n\n        # Clean up the temporary column.\n        df = df.drop(columns=['temp_cohesion'])\n\n    except Exception as e:\n        # In case of any error (e.g., model loading), ensure the column exists.\n        print(f\"Error generating feature '{feature_name}': {e}\")\n        if feature_name not in df.columns:\n            df[feature_name] = 1.0 # Default to neutral value on error\n\n    # 6. Return the full DataFrame with the new column.\n    return df\n"
}{
  "timestamp": "2025-07-22T06:57:19.175279",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_semantic_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    global _model\n    if _model is None:\n        # Use a multilingual model suitable for Korean text\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between a post's title and body, and then compares this\n    score to the average cohesion of competitor posts for the same representative query.\n    \n    This corrected version ensures variance by:\n    1. Calculating an individual cohesion score for every single post.\n    2. Calculating a per-query average benchmark from competitors.\n    3. Creating the final feature as a ratio of the individual score to the group benchmark.\n       This results in a unique value for each post, solving the 'constant value' error.\n    \"\"\"\n    # 4. ALWAYS check for empty DataFrames.\n    if df.empty:\n        df['relative_title_body_semantic_cohesion'] = pd.Series(dtype=np.float64)\n        return df\n\n    model = get_model()\n\n    # Preserve original index to ensure correct final assignment\n    original_index = df.index\n\n    # 2. Use efficient batch processing.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode all titles and bodies at once\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate individual cohesion score for EACH post\n    # .diag() correctly pairs the i-th title with the i-th body\n    individual_cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n    # Create a temporary DataFrame for easier group-by operations\n    temp_df = pd.DataFrame({\n        'representative_query': df['representative_query'],\n        'source': df['source'],\n        'cohesion_score': individual_cohesion_scores.cpu().numpy()\n    }, index=original_index)\n\n    # Filter for competitors to create the benchmark\n    competitors_df = temp_df[temp_df['source'] == 'competitors']\n\n    # Calculate the average cohesion score for each competitor query group\n    # This creates a map from query to average score\n    competitor_avg_map = competitors_df.groupby('representative_query')['cohesion_score'].mean()\n\n    # Map the competitor average back to ALL posts based on their query\n    # This provides the relevant benchmark for each post\n    temp_df['competitor_avg_cohesion'] = temp_df['representative_query'].map(competitor_avg_map)\n\n    # Handle cases where a query group might have no competitors (fillna with the global competitor average)\n    global_competitor_avg = competitors_df['cohesion_score'].mean()\n    temp_df['competitor_avg_cohesion'].fillna(global_competitor_avg, inplace=True)\n\n    # Calculate the final feature: the ratio of individual score to the competitor benchmark\n    # Add a small epsilon to prevent division by zero\n    feature_values = temp_df['cohesion_score'] / (temp_df['competitor_avg_cohesion'] + 1e-9)\n\n    # 3. Return the full DataFrame with the new column.\n    df['relative_title_body_semantic_cohesion'] = feature_values\n    \n    return df"
}{
  "timestamp": "2025-07-22T06:58:20.607759",
  "attempt": 3,
  "status": "success",
  "feature_name": "title_body_semantic_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 '제목-본문 의미적 일관성' 점수가 동일 대표 검색어 그룹 내 경쟁 포스트들의 평균 점수보다 높을수록, 즉 해당 비율이 1보다 클수록, 사용자가 제목에서 기대한 바를 본문이 잘 충족시켜 이탈률이 낮아지고 비브랜드 CTR은 높아질 것입니다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean text\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between title and body for each 'ours' post, \n    and normalizes it by the average cohesion of competitor posts within the same query group.\n    This ensures the feature has variance based on individual post performance relative to its specific competitors.\n    \"\"\"\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n    df[feature_name] = np.nan\n\n    # 2. Check for empty DataFrame to prevent errors.\n    if not df.empty:\n        try:\n            model = get_model()\n            \n            # Group by the representative query to create context-specific benchmarks\n            grouped = df.groupby('representative_query')\n\n            for name, group in grouped:\n                # Skip groups too small to have both 'ours' and 'competitor' posts\n                if len(group) < 2:\n                    continue\n\n                # Create boolean masks for 'ours' and 'competitor' posts within the group\n                # .values is used to get a boolean array for tensor indexing\n                is_ours_mask = (group['source'] == 'ours').values\n                is_competitor_mask = (group['source'] == 'competitor').values\n\n                # Ensure both types of posts exist in the group\n                if not np.any(is_ours_mask) or not np.any(is_competitor_mask):\n                    continue\n\n                # 3. Use efficient batch processing for the entire group\n                titles = group['post_title'].fillna('').astype(str).tolist()\n                bodies = group['post_body'].fillna('').astype(str).tolist()\n\n                # Encode titles and bodies into embeddings\n                title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n                body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n                # Calculate cosine similarity for each title-body pair in the group\n                # .diag() extracts the element-wise similarity, resulting in a 1D tensor of cohesion scores\n                cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n                # Calculate the average cohesion for competitor posts\n                competitor_avg_cohesion = cohesion_scores[is_competitor_mask].mean().item()\n\n                # Avoid division by zero or near-zero\n                if competitor_avg_cohesion > 1e-6:\n                    # Get cohesion scores for our posts\n                    our_scores = cohesion_scores[is_ours_mask]\n\n                    # Calculate the feature: each 'ours' post's score relative to the competitor average.\n                    # This is the key correction: it computes a unique value for each 'ours' post.\n                    relative_cohesion = (our_scores / competitor_avg_cohesion).cpu().numpy()\n                    \n                    # Get the original DataFrame indices for the 'ours' posts in this group\n                    our_indices = group.index[is_ours_mask]\n\n                    # 4. Assign the calculated values back to the original DataFrame safely using .loc and original indices\n                    df.loc[our_indices, feature_name] = relative_cohesion\n\n        except Exception as e:\n            print(f\"Error generating {feature_name}: {e}\")\n            # Ensure the column exists even if an error occurs\n            if feature_name not in df.columns:\n                df[feature_name] = np.nan\n\n    # 5. Return the full DataFrame with the new or updated column.\n    return df\n",
  "analysis": {
    "correlation": 0.10142649803131536,
    "p_value": 0.32806388089978455,
    "interpretation": "약한 양의 상관관계(0.1014)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3281)."
  }
}{
  "timestamp": "2025-07-22T07:19:10.508289",
  "attempt": 1,
  "status": "execution_error",
  "error": "코드 실행 실패:\nError during script execution: cannot reindex on an axis with duplicate labels\n",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a SentenceTransformer model, loading it only once.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model is a safe choice for diverse content.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between title and body for our post, \n    and benchmarks it against the average cohesion of competitor posts in the same query group.\n\n    The feature value is the ratio of our post's cohesion to the competitors' average cohesion.\n    \"\"\"\n    FEATURE_NAME = \"relative_title_body_semantic_cohesion\"\n    \n    # 2. Input validation and edge case handling.\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        return pd.DataFrame(columns=list(df.columns) + [FEATURE_NAME]) if isinstance(df, pd.DataFrame) else pd.DataFrame()\n\n    required_columns = ['post_title', 'post_body', 'representative_query', 'source']\n    if not all(col in df.columns for col in required_columns):\n        df[FEATURE_NAME] = 1.0\n        return df\n\n    model = get_model()\n\n    # 3. Work on a copy to avoid modifying the original DataFrame until the final assignment.\n    df_copy = df.copy()\n\n    # 4. Prepare data and generate embeddings in a single batch for efficiency.\n    titles = df_copy['post_title'].fillna('').astype(str).tolist()\n    bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 5. Calculate the pairwise cosine similarity (cohesion) between each title and its body.\n    # .diag() extracts the similarity of title[i] to body[i] from the full similarity matrix.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    df_copy['title_body_cohesion'] = cohesion_scores.cpu().numpy()\n\n    # 6. Calculate the average cohesion for 'competitors' within each query group.\n    competitor_avg_cohesion_map = df_copy[df_copy['source'] == 'competitors'].groupby('representative_query')['title_body_cohesion'].mean()\n\n    # 7. Isolate the cohesion score for the 'ours' post within each query group.\n    # We assume one 'ours' post per group; .first() handles this safely.\n    our_cohesion_map = df_copy[df_copy['source'] == 'ours'].set_index('representative_query')['title_body_cohesion']\n\n    # 8. Create a unified comparison DataFrame indexed by query.\n    comparison_df = pd.DataFrame({\n        'our_cohesion': our_cohesion_map,\n        'competitor_avg_cohesion': competitor_avg_cohesion_map\n    }).reindex(df_copy['representative_query'].unique())\n\n    # 9. Calculate the relative cohesion ratio.\n    # Replace 0 in the denominator with NaN to prevent division by zero errors.\n    denominator = comparison_df['competitor_avg_cohesion'].replace(0, np.nan)\n    comparison_df[FEATURE_NAME] = comparison_df['our_cohesion'] / denominator\n\n    # 10. Map the calculated feature value back to the original DataFrame.\n    # The feature is a property of the query group, so all posts in a group get the same value.\n    feature_map = comparison_df[FEATURE_NAME].to_dict()\n    df[FEATURE_NAME] = df['representative_query'].map(feature_map)\n\n    # 11. Fill NaN values with 1.0, a neutral value indicating parity with competitors.\n    # NaNs can occur if a group has no competitors or no 'ours' post.\n    df[FEATURE_NAME].fillna(1.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T07:20:11.781344",
  "attempt": 2,
  "status": "success",
  "feature_name": "relative_title_body_semantic_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 해당 대표 검색어의 경쟁자 포스트 그룹 평균보다 높을수록, 검색 결과에서 사용자의 기대를 더 잘 충족시켜 더 높은 CTR을 유도할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Lazy-loads and returns the SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Use a versatile multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post relative to its competitors.\n\n    This feature first measures how well a post's body fulfills the promise of its title\n    by calculating the semantic similarity between them. It then compares this cohesion score\n    to the average score of all other competing posts for the same representative query.\n\n    The final feature is a ratio. A value > 1 means the post has better title-body cohesion\n    than its competitors; < 1 means it's worse.\n    \n    This approach uses groupby().transform() to correctly broadcast group-level calculations\n    back to each row, which is the standard and correct way to avoid 'duplicate labels'\n    errors during reindexing.\n    \"\"\"\n    feature_name = 'relative_title_body_semantic_cohesion'\n\n    if not df.empty:\n        # --- Step 1: Calculate Title-Body Cohesion for ALL posts ---\n        model = get_model()\n\n        titles = df['post_title'].fillna('').astype(str).tolist()\n        bodies = df['post_body'].fillna('').astype(str).tolist()\n\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n        df['temp_cohesion'] = cohesion_scores.cpu().numpy()\n\n        # --- Step 2: Calculate the average cohesion of COMPETITORS for each post ---\n        # .transform() calculates a value per group and broadcasts it to all rows in that group,\n        # preserving the original DataFrame's index and shape. This is the key to avoiding the\n        # 'cannot reindex on an axis with duplicate labels' error.\n        group_sum = df.groupby('representative_query')['temp_cohesion'].transform('sum')\n        group_count = df.groupby('representative_query')['temp_cohesion'].transform('count')\n\n        # Calculate the average cohesion of competitors.\n        # The sum of competitors' scores is (group_sum - own_score).\n        # The number of competitors is (group_count - 1).\n        denominator = group_count - 1\n        numerator = group_sum - df['temp_cohesion']\n        \n        # Use np.divide for safe division. Where the denominator is 0 (a group with one post),\n        # the result will be NaN, which is handled later.\n        competitor_avg_cohesion = np.divide(numerator, denominator, out=np.full_like(numerator, np.nan), where=(denominator != 0))\n\n        # --- Step 3: Calculate the final feature as a ratio ---\n        # Ratio of the post's own cohesion to its competitors' average cohesion.\n        # Use np.divide for safe division. Where competitor_avg_cohesion is 0 or NaN, \n        # the result is set to a neutral value of 1.0.\n        final_feature = np.divide(df['temp_cohesion'], competitor_avg_cohesion, out=np.full_like(df['temp_cohesion'], 1.0), where=(competitor_avg_cohesion != 0))\n\n        df[feature_name] = final_feature\n        \n        # Clean up the temporary column\n        df.drop(columns=['temp_cohesion'], inplace=True)\n\n        # Fill any remaining NaNs (e.g., from groups with only one post) with a neutral value of 1.0.\n        df[feature_name].fillna(1.0, inplace=True)\n    else:\n        df[feature_name] = pd.Series(dtype=float)\n\n    return df\n",
  "analysis": {
    "correlation": 0.08292786993843819,
    "p_value": 0.42431467348498525,
    "interpretation": "약한 양의 상관관계(0.0829)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.4243)."
  }
}