{
  "timestamp": "2025-07-22T04:11:22.767028",
  "attempt": 1,
  "status": "execution_error",
  "error": "코드 실행 실패:\n  File \"/Users/min/codes/medilawyer_sales/blog_automation/agents/_temp_feature_generator.py\", line 27\n    \"\"\"\n    ^\nSyntaxError: unterminated triple-quoted string literal (detected at line 105)\n",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. 모델을 전역 변수로 선언하여 반복적인 로딩을 방지합니다 (Lazy-loading).\n_model = None\n\ndef get_model():\n    \"\"\"효율적인 모델 로딩을 위해 싱글턴 패턴을 사용합니다.\"\"\"\n    global _model\n    if _model is None:\n        # 다국어 환경에 적합하고 효율적인 모델을 선택합니다.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    게시물의 제목과 본문 간의 의미적 일관성을 계산하고, \n    이를 경쟁사 그룹의 평균과 비교하여 상대적인 비율 피처를 생성합니다.\n    \"\n    feature_name = 'title_body_consistency_ratio_vs_competitors'\n    # 피처 열을 NaN으로 초기화합니다.\n    df[feature_name] = np.nan\n\n    # 2. 입력 DataFrame이 비어있는 경우, 추가 처리 없이 즉시 반환합니다.\n    if df.empty:\n        return df\n\n    # 원본 인덱스를 보존하여 처리 중 데이터 정렬 오류를 방지합니다.\n    original_index = df.index\n\n    model = get_model()\n\n    # 3. .apply() 대신 리스트 변환 후 배치 처리를 통해 인코딩 성능을 최적화합니다.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 4. 각 게시물의 제목-본문 간 코사인 유사도를 계산합니다.\n    # (N, N) 형태의 유사도 행렬에서 대각선(diagonal)은 각 i번째 제목과 i번째 본문의 유사도를 의미합니다.\n    # 이는 .diag()를 사용하여 효율적으로 추출할 수 있습니다.\n    consistency_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n    # 계산된 텐서를 pandas가 처리할 수 있는 numpy 배열로 변환합니다.\n    df['temp_consistency'] = consistency_scores.cpu().numpy()\n\n    # 5. 'representative_query'별로 경쟁사('competitor')의 평균 일관성 점수를 계산합니다.\n    competitor_avg_consistency = df[df['source'] == 'competitor'].groupby('representative_query')['temp_consistency'].mean()\n\n    # 6. map 함수를 사용하여 계산된 경쟁사 평균 점수를 전체 DataFrame에 효율적으로 매핑합니다.\n    df['temp_competitor_avg'] = df['representative_query'].map(competitor_avg_consistency)\n\n    # 7. 'ours' 포스트에 대해서만 최종 피처(비율)를 계산합니다.\n    is_ours = df['source'] == 'ours'\n    our_consistency = df.loc[is_ours, 'temp_consistency']\n    competitor_avg = df.loc[is_ours, 'temp_competitor_avg']\n\n    # 0으로 나누기 오류 및 NaN 분모를 처리하며 비율을 계산합니다.\n    ratio = our_consistency / competitor_avg\n    \n    # 'ours' 포스트의 해당 위치에만 계산된 비율 값을 할당합니다.\n    df.loc[is_ours, feature_name] = ratio\n\n    # 임시로 사용된 열들을 삭제합니다.\n    df.drop(columns=['temp_consistency', 'temp_competitor_avg'], inplace=True)\n    \n    # 8. 계산 과정에서 발생할 수 있는 무한대 값을 NaN으로 변환합니다.\n    # (예: 경쟁사 평균 점수가 0일 경우)\n    df[feature_name].replace([np.inf, -np.inf], np.nan, inplace=True)\n    \n    # 9. 그룹 내 경쟁사가 없거나 평균 점수가 0이어서 NaN이 된 경우, 우리 포스트와 경쟁사가 동일한 수준(1.0)이라고 가정하여 채웁니다.\n    # 이는 모델링 시 결측치로 인한 문제를 방지하는 안정적인 기본값입니다.\n    df[feature_name].fillna(1.0, inplace=True)\n\n    # 10. 모든 처리가 완료된 전체 DataFrame을 반환합니다.\n    return df"
}{
  "timestamp": "2025-07-22T04:12:24.944442",
  "attempt": 2,
  "status": "success",
  "feature_name": "title_body_consistency_ratio_vs_competitors",
  "hypothesis": "우리 포스트의 제목-본문 간 의미 일관성 점수가 동일 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록, 즉 제목이 제시한 기대치를 본문이 더 잘 충족시킬수록 비브랜드 유입(non_brand_inflow)이 많을 것입니다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton instance of the sentence transformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for Korean content.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of title-body semantic consistency of 'our' posts\n    to the average consistency of 'competitor' posts for the same representative query.\n\n    The feature value is NaN for competitor posts and for 'our' posts in query groups\n    that lack competitors or where the average competitor score is zero.\n    \"\"\"\n    feature_name = 'title_body_consistency_ratio_vs_competitors'\n    df[feature_name] = np.nan  # Initialize feature column in the original DataFrame\n\n    if df.empty:\n        return df\n\n    # Ensure required columns exist to prevent KeyErrors\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_cols):\n        # Return original df if data is malformed\n        return df\n\n    model = get_model()\n\n    # 2. Process data in a batch for efficiency. Avoids slow .apply() loops.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 3. Calculate cosine similarity for each title-body pair and store it.\n    # Using a temporary column in a copy to perform calculations before final assignment.\n    df_work = df.copy()\n    df_work['title_body_consistency'] = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # 4. Calculate the average consistency for competitors within each query group.\n    competitors_df = df_work[df_work['source'] == 'competitor']\n    if competitors_df.empty:\n        return df  # No benchmark possible if no competitors exist.\n\n    competitor_avg_map = competitors_df.groupby('representative_query')['title_body_consistency'].mean()\n\n    # 5. Map the competitor average back to the working DataFrame.\n    df_work['competitor_avg_consistency'] = df_work['representative_query'].map(competitor_avg_map)\n\n    # 6. Calculate the feature ratio, but only for 'our' posts.\n    our_posts_mask = (df_work['source'] == 'ours')\n\n    our_scores = df_work.loc[our_posts_mask, 'title_body_consistency']\n    competitor_avg_scores = df_work.loc[our_posts_mask, 'competitor_avg_consistency']\n\n    # Safely calculate the ratio, np.divide handles division by NaN correctly.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        ratio = np.divide(our_scores, competitor_avg_scores)\n\n    # Replace infinite values (from division by zero) with NaN.\n    ratio[np.isinf(ratio)] = np.nan\n\n    # 7. Assign the calculated feature values back to the original DataFrame.\n    # Using the boolean mask on the original df ensures indices are aligned correctly.\n    df.loc[our_posts_mask, feature_name] = ratio\n\n    return df\n",
  "analysis": {
    "correlation": -0.0649274869354903,
    "p_value": 0.531894042501456,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T04:30:31.179514",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_consistency_ratio_vs_competitors",
  "hypothesis": "우리 포스트의 제목과 본문 간 의미적 일관성 점수가 해당 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록(즉, 비율이 1보다 클수록) 비브랜드 유입량이 증가할 것이다. 이는 제목이 제시한 주제를 본문에서 충실하게 다루는 것이 사용자 만족도를 높여 검색 엔진에서 긍정적인 평가를 받는다는 것을 의미한다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of each post's title-body semantic consistency to the average\n    consistency of competitor posts within the same representative query group.\n    \"\"\"\n    feature_name = 'title_body_consistency_ratio_vs_competitors'\n    \n    # Handle empty DataFrame by returning it with the feature column filled with NaNs.\n    if df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # Ensure required columns are present to prevent KeyErrors.\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_cols):\n        df[feature_name] = np.nan\n        return df\n\n    model = get_model()\n\n    # 2. Prepare data for efficient batch processing.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 3. Generate embeddings for all titles and bodies.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 4. Calculate a 'consistency score' for each post by finding the cosine similarity\n    #    between its own title and body. The .diag() method correctly extracts these\n    #    pairwise similarities from the full similarity matrix.\n    #    .cpu() is added for safety in environments where the model might run on a GPU.\n    consistency_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n    df['temp_consistency_score'] = consistency_scores\n\n    # 5. Calculate the average consistency score for 'competitor' posts within each group.\n    #    Using .loc with a boolean mask is a safe way to select the competitor subset.\n    is_competitor = df['source'] == 'competitor'\n    competitor_avg_map = df.loc[is_competitor].groupby('representative_query')['temp_consistency_score'].mean()\n\n    # 6. Map the calculated competitor average back to all posts in the DataFrame based on their query.\n    #    This operation correctly aligns data using the DataFrame's index.\n    df['competitor_avg_score'] = df['representative_query'].map(competitor_avg_map)\n\n    # 7. Calculate the final feature ratio.\n    #    Handle division-by-zero by replacing zeros in the denominator with NaN,\n    #    which results in a NaN ratio, correctly indicating an undefined value.\n    denominator = df['competitor_avg_score'].replace(0, np.nan)\n    df[feature_name] = df['temp_consistency_score'] / denominator\n\n    # 8. Clean up temporary helper columns.\n    df.drop(columns=['temp_consistency_score', 'competitor_avg_score'], inplace=True)\n\n    return df",
  "analysis": {
    "correlation": -0.0649274791840481,
    "p_value": 0.531894091583092,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T04:49:29.728200",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 제목과 본문 간의 의미적 일관성 점수가 해당 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록, 즉 제목이 제시한 주제를 본문에서 더 충실하게 다룰수록 비브랜드 유입(non_brand_inflow)이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence transformer model.\"\"\"\n    global _model\n    if _model is None:\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares it to the competitor average.\n\n    The feature is the ratio of 'our' post's cohesion score to the average cohesion score of\n    all competitors sharing the same 'representative_query'.\n    \"\"\"\n    # 2. Check for empty DataFrame to avoid errors.\n    if df.empty:\n        df['title_body_cohesion_vs_competitors'] = pd.Series(dtype=float)\n        return df\n\n    model = get_model()\n\n    # Preserve the original index to ensure correct assignment later.\n    original_index = df.index\n\n    # 3. Prepare data for efficient batch processing.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 4. Encode all titles and bodies in a single batch operation.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 5. Calculate the title-body semantic similarity for every post.\n    # The .diag() method correctly extracts the pair-wise similarity (title_i vs. body_i).\n    consistency_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().tolist()\n\n    # Use a temporary DataFrame to hold intermediate results.\n    temp_df = pd.DataFrame({\n        'consistency_score': consistency_scores,\n        'source': df['source'],\n        'representative_query': df['representative_query']\n    }, index=original_index)\n\n    # 6. Calculate the average consistency score for 'competitor' posts per query group.\n    competitors = temp_df[temp_df['source'] == 'competitor']\n\n    if not competitors.empty:\n        competitor_avg_scores = competitors.groupby('representative_query')['consistency_score'].mean()\n\n        # 7. Map the competitor average back to each post in its group.\n        temp_df['competitor_avg_score'] = temp_df['representative_query'].map(competitor_avg_scores)\n\n        # 8. Calculate the final ratio for 'ours' posts.\n        ours_mask = temp_df['source'] == 'ours'\n        our_scores = temp_df.loc[ours_mask, 'consistency_score']\n        competitor_scores = temp_df.loc[ours_mask, 'competitor_avg_score']\n\n        # Use np.divide for safe division, handle division by zero and NaNs.\n        # A ratio of 1.0 is neutral (equal to competitor average).\n        with np.errstate(divide='ignore', invalid='ignore'):\n            ratios = np.divide(our_scores, competitor_scores)\n        \n        # Replace inf (from division by zero) and NaN (from missing competitor group) with 1.0.\n        ratios = ratios.replace([np.inf, -np.inf], 1.0).fillna(1.0)\n\n        # Assign the calculated ratios to the final feature column.\n        df['title_body_cohesion_vs_competitors'] = ratios\n        # Ensure non-'ours' posts have a neutral value (NaN or 1.0). Let's use NaN.\n        df['title_body_cohesion_vs_competitors'] = df['title_body_cohesion_vs_competitors'].where(ours_mask)\n    else:\n        # If there are no competitors in the entire dataset, the ratio is undefined.\n        # Set to a neutral value (NaN for 'ours', as no comparison is possible).\n        df['title_body_cohesion_vs_competitors'] = np.nan\n\n    return df",
  "analysis": {
    "correlation": -0.06492749157608177,
    "p_value": 0.5318940131175294,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T05:09:31.880456",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 해당 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록, 즉 제목이 암시한 내용을 본문이 더 충실하게 설명할수록 비브랜드 유입(non_brand_inflow)이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Lazily initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # This model is a good multilingual choice for semantic similarity.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic consistency between post title and body, and compares\n    this score against the average score of the competitor group for the same query.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame with columns 'post_title', 'post_body',\n                           'source', and 'representative_query'.\n\n    Returns:\n        pd.DataFrame: The original DataFrame with the new feature column\n                      'title_body_cohesion_vs_competitors' added.\n    \"\"\"\n    feature_name = 'title_body_cohesion_vs_competitors'\n    \n    # 4. ALWAYS check for empty DataFrames to prevent errors.\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    model = get_model()\n\n    # Preserve the original index to ensure correct assignment of the new feature.\n    # This prevents misalignment if the DataFrame's order is changed during processing.\n    original_index = df.index\n\n    # 2. Use efficient batch processing by converting columns to lists.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode all titles and bodies in a single, efficient batch call.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate the cosine similarity for each (title, body) pair.\n    # .diag() correctly extracts the similarity between title_i and body_i from the full NxN matrix.\n    consistencies = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # Create a temporary working DataFrame to organize calculations.\n    work_df = pd.DataFrame({\n        'representative_query': df['representative_query'],\n        'source': df['source'],\n        'consistency': consistencies\n    }, index=original_index)\n\n    # Calculate the average consistency ONLY for competitors, grouped by their query.\n    # This creates a Series mapping each query to its competitor benchmark.\n    competitor_avg_consistency = work_df[work_df['source'] == 'competitor'].groupby('representative_query')['consistency'].mean()\n\n    # Map the calculated competitor average back to each row in the working DataFrame.\n    # Rows in groups without any competitors will get a NaN value.\n    work_df['competitor_avg'] = work_df['representative_query'].map(competitor_avg_consistency)\n\n    # Calculate the final ratio: each post's consistency score divided by its group's competitor average.\n    # Using np.divide is safer as it handles division by zero or NaN gracefully.\n    ratios = np.divide(\n        work_df['consistency'].to_numpy(), \n        work_df['competitor_avg'].to_numpy(), \n        out=np.full_like(work_df['consistency'], 1.0, dtype=float), # Default to a neutral 1.0 if division fails.\n        where=(work_df['competitor_avg'].notna() & (work_df['competitor_avg'] != 0))\n    )\n\n    # 3. Return the full DataFrame with the new column.\n    # Assign the final feature values back to the original DataFrame using the preserved index.\n    df[feature_name] = pd.Series(ratios, index=original_index)\n    \n    # Ensure any remaining NaNs (e.g., from groups with no competitors) are filled.\n    df[feature_name].fillna(1.0, inplace=True)\n\n    return df",
  "analysis": {
    "correlation": -0.0649274869354903,
    "p_value": 0.531894042501456,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T05:34:58.743747",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_consistency_ratio_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    global _model\n    if _model is None:\n        # Using a well-regarded multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of title-body semantic consistency for each post\n    compared to the average consistency of 'competitors' posts for the same representative query.\n\n    The consistency is measured as the cosine similarity between the title and body embeddings.\n    \"\"\"\n    feature_name = 'title_body_consistency_ratio_vs_competitors'\n    \n    # Always check for an empty DataFrame.\n    if not df.empty:\n        # Initialize the feature column with a default neutral value.\n        df[feature_name] = 1.0\n\n        model = get_model()\n\n        # Prepare data for batch processing, handling potential nulls.\n        titles = df['post_title'].fillna('').astype(str).tolist()\n        bodies = df['post_body'].fillna('').astype(str).tolist()\n\n        # 2. Encode all titles and bodies in efficient batches.\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # 3. Calculate the cosine similarity for each (title_i, body_i) pair.\n        # The .diag() call correctly extracts the similarity of title_i to body_i from the NxN matrix.\n        consistency_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n        # Use a temporary column to hold individual consistency scores. Preserves original index.\n        df['temp_consistency'] = consistency_scores.cpu().tolist()\n\n        # 4. Calculate the average consistency score for competitors within each query group.\n        competitors_df = df[df['source'] == 'competitors']\n        \n        if not competitors_df.empty:\n            # Create a map from representative_query to the mean consistency score of competitors.\n            # This is more efficient than a groupby().transform() on the whole dataframe.\n            competitor_avg_map = competitors_df.groupby('representative_query')['temp_consistency'].mean()\n\n            # Map the competitor average scores back to the original DataFrame.\n            # Rows for queries without competitors will get NaN, which is handled later.\n            df['competitor_avg_consistency'] = df['representative_query'].map(competitor_avg_map)\n\n            # 5. Calculate the final feature ratio.\n            # This compares each post's consistency to its query group's competitor average.\n            # Use .loc to ensure assignment aligns correctly and avoid SettingWithCopyWarning.\n            df.loc[:, feature_name] = df['temp_consistency'] / df['competitor_avg_consistency']\n\n            # 6. Clean up results.\n            # Replace infinite values (from division by zero) and NaNs with 1.0.\n            # A value of 1.0 implies the post's consistency is equal to the competitor average,\n            # a neutral and safe default for cases with no competitors or zero-score competitors.\n            df[feature_name] = df[feature_name].replace([np.inf, -np.inf], np.nan).fillna(1.0)\n            \n            # Drop the temporary calculation column.\n            df.drop(columns=['competitor_avg_consistency'], inplace=True)\n\n        # Drop the temporary consistency score column. `errors='ignore'` is safe if the column was never created.\n        df.drop(columns=['temp_consistency'], inplace=True, errors='ignore')\n\n    return df"
}{
  "timestamp": "2025-07-22T05:35:50.365488",
  "attempt": 2,
  "status": "success",
  "feature_name": "relative_title_body_semantic_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 동일 대표 검색어에 대한 경쟁사 그룹의 평균 점수보다 높을수록, 제목이 제시한 사용자 기대를 본문이 더 잘 충족시켜 비브랜드 유입에 긍정적인 영향을 미칠 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a well-regarded multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares it to the competitor average \n    for the same representative query.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame containing post data.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the new feature column 'relative_title_body_semantic_cohesion'.\n    \"\"\"\n    feature_name = 'relative_title_body_semantic_cohesion'\n\n    # 0. Handle empty DataFrame\n    if not df.empty:\n        # Ensure the feature column exists with a default value (NaN)\n        df[feature_name] = np.nan\n    else:\n        # If df is empty, return it with the empty column\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    model = get_model()\n\n    # 1. Prepare data for batch processing, handling potential NaN values.\n    # The original index is preserved throughout the process.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # 2. Generate embeddings for all titles and bodies in efficient batches.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 3. Calculate the semantic cohesion (cosine similarity) for each post individually.\n    # .diag() extracts the similarity of title[i] to body[i] for all i.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n    \n    # Create a temporary column to hold these scores. This avoids modifying the original df in place inside a loop.\n    temp_df = df[['source', 'representative_query']].copy()\n    temp_df['title_body_cohesion'] = cohesion_scores\n\n    # 4. Calculate the average cohesion score for competitors, grouped by representative_query.\n    # This is the crucial step to create a per-query benchmark.\n    competitor_scores = temp_df[temp_df['source'] == 'competitor']\n    \n    # The groupby operation correctly handles cases with no competitors for a query.\n    competitor_avg_cohesion = competitor_scores.groupby('representative_query')['title_body_cohesion'].mean().rename('competitor_avg_cohesion')\n\n    # 5. Merge the competitor average back into the temporary DataFrame.\n    # This aligns each post with its corresponding competitor benchmark.\n    temp_df = temp_df.merge(competitor_avg_cohesion, on='representative_query', how='left')\n\n    # 6. Calculate the final ratio for 'ours' posts.\n    # The ratio measures our post's cohesion relative to the competitor average.\n    our_posts_mask = temp_df['source'] == 'ours'\n    our_scores = temp_df.loc[our_posts_mask, 'title_body_cohesion']\n    competitor_avg_scores = temp_df.loc[our_posts_mask, 'competitor_avg_cohesion']\n\n    # Handle division by zero or cases where no competitors exist (competitor_avg_scores is NaN).\n    # If competitor average is 0 or NaN, the ratio is defined as 1.0 (neutral).\n    # This ensures that our posts without competitor data are not penalized and a value is still generated.\n    relative_cohesion = our_scores.div(competitor_avg_scores).fillna(1.0).replace(np.inf, 1.0)\n\n    # 7. Assign the calculated feature values to the original DataFrame using its index.\n    # This is a safe assignment that respects the original DataFrame's structure.\n    df.loc[our_posts_mask, feature_name] = relative_cohesion\n\n    return df\n",
  "analysis": {
    "correlation": -0.0649274869354903,
    "p_value": 0.531894042501456,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T05:51:07.894656",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_semantic_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    global _model\n    if _model is None:\n        # Use a powerful, multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between a post's title and body,\n    and then computes the ratio of this score for 'our' post against the\n    average score of 'competitor' posts within the same representative query group.\n\n    - Step 1: Encode all titles and bodies into semantic vectors.\n    - Step 2: Calculate the cosine similarity for each title-body pair (individual cohesion score).\n    - Step 3: For each 'representative_query' group, find the 'ours' cohesion score.\n    - Step 4: For each group, calculate the average cohesion score of all 'competitors'.\n    - Step 5: Compute the ratio of 'our' score to the 'competitor' average.\n    - Step 6: Assign this ratio to all posts in the group.\n    \"\"\"\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n\n    if df.empty or 'post_title' not in df.columns or 'post_body' not in df.columns:\n        df[feature_name] = np.nan\n        return df\n\n    # Use a copy to avoid potential SettingWithCopyWarning while ensuring the original df is modified at the end.\n    df_copy = df.copy()\n\n    model = get_model()\n\n    # Step 1 & 2: Batch process embeddings and calculate individual cohesion scores.\n    titles = df_copy['post_title'].fillna('').astype(str).tolist()\n    bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate similarity between each title[i] and body[i].\n    # .diag() extracts the element-wise similarities.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n    df_copy['_temp_cohesion'] = cohesion_scores\n\n    # Step 3, 4, & 5: Use groupby().transform() for efficient, index-aligned group calculations.\n    \n    # Create a Series with cohesion scores only for 'ours' posts, others are NaN.\n    our_cohesion = df_copy.where(df_copy['source'] == 'ours')['_temp_cohesion']\n    \n    # Create a Series with cohesion scores only for 'competitors' posts, others are NaN.\n    competitor_cohesion = df_copy.where(df_copy['source'] == 'competitors')['_temp_cohesion']\n\n    # For each group, get the single 'our' score and broadcast it to all members of the group.\n    # 'first' correctly handles this since there is only one 'ours' per group.\n    our_score_per_group = our_cohesion.groupby(df_copy['representative_query']).transform('first')\n\n    # For each group, calculate the mean competitor score and broadcast it.\n    competitor_avg_per_group = competitor_cohesion.groupby(df_copy['representative_query']).transform('mean')\n\n    # Step 6: Compute the final ratio. Adding epsilon prevents division by zero.\n    # This operation correctly propagates NaNs for groups missing 'ours' or 'competitors'.\n    ratio = our_score_per_group / (competitor_avg_per_group + 1e-9)\n    \n    # Assign the calculated feature back to the original DataFrame.\n    df[feature_name] = ratio\n    \n    return df"
}{
  "timestamp": "2025-07-22T05:53:34.491931",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_semantic_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\nimport sys\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence transformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a powerful multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between title and body for each post,\n    and then computes the ratio of this cohesion for 'ours' posts against the\n    average cohesion of 'competitors' for the same representative query.\n    This corrected version ensures variance by performing calculations per query group.\n    \"\"\"\n    # 2. Check for empty DataFrame to prevent errors.\n    if not df.empty:\n        pass\n    else:\n        df['relative_title_body_semantic_cohesion'] = pd.Series(dtype=float)\n        return df\n\n    # 3. Ensure necessary columns exist.\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    for col in required_cols:\n        if col not in df.columns:\n            # Initialize the column with a default value if it doesn't exist, to prevent crashes.\n            df[col] = '' if col != 'source' else 'competitors'\n\n    model = get_model()\n    \n    # IMPORTANT: Preserve original index to ensure correct final assignment.\n    original_index = df.index\n\n    # 4. Batch process embeddings for efficiency.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 5. Calculate individual title-body cohesion for every post.\n    # .diag() efficiently gets the element-wise similarity for corresponding pairs.\n    all_cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    \n    # Use a temporary DataFrame to hold intermediate calculations, aligned by original index.\n    temp_df = pd.DataFrame({\n        'temp_cohesion': all_cohesion_scores.cpu().numpy(),\n        'source': df['source'].values,\n        'representative_query': df['representative_query'].values\n    }, index=original_index)\n\n    # 6. Calculate the average cohesion for competitors within each query group.\n    competitors_df = temp_df[temp_df['source'] == 'competitors']\n    \n    # Group by query and calculate the mean cohesion. This creates a Series\n    # where the index is 'representative_query' and the value is the avg score.\n    competitor_avg_cohesion_by_query = competitors_df.groupby('representative_query')['temp_cohesion'].mean()\n\n    # 7. Map the competitor average back to each row in the temp DataFrame based on its query.\n    # This assigns the correct competitor benchmark to each post.\n    temp_df['competitor_avg_cohesion'] = temp_df['representative_query'].map(competitor_avg_cohesion_by_query)\n    \n    # 8. Calculate the final feature: the ratio of 'our' post's cohesion to its competitors' average.\n    is_ours = (temp_df['source'] == 'ours')\n    our_rows = temp_df[is_ours]\n\n    # Calculate the ratio. This will naturally vary per 'ours' post as long as their\n    # individual cohesion or their competitor group's average cohesion varies.\n    our_ratio = our_rows['temp_cohesion'] / our_rows['competitor_avg_cohesion']\n    \n    # Initialize the final column in the original DataFrame with a default value.\n    df['relative_title_body_semantic_cohesion'] = 1.0\n    \n    # Assign the calculated ratios to the 'ours' rows in the original DataFrame.\n    # This correctly aligns the results using the preserved index.\n    df.loc[is_ours, 'relative_title_body_semantic_cohesion'] = our_ratio\n    \n    # Handle cases where there are no competitors for a query (resulting in NaN) or where the\n    # competitor average is zero (resulting in inf). A ratio of 1.0 is a neutral default.\n    df['relative_title_body_semantic_cohesion'].fillna(1.0, inplace=True)\n    df['relative_title_body_semantic_cohesion'].replace([np.inf, -np.inf], 1.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:55:18.089362",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_cohesion_zscore'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\nimport sys\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Lazy-loads and returns the SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a standard multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion Z-score for 'ours' posts relative to competitors.\n\n    This feature first computes a 'cohesion score' (cosine similarity) between the title and body\n    for every post. Then, for each 'representative_query', it benchmarks the cohesion score of\n    'our' post against the distribution (mean and std dev) of scores from competitor posts.\n    The resulting Z-score represents how many standard deviations our post's cohesion is from\n    the competitor average. A positive Z-score indicates above-average cohesion, which is hypothesized\n    to correlate with higher user satisfaction and non-brand inflow.\n    This Z-score approach creates more variance than a simple ratio, solving the issue of the\n    previous attempt where the feature value was constant.\n    \"\"\"\n    feature_name = 'relative_title_body_cohesion_zscore'\n\n    # Initialize the feature column with a neutral default value (0).\n    df[feature_name] = 0.0\n\n    if df.empty:\n        return df\n\n    model = get_model()\n\n    # Prepare text data, handling potential NaN values.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode all titles and bodies efficiently in batches.\n    try:\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n    except Exception as e:\n        # In case of a model error, return the dataframe with the default feature value.\n        # This prevents a crash in the pipeline.\n        print(f\"Error during model encoding: {e}\", file=sys.stderr)\n        return df\n\n    # Calculate cosine similarity for each (title, body) pair.\n    # .diag() correctly and efficiently extracts the similarity of title_i to body_i.\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag().cpu().numpy()\n\n    # Use a temporary DataFrame for calculations to avoid chain assignment issues.\n    # This is safer than adding a column to the original df while iterating.\n    df_temp = df[['source', 'representative_query']].copy()\n    df_temp['cohesion_score'] = cohesion_scores\n\n    # Group by the representative query to create per-query benchmarks.\n    grouped = df_temp.groupby('representative_query')\n\n    # Store results to perform a single, safe update to the original DataFrame.\n    z_scores_to_assign = {}\n\n    for name, group in grouped:\n        our_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitors']\n\n        # Proceed only if we have our post(s) and competitors to compare against.\n        if not our_posts.empty and not competitor_posts.empty:\n            our_scores = our_posts['cohesion_score']\n            competitor_scores = competitor_posts['cohesion_score']\n\n            # Calculate the benchmark (mean and std dev) from competitor scores.\n            comp_mean = competitor_scores.mean()\n            comp_std = competitor_scores.std()\n\n            # Calculate Z-score. Handle the case where standard deviation is zero\n            # (all competitors have the same score) to prevent division by zero.\n            if comp_std > 1e-6: # Use a small epsilon for float precision.\n                z_scores = (our_scores - comp_mean) / comp_std\n            else:\n                # If std is 0, a Z-score is undefined. A value of 0 indicates\n                # our post is exactly at the (uniform) competitor mean.\n                z_scores = pd.Series(0.0, index=our_scores.index)\n\n            # Store the calculated Z-scores with their original indices.\n            for idx, score in z_scores.items():\n                z_scores_to_assign[idx] = score\n\n    # Safely assign the calculated values back to the original DataFrame if any were computed.\n    if z_scores_to_assign:\n        # Create a Series from the dictionary to align indices automatically.\n        final_scores = pd.Series(z_scores_to_assign)\n        df.loc[final_scores.index, feature_name] = final_scores\n\n    return df"
}{
  "timestamp": "2025-07-22T05:56:51.781683",
  "attempt": 4,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_title_body_semantic_cohesion'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\nimport sys\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a powerful multilingual model suitable for Korean text.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between post title and body, and benchmarks\n    'ours' posts against the average cohesion of competitor posts for the same query.\n\n    The final feature is a ratio: (our_cohesion / competitor_average_cohesion).\n    This fixes the previous issue where a z-score calculation resulted in a constant\n    value due to flawed group-wise application.\n    \"\"\"\n    # Ensure the script can run in an environment where stdout encoding is not guaranteed to be UTF-8\n    if sys.stdout.encoding != 'UTF-8':\n        sys.stdout.reconfigure(encoding='utf-8')\n\n    # Check for empty DataFrame to avoid errors on empty input\n    if df.empty:\n        df['relative_title_body_semantic_cohesion'] = pd.NA\n        return df\n\n    # Preserve the original index to ensure correct feature assignment at the end\n    original_index = df.index\n\n    model = get_model()\n\n    # Prepare text data for batch processing, handling potential missing values\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Efficiently encode all titles and bodies in batches\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate cosine similarity between each title and its corresponding body\n    # .diag() extracts the element-wise similarity, giving a score for each post\n    df['title_body_cohesion'] = util.cos_sim(title_embeddings, body_embeddings).diag().tolist()\n\n    # --- BENCHMARKING LOGIC ---\n    # This section is redesigned to be robust and avoid the constant-value error.\n\n    # 1. Calculate the average cohesion score for competitors within each query group.\n    # We select only competitors, group by query, calculate the mean, and name the resulting Series.\n    competitor_avg_cohesion = df.loc[df['source'] == 'competitors'].groupby('representative_query')['title_body_cohesion'].mean().rename('competitor_avg_cohesion')\n\n    # 2. Safely merge the calculated competitor averages back into the main DataFrame.\n    # This maps the correct benchmark value to every post based on its query.\n    # 'how='left'' ensures we don't lose any of the original rows.\n    df = df.merge(competitor_avg_cohesion, on='representative_query', how='left')\n\n    # Ensure the index is restored to its original state after the merge\n    df.index = original_index\n\n    # 3. Calculate the relative feature for 'ours' posts.\n    # The feature is the ratio of our post's cohesion to the competitor average.\n    # Initialize the column with a neutral value (1.0) for all posts.\n    df['relative_title_body_semantic_cohesion'] = 1.0\n\n    our_posts_mask = df['source'] == 'ours'\n    # Use a small epsilon to prevent division by zero if competitor average is 0.\n    competitor_avg = df.loc[our_posts_mask, 'competitor_avg_cohesion']\n    our_cohesion = df.loc[our_posts_mask, 'title_body_cohesion']\n\n    relative_score = our_cohesion / (competitor_avg + 1e-9)\n\n    # Assign the calculated ratio to 'ours' posts. Fill NaNs (for groups with no competitors)\n    # with the neutral value of 1.0, implying parity.\n    df.loc[our_posts_mask, 'relative_title_body_semantic_cohesion'] = relative_score.fillna(1.0)\n\n    # Clean up intermediate columns before returning the result\n    df = df.drop(columns=['title_body_cohesion', 'competitor_avg_cohesion'])\n\n    return df\n"
}{
  "timestamp": "2025-07-22T05:57:49.156749",
  "attempt": 5,
  "status": "success",
  "feature_name": "relative_title_body_cohesion",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 동일 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록, 사용자에게 더 명확하고 만족스러운 콘텐츠 경험을 제공하여 비브랜드 유입률이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton model instance.\"\"\"\n    global _model\n    if _model is None:\n        # Using a model optimized for Korean language tasks.\n        _model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and then computes a relative\n    score for 'ours' posts against the competitor average for the same representative query.\n    This directly addresses the previous error by ensuring the calculation is performed per-group,\n    thus creating variance in the final feature values across different query groups.\n    \"\"\"\n    feature_name = 'relative_title_body_cohesion'\n    \n    # Always check for empty DataFrame to prevent errors.\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # Ensure required columns exist for the logic to run.\n    required_cols = ['post_title', 'post_body', 'source', 'representative_query']\n    if not all(col in df.columns for col in required_cols):\n        df[feature_name] = np.nan\n        return df\n\n    model = get_model()\n\n    # Create a working copy to avoid SettingWithCopyWarning.\n    df_copy = df.copy()\n\n    # Pre-process text data, handling NaNs, and convert to list for batch processing.\n    titles = df_copy['post_title'].fillna('').astype(str).tolist()\n    bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n    # Encode in batches for efficiency. This is much faster than .apply().\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate the semantic cohesion for each post between its title and body.\n    # .diag() correctly selects the pairwise similarity: [sim(title_0, body_0), sim(title_1, body_1), ...]\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    \n    # Add this intermediate score to the DataFrame for easier grouping.\n    df_copy['cohesion_score'] = cohesion_scores.cpu().tolist()\n\n    # Use groupby().transform() for an efficient, vectorized calculation of the competitor average.\n    # This is the key fix: it avoids manual iteration and correctly broadcasts the group-specific\n    # average back to each row within its group, preserving the original index and creating variance.\n    \n    # Create a temporary series of cohesion scores for competitors only.\n    competitor_cohesion = df_copy['cohesion_score'].where(df_copy['source'] == 'competitor')\n    \n    # Group by query and calculate the average competitor cohesion for each group.\n    # .transform('mean') broadcasts the group's mean value to all members of that group.\n    competitor_avg_cohesion = competitor_cohesion.groupby(df_copy['representative_query']).transform('mean')\n    \n    # Calculate the relative cohesion score for 'ours' posts.\n    # Formula: (our_cohesion) / (competitor_avg_for_that_query)\n    # .where() ensures this calculation is only performed for rows where source is 'ours'.\n    relative_scores = df_copy['cohesion_score'].where(df_copy['source'] == 'ours') / (competitor_avg_cohesion + 1e-9)\n\n    # Assign the calculated scores to the final feature column in the original DataFrame.\n    # This ensures correct index alignment.\n    df[feature_name] = relative_scores\n    \n    # A ratio of 1.0 implies parity. This is a sensible default for competitors themselves\n    # and for 'ours' posts that might not have any competitors in their group.\n    df[feature_name].fillna(1.0, inplace=True)\n\n    return df",
  "analysis": {
    "correlation": -0.15820549911639603,
    "p_value": 0.12570914103837066,
    "interpretation": "약한 음의 상관관계(-0.1582)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.1257)."
  }
}{
  "timestamp": "2025-07-22T06:09:36.999829",
  "attempt": 1,
  "status": "success",
  "feature_name": "relative_title_body_semantic_cohesion",
  "hypothesis": "우리 포스트의 제목과 본문 간의 의미적 일관성 점수가 해당 대표 검색어의 경쟁자 그룹 평균 점수보다 높을수록 (즉, 비율이 1보다 클수록) 비브랜드 유입률이 높을 것이다. 이는 제목에서 제시한 약속을 본문이 충실히 이행하는 구조적 완성도가 높은 콘텐츠가 사용자의 검색 의도를 더 잘 만족시키기 때문이다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a powerful, multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between title and body for each post,\n    and then computes its ratio relative to the competitor average for the same query.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame with columns 'post_title', 'post_body',\n                           'source', and 'representative_query'.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the new feature column 'relative_title_body_semantic_cohesion'.\n    \"\"\"\n    # 2. Always check for an empty DataFrame to prevent errors.\n    if not df.empty:\n        # Ensure the original index is preserved for correct final assignment.\n        df_copy = df.copy()\n\n        model = get_model()\n\n        # 3. Use efficient batch processing for embeddings.\n        titles = df_copy['post_title'].fillna('').astype(str).tolist()\n        bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # Calculate pairwise cosine similarity for each title-body pair.\n        # .diag() efficiently extracts the similarity of title_i with body_i.\n        df_copy['title_body_cohesion'] = util.cos_sim(title_embeddings, body_embeddings).diag().tolist()\n\n        # Create a mapping of competitor average cohesion per query.\n        # This is more efficient than a groupby().apply().\n        competitors = df_copy[df_copy['source'] == 'competitor']\n        competitor_avg_cohesion_map = competitors.groupby('representative_query')['title_body_cohesion'].mean()\n\n        # Map the competitor average to all posts based on their query.\n        df_copy['competitor_avg_cohesion'] = df_copy['representative_query'].map(competitor_avg_cohesion_map)\n\n        # Handle cases where competitor average might be 0 to avoid division errors.\n        df_copy['competitor_avg_cohesion'].replace(0, np.nan, inplace=True)\n\n        # Calculate the relative cohesion.\n        # The result will be NaN for posts in groups with no competitors or where avg is 0.\n        df['relative_title_body_semantic_cohesion'] = df_copy['title_body_cohesion'] / df_copy['competitor_avg_cohesion']\n\n        # For groups without competitors, the comparison is meaningless.\n        # A value of 1.0 implies parity, a safe default.\n        df['relative_title_body_semantic_cohesion'].fillna(1.0, inplace=True)\n\n    # If the DataFrame was empty, it will be returned unmodified.\n    return df",
  "analysis": {
    "correlation": -0.06492749157608177,
    "p_value": 0.5318940131175294,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T06:30:00.311660",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'title_body_semantic_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns a singleton SentenceTransformer model instance.\"\"\"\n    global _model\n    if _model is None:\n        # Using a multilingual model is a safe choice for diverse content.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between title and body for each post,\n    and then computes the ratio of this score for each post against the\n    average score of 'competitors' within the same representative query group.\n\n    Args:\n        df: DataFrame containing post data with columns 'post_title',\n            'post_body', 'source', and 'representative_query'.\n\n    Returns:\n        The original DataFrame with a new feature column\n        'title_body_semantic_cohesion_vs_competitors'.\n    \"\"\"\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n\n    # Always check for an empty DataFrame to prevent errors.\n    if not df.empty:\n        # Ensure the output column exists even if processing fails.\n        if feature_name not in df.columns:\n            df[feature_name] = np.nan\n\n        # Create a working copy to avoid SettingWithCopyWarning while preserving original index\n        df_copy = df.copy()\n\n        model = get_model()\n\n        # Prepare text data for efficient batch processing\n        titles = df_copy['post_title'].fillna('').astype(str).tolist()\n        bodies = df_copy['post_body'].fillna('').astype(str).tolist()\n\n        # Encode titles and bodies into semantic vectors in batches\n        title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n        # Calculate the cosine similarity between each title and its corresponding body\n        # .diag() extracts the element-wise similarity scores [sim(t1,b1), sim(t2,b2), ...]\n        cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n        df_copy['title_body_cohesion'] = cohesion_scores.cpu().numpy()\n\n        # Calculate the average cohesion score for competitors within each query group\n        competitor_rows = df_copy['source'] == 'competitors'\n        \n        # This correctly calculates the mean for each group and prepares it for mapping\n        competitor_avg_map = df_copy[competitor_rows].groupby('representative_query')['title_body_cohesion'].mean()\n\n        # Map the competitor average back to all rows in the respective group\n        df_copy['competitor_avg_cohesion'] = df_copy['representative_query'].map(competitor_avg_map)\n\n        # --- Handle edge cases ---\n        # Case 1: A group has 'ours' posts but no 'competitors'.\n        # 'competitor_avg_cohesion' will be NaN. We fill it with the post's\n        # own cohesion score, making the resulting ratio 1.0 (a neutral value).\n        df_copy['competitor_avg_cohesion'].fillna(df_copy['title_body_cohesion'], inplace=True)\n\n        # Case 2: A competitor group's average cohesion is 0.\n        # To prevent division by zero, replace 0 with a very small number.\n        df_copy['competitor_avg_cohesion'].replace(0, 1e-9, inplace=True)\n\n        # Calculate the final feature: the ratio of a post's cohesion to its group's competitor average.\n        df_copy[feature_name] = df_copy['title_body_cohesion'] / df_copy['competitor_avg_cohesion']\n\n        # Assign the calculated feature back to the original DataFrame using the index\n        df[feature_name] = df_copy[feature_name]\n    else:\n        df[feature_name] = np.nan\n        \n    return df"
}{
  "timestamp": "2025-07-22T06:31:16.053174",
  "attempt": 2,
  "status": "success",
  "feature_name": "title_body_semantic_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 제목-본문 간 의미 일관성 점수(제목과 본문의 의미적 유사도)가 동일 대표 검색어 그룹 내 경쟁자 포스트들의 평균 점수보다 상대적으로 높을수록, 즉 피처의 값이 1보다 클수록 비브랜드 유입(`non_brand_inflow`)이 많을 것입니다. 이 피처는 각 포스트별로 고유한 상대적 점수를 계산하여 이전 시도의 '모든 행 동일 값' 문제를 해결합니다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence transformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a well-regarded multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and creates a relative\n    score for 'ours' posts against the average cohesion of competitor posts within\n    the same representative query group. This ensures each 'ours' post gets a\n    unique, comparable score, resolving the issue of a constant feature value.\n    \"\"\"\n    # Use a specific feature name for consistency.\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n\n    # Check for an empty DataFrame to avoid errors.\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    model = get_model()\n\n    # Ensure correct data types and handle missing values.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # Encode titles and bodies in efficient batches.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # Calculate individual cohesion (cosine similarity) for EACH post.\n    # .diag() efficiently gets the similarity between corresponding pairs (title_i, body_i).\n    individual_cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    \n    # Add this as a temporary column to the DataFrame.\n    # .cpu().numpy() converts the tensor to a numpy array for pandas compatibility.\n    df['_temp_cohesion'] = individual_cohesion_scores.cpu().numpy()\n\n    # Calculate the average cohesion of competitors for each query group.\n    # This creates a map: {query_1: avg_score_1, query_2: avg_score_2, ...}\n    competitor_avg_map = df[df['source'] == 'competitor'].groupby('representative_query')['_temp_cohesion'].mean()\n\n    # Map this benchmark score to every row based on its 'representative_query'.\n    # Rows in groups without competitors will get NaN.\n    df['_competitor_avg_cohesion'] = df['representative_query'].map(competitor_avg_map)\n    \n    # Initialize the final feature column with a neutral value of 1.0.\n    # This value will be kept for competitor posts and 'ours' posts without a valid benchmark.\n    df[feature_name] = 1.0\n\n    # Isolate 'ours' posts for the final calculation.\n    is_ours_mask = df['source'] == 'ours'\n    \n    # Get the individual cohesion scores and the mapped competitor benchmarks for 'ours' posts.\n    our_cohesion = df.loc[is_ours_mask, '_temp_cohesion']\n    competitor_benchmark = df.loc[is_ours_mask, '_competitor_avg_cohesion']\n\n    # Calculate the relative score: (our_score / competitor_avg_score).\n    # This calculation is performed element-wise for each 'ours' post.\n    relative_scores = our_cohesion.divide(competitor_benchmark)\n    \n    # Handle edge cases for the calculated relative scores:\n    # 1. .fillna(1.0): If competitor_benchmark was NaN (no competitors), the result is NaN.\n    #    We fill it with 1.0, meaning our post is on par with a non-existent baseline.\n    # 2. .replace([np.inf, -np.inf], 2.0): If competitor_benchmark was 0, the result is inf.\n    #    We replace it with 2.0, signifying our post is significantly better without creating extreme outliers.\n    relative_scores = relative_scores.fillna(1.0).replace([np.inf, -np.inf], 2.0)\n    \n    # Assign the calculated, cleaned scores back to the final feature column for 'ours' posts.\n    df.loc[is_ours_mask, feature_name] = relative_scores\n\n    # Clean up by dropping the temporary columns.\n    df.drop(columns=['_temp_cohesion', '_competitor_avg_cohesion'], inplace=True)\n\n    return df",
  "analysis": {
    "correlation": -0.0649274869354903,
    "p_value": 0.531894042501456,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T06:55:01.404205",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_semantic_cohesion_vs_competitors",
  "hypothesis": "우리 포스트의 제목-본문 간 의미적 일관성 점수가 동일 대표 검색어에 대한 경쟁자 그룹의 평균 점수보다 높을수록(비율 > 1), 사용자의 검색 의도를 더 명확하게 충족시켜 이탈률을 낮추고 'non_brand_inflow'를 증가시킬 것입니다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    \"\"\"Initializes and returns the sentence transformer model.\"\"\"\n    global _model\n    if _model is None:\n        # Using a versatile multilingual model suitable for Korean.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the semantic cohesion between title and body for each post,\n    then computes the ratio of our post's cohesion score against the competitor average\n    for the same representative query.\n    \"\"\"\n    # 2. Always check for an empty DataFrame to prevent errors.\n    if df.empty:\n        return df\n\n    feature_name = 'title_body_semantic_cohesion_vs_competitors'\n    # Initialize the feature column with a neutral value of 1.0.\n    # This value indicates parity with competitors and acts as a safe default.\n    df[feature_name] = 1.0\n\n    model = get_model()\n\n    # 3. Prepare data and encode in efficient batches, avoiding .apply().\n    # Preserve the original index by creating lists directly.\n    titles = df['post_title'].fillna('').astype(str).tolist()\n    bodies = df['post_body'].fillna('').astype(str).tolist()\n\n    # show_progress_bar=False to avoid clutter in production logs.\n    title_embeddings = model.encode(titles, convert_to_tensor=True, show_progress_bar=False)\n    body_embeddings = model.encode(bodies, convert_to_tensor=True, show_progress_bar=False)\n\n    # 4. Calculate individual title-body cohesion (cosine similarity).\n    # .diag() correctly gets the element-wise similarity: sim(title_i, body_i).\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n\n    # Add scores as a temporary column. Using .loc ensures index alignment.\n    df.loc[:, 'temp_cohesion_score'] = cohesion_scores.cpu().numpy()\n\n    # 5. Group by query to calculate the relative score against competitors.\n    # This approach correctly handles multiple queries and ensures variance in the feature.\n    # We operate on a view of the DataFrame that has valid queries to avoid errors.\n    valid_df = df.dropna(subset=['representative_query', 'source'])\n    if not valid_df.empty:\n        grouped = valid_df.groupby('representative_query')\n\n        for _, group in grouped:\n            # The 'group' DataFrame preserves the original index from 'df'.\n            our_posts = group[group['source'] == 'ours']\n            competitor_posts = group[group['source'] == 'competitor']\n\n            # Proceed only if both our post(s) and competitor posts exist for the query.\n            if not our_posts.empty and not competitor_posts.empty:\n                our_cohesion = our_posts['temp_cohesion_score']\n                competitor_avg_cohesion = competitor_posts['temp_cohesion_score'].mean()\n\n                # Calculate the ratio, handling potential division by zero.\n                if competitor_avg_cohesion > 1e-9:\n                    relative_cohesion = our_cohesion / competitor_avg_cohesion\n                else:\n                    # If competitor cohesion is zero, our post is relatively superior.\n                    # We assign a value of 2.0 to represent strong superiority, or 1.0 if our post also has zero cohesion.\n                    relative_cohesion = np.where(our_cohesion < 1e-9, 1.0, 2.0)\n\n                # Get the original index to assign the value back to the main DataFrame.\n                # This is a critical step to prevent data misalignment.\n                our_posts_indices = our_posts.index\n                df.loc[our_posts_indices, feature_name] = relative_cohesion\n\n    # 6. Clean up the temporary column and return the full DataFrame.\n    df = df.drop(columns=['temp_cohesion_score'])\n    return df",
  "analysis": {
    "correlation": -0.06492749438793932,
    "p_value": 0.5318939953130282,
    "interpretation": "약한 음의 상관관계(-0.0649)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5319)."
  }
}{
  "timestamp": "2025-07-22T07:17:45.401507",
  "attempt": 1,
  "status": "success",
  "feature_name": "title_body_cohesion_vs_competitors",
  "hypothesis": "Posts where the semantic cohesion between the title and body is higher than the average cohesion of competitor posts for the same query will attract more non-brand inflow. This indicates that a well-structured post that effectively delivers on the promise made in its title is rewarded by users and search algorithms.",
  "code": "import pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_model = None\n\ndef get_model():\n    global _model\n    if _model is None:\n        # Using a multilingual model suitable for various languages.\n        _model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n    return _model\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the title-body semantic cohesion for each post and compares it\n    to the average cohesion of its competitors for the same representative query.\n    \"\"\"\n    feature_name = 'title_body_cohesion_vs_competitors'\n\n    # Handle empty or invalid DataFrame input gracefully\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        if isinstance(df, pd.DataFrame):\n            df[feature_name] = 1.0\n        return df\n\n    # Create a working copy to avoid SettingWithCopyWarning and preserve original df\n    df_work = df.copy()\n\n    # Ensure required columns exist, filling missing data\n    df_work['post_title'] = df_work.get('post_title', pd.Series(index=df.index, dtype=str)).fillna('').astype(str)\n    df_work['post_body'] = df_work.get('post_body', pd.Series(index=df.index, dtype=str)).fillna('').astype(str)\n\n    # 2. Get embeddings in efficient batches\n    model = get_model()\n    try:\n        title_embeddings = model.encode(df_work['post_title'].tolist(), convert_to_tensor=True, show_progress_bar=False)\n        body_embeddings = model.encode(df_work['post_body'].tolist(), convert_to_tensor=True, show_progress_bar=False)\n    except Exception:\n        # In case of a model error, return DataFrame with default value\n        df[feature_name] = 1.0\n        return df\n\n    # 3. Calculate raw cohesion score (cosine similarity) for every post\n    cohesion_scores = util.cos_sim(title_embeddings, body_embeddings).diag()\n    df_work['_cohesion'] = cohesion_scores.cpu().numpy()\n\n    # 4. Calculate the average cohesion for competitors within each query group\n    # The result of transform is a Series with the same index as df_work,\n    # mapping the group's competitor average to each row in that group.\n    df_work['competitor_avg_cohesion'] = df_work.groupby('representative_query')['_cohesion'].transform(\n        lambda x: x[df_work.loc[x.index, 'source'] == 'competitors'].mean()\n    )\n\n    # 5. Calculate the final feature: a ratio of the post's cohesion to its competitors' average\n    # Handle edge cases for safe division:\n    # - Fill NaN (groups with no competitors) with 1.0 for a neutral ratio.\n    # - Replace 0 with a very small number to prevent division by zero.\n    denominator = df_work['competitor_avg_cohesion'].fillna(1.0).replace(0, 1e-9)\n    \n    # The feature is the post's own cohesion score relative to its competitors' average.\n    final_feature_series = df_work['_cohesion'] / denominator\n\n    # Assign the calculated feature back to the original DataFrame, ensuring index alignment.\n    # Fill any remaining NaNs with a neutral 1.0.\n    df[feature_name] = final_feature_series\n    df[feature_name].fillna(1.0, inplace=True)\n\n    return df",
  "analysis": {
    "correlation": -0.0012313596494906574,
    "p_value": 0.9905509307703275,
    "interpretation": "약한 음의 상관관계(-0.0012)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.9906)."
  }
}