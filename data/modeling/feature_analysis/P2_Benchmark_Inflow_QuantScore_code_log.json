{
  "timestamp": "2025-07-22T03:58:50.020075",
  "attempt": 1,
  "status": "success",
  "feature_name": "word_count_zscore_vs_competitors",
  "hypothesis": "경쟁사 그룹의 단어 수 분포 대비 우리 포스트 단어 수의 Z-점수(Z-score)는 콘텐츠 깊이의 차별성을 나타내는 지표입니다. Z-점수가 특정 양수 구간(예: 0.5 ~ 1.5)에 있을 때, 이는 경쟁사 평균보다 포괄적이면서도 불필요하게 길지 않은 최적의 콘텐츠 분량을 의미하며, 결과적으로 non_brand_inflow와 높은 양의 상관관계를 보일 것이라 가정합니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대해, 동일한 'representative_query'를 가진 'competitor' 포스트들의\n    단어 수(word_count) 분포를 기준으로 해당 'ours' 포스트의 단어 수 Z-점수를 계산합니다.\n\n    Z-점수 = (우리 포스트 단어 수 - 경쟁사 평균 단어 수) / 경쟁사 단어 수 표준편차\n\n    이 피처는 우리 포스트가 경쟁사 그룹 대비 얼마나 더 길거나 짧은지를 통계적으로 나타냅니다.\n    \"\"\"\n    # 0. 입력 DataFrame이 비어 있는지 확인합니다.\n    if not df.empty:\n        df_out = df.copy()\n    else:\n        return pd.DataFrame(columns=list(df.columns) + ['word_count_zscore_vs_competitors'])\n\n    # 1. 'competitor' 포스트만 필터링하여 'representative_query'별로 단어 수의 평균과 표준편차를 계산합니다.\n    competitors = df_out[df_out['source'] == 'competitor'].copy()\n    \n    if not competitors.empty:\n        competitor_stats = competitors.groupby('representative_query')['word_count'].agg(['mean', 'std']).reset_index()\n        competitor_stats.columns = ['representative_query', 'competitor_mean_wc', 'competitor_std_wc']\n\n        # 2. 계산된 통계량을 원본 DataFrame에 'representative_query'를 기준으로 병합합니다.\n        df_out = pd.merge(df_out, competitor_stats, on='representative_query', how='left')\n\n        # 3. 'ours' 포스트에 대해서만 Z-점수를 계산합니다.\n        ours_mask = df_out['source'] == 'ours'\n        \n        # 분모가 될 표준편차가 0이거나 NaN인 경우(경쟁사가 1개 이하) Z-점수가 무한대나 NaN이 되는 것을 방지합니다.\n        # 표준편차가 0이라는 것은 모든 경쟁사 포스트의 길이가 같다는 의미이므로, 우리 포스트와의 '차이'는 의미가 있지만\n        # 표준화된 편차(Z-점수)는 0으로 처리하는 것이 합리적입니다.\n        denominator = df_out['competitor_std_wc'].replace(0, np.nan)\n\n        # Z-점수 계산\n        z_score = (df_out['word_count'] - df_out['competitor_mean_wc']) / denominator\n        \n        # Z-점수 계산 결과가 NaN인 경우 (경쟁사가 없거나, 표준편차가 0인 경우) 0으로 채웁니다.\n        z_score.fillna(0, inplace=True)\n\n        # 4. 새로운 피처 컬럼을 생성하고, 'ours' 포스트에만 계산된 Z-점수 값을 할당합니다.\n        # 'competitor' 포스트의 해당 피처 값은 NaN으로 유지됩니다.\n        feature_name = 'word_count_zscore_vs_competitors'\n        df_out[feature_name] = np.nan\n        df_out.loc[ours_mask, feature_name] = z_score[ours_mask]\n        \n        # 5. 중간 계산에 사용된 컬럼을 삭제합니다.\n        df_out.drop(columns=['competitor_mean_wc', 'competitor_std_wc'], inplace=True)\n    else:\n        # 경쟁사 데이터가 없는 경우, 피처 컬럼을 NaN으로 채웁니다.\n        df_out['word_count_zscore_vs_competitors'] = np.nan\n\n    return df_out",
  "analysis": {
    "correlation": 0.058500639248016635,
    "p_value": 0.5733477539645248,
    "interpretation": "약한 양의 상관관계(0.0585)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.5733)."
  }
}{
  "timestamp": "2025-07-22T04:19:33.190766",
  "attempt": 1,
  "status": "success",
  "feature_name": "word_count_ratio_vs_competitor_avg",
  "hypothesis": "우리 포스트의 단어 수가 해당 대표 검색어의 경쟁 포스트 평균 단어 수보다 약간 많을 때 (예: 1.1배 ~ 1.5배), 자연 유입 성과가 더 높을 것이다. 이는 콘텐츠의 깊이와 정보량이 충분함을 시사하면서도, 과도하게 길어 사용자의 이탈을 유발하지 않는 최적의 지점을 나타낸다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of each 'ours' post's word count to the average\n    word count of its competitor posts for the same representative query.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame containing post data.\n                           Must include 'source', 'representative_query', and 'word_count'.\n\n    Returns:\n        pd.DataFrame: The original DataFrame with a new column\n                      'word_count_ratio_vs_competitor_avg'. This column will have\n                      values for 'ours' posts and NaN for 'competitor' posts.\n    \"\"\"\n    # 1. Handle empty DataFrame\n    if df.empty:\n        return df\n\n    feature_name = 'word_count_ratio_vs_competitor_avg'\n\n    # 2. Ensure required columns exist, else return df with an empty feature column\n    required_columns = ['source', 'representative_query', 'word_count']\n    if not all(col in df.columns for col in required_columns):\n        df[feature_name] = np.nan\n        return df\n\n    # 3. Separate our posts and competitor posts, preserving the original index\n    ours_df = df[df['source'] == 'ours']\n    competitor_df = df[df['source'] == 'competitor']\n\n    # Handle case where there are no 'ours' or 'competitor' posts\n    if ours_df.empty or competitor_df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # 4. Calculate the average word count for competitors per representative query\n    # This creates a Series with 'representative_query' as its index\n    competitor_avg_word_count = competitor_df.groupby('representative_query')['word_count'].mean()\n\n    # 5. Map the competitor average to each 'ours' post using its representative query\n    # .map is efficient and correctly handles queries present in 'ours' but not in competitors (results in NaN)\n    # This operation is performed on a Series, which is faster than merging a whole DataFrame.\n    # The resulting Series `mapped_avg` will align with `ours_df.index`.\n    mapped_avg = ours_df['representative_query'].map(competitor_avg_word_count)\n\n    # 6. Calculate the ratio, preventing division by zero\n    # Replace 0 in the denominator with NaN. This ensures that division by zero results in NaN, not infinity.\n    denominator = mapped_avg.replace(0, np.nan)\n    \n    # The calculation is performed on Series aligned by index, which is safe.\n    calculated_ratios = ours_df['word_count'] / denominator\n\n    # 7. Add the new feature to the original DataFrame\n    # Assign the calculated Series to a new column in the main DataFrame.\n    # Pandas automatically aligns the data based on the index, so only 'ours' rows get values.\n    # This is the safest method, preventing any risk of data misalignment.\n    df[feature_name] = calculated_ratios\n\n    return df",
  "analysis": {
    "correlation": 0.08409702430776908,
    "p_value": 0.4177895797369629,
    "interpretation": "약한 양의 상관관계(0.0841)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.4178)."
  }
}{
  "timestamp": "2025-07-22T04:38:34.267368",
  "attempt": 1,
  "status": "success",
  "feature_name": "word_count_ratio_vs_competitor_avg",
  "hypothesis": "우리 포스트의 단어 수를 해당 대표 검색어의 경쟁자 포스트 평균 단어 수로 나눈 비율을 계산합니다. 이 비율이 1.0을 초과하면 (즉, 우리 포스트가 경쟁자 평균보다 길면) 콘텐츠의 깊이와 포괄성을 나타내는 긍정적인 신호로 작용하여 사용자 만족도와 검색 엔진 평가에 좋은 영향을 줄 수 있습니다. 가설: 이 비율이 1.1 ~ 1.5 사이일 때 비브랜드 유입량이 가장 높을 것이며, 이는 경쟁자보다 약간 더 상세한 콘텐츠가 선호됨을 시사합니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of our post's word count to the average word count of competitor posts \n    for the same representative query.\n\n    This feature benchmarks our content length against the competitive landscape for each query.\n    \"\"\"\n    feature_name = 'word_count_ratio_vs_competitor_avg'\n    \n    # Initialize the feature column with a neutral value (1.0) to handle all edge cases upfront.\n    df[feature_name] = 1.0\n\n    # Ensure required columns exist to prevent KeyErrors.\n    required_cols = ['source', 'representative_query', 'word_count']\n    if df.empty or not all(col in df.columns for col in required_cols):\n        return df\n\n    # Create a copy to safely modify dtypes without affecting the original DataFrame slice.\n    df_copy = df[required_cols].copy()\n    \n    # Ensure 'word_count' is a numeric type for calculations, coercing non-numeric values to NaN.\n    df_copy['word_count'] = pd.to_numeric(df_copy['word_count'], errors='coerce')\n\n    # --- Competitor Analysis ---\n    # Filter for competitor posts and drop rows with missing data for the calculation.\n    competitors = df_copy[df_copy['source'] == 'competitor'].dropna()\n\n    if not competitors.empty:\n        # Calculate the average word count for each representative query.\n        # This creates a Series where the index is 'representative_query' and the value is the mean word count.\n        competitor_avg_word_count = competitors.groupby('representative_query')['word_count'].mean()\n        \n        # --- Feature Calculation for 'ours' posts ---\n        # Map the competitor averages to all rows in the copied DataFrame based on the query.\n        # This efficiently assigns the correct competitor average to each of our posts.\n        df_copy['competitor_avg_wc'] = df_copy['representative_query'].map(competitor_avg_word_count)\n\n        # Identify our posts to apply the calculation.\n        our_posts_mask = (df_copy['source'] == 'ours')\n\n        # Safely calculate the ratio for 'our' posts.\n        # This slice of the DataFrame contains our word count and the mapped competitor average.\n        our_posts_data = df_copy[our_posts_mask].copy()\n\n        # Avoid division by zero or by NaN.\n        # Replace 0 or NaN in the denominator with a very small number to prevent errors and yield large, filterable ratios,\n        # or replace with NaN to be filled later. Let's choose NaN for clarity.\n        our_posts_data['competitor_avg_wc'].replace(0, np.nan, inplace=True)\n\n        # Calculate the ratio\n        ratios = our_posts_data['word_count'] / our_posts_data['competitor_avg_wc']\n\n        # Use the original index from 'our_posts_data' to assign the calculated ratios back to the main DataFrame.\n        # This is a CRITICAL step to prevent data misalignment.\n        df.loc[ratios.index, feature_name] = ratios\n\n        # Clean up any NaN/inf values that resulted from missing competitors or division issues,\n        # filling them with the neutral value of 1.0.\n        df[feature_name].replace([np.inf, -np.inf], np.nan, inplace=True)\n        df[feature_name].fillna(1.0, inplace=True)\n\n    return df",
  "analysis": {
    "correlation": 0.08409702430776908,
    "p_value": 0.4177895797369629,
    "interpretation": "약한 양의 상관관계(0.0841)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.4178)."
  }
}{
  "timestamp": "2025-07-22T05:00:13.418377",
  "attempt": 1,
  "status": "success",
  "feature_name": "log_quantitative_benchmark_score",
  "hypothesis": "A composite score representing the log-ratio of a post's key quantitative metrics (word count, readability, image count) against its direct competitor average will positively correlate with `non_brand_inflow`. A positive score signifies quantitative superiority (e.g., longer, more readable content with more images), which we hypothesize attracts more organic traffic.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates a composite benchmark score for 'ours' posts against their competitors.\n\n    The score is the average of the log-ratios for three quantitative metrics:\n    1. word_count\n    2. readability_score\n    3. valid_image_count\n\n    The log-ratio `log((our_value + 1) / (competitor_avg + 1))` is used for robustness against\n    zeros and to create a more symmetric distribution. A positive score indicates\n    that our post is quantitatively superior to the competitor average for a given query.\n    \"\"\"\n    # 1. Handle empty or invalid input DataFrame\n    if df.empty:\n        return df\n\n    benchmark_cols = ['word_count', 'readability_score', 'valid_image_count']\n    required_cols = benchmark_cols + ['source', 'representative_query']\n\n    if not all(col in df.columns for col in required_cols):\n        df['log_quantitative_benchmark_score'] = np.nan\n        return df\n\n    # 2. Isolate competitor data to build the benchmark averages\n    competitors = df[df['source'] == 'competitor']\n\n    # If there are no competitors, we can't create the feature.\n    if competitors.empty:\n        df['log_quantitative_benchmark_score'] = np.nan\n        return df\n\n    # 3. Calculate average stats for competitor groups per query.\n    # Using .agg() is explicit and clear. .reset_index() turns the grouped 'representative_query' back into a column.\n    avg_stats = competitors.groupby('representative_query')[benchmark_cols].mean().reset_index()\n\n    # Rename aggregated columns to avoid name collisions during the merge.\n    rename_dict = {col: f'avg_comp_{col}' for col in benchmark_cols}\n    avg_stats.rename(columns=rename_dict, inplace=True)\n\n    # 4. Merge competitor averages back into the main DataFrame.\n    # A 'left' merge preserves all original rows and the index from 'df'.\n    # This is a safe, index-aware operation that avoids the misalignment from past mistakes.\n    df_merged = pd.merge(df, avg_stats, on='representative_query', how='left')\n\n    # 5. Calculate the log-ratios for each metric.\n    # This vectorized operation is efficient and avoids slow .apply() loops.\n    # The formula log((A+1)/(B+1)) handles zeros gracefully.\n    log_word_ratio = np.log((df_merged['word_count'] + 1) / (df_merged['avg_comp_word_count'] + 1))\n    log_readability_ratio = np.log((df_merged['readability_score'] + 1) / (df_merged['avg_comp_readability_score'] + 1))\n    log_image_ratio = np.log((df_merged['valid_image_count'] + 1) / (df_merged['avg_comp_valid_image_count'] + 1))\n\n    # 6. Combine the log-ratios into a single composite score.\n    # This will result in NaN for rows where no competitor average was available.\n    composite_score = (log_word_ratio + log_readability_ratio + log_image_ratio) / 3\n\n    # 7. Assign the score to the final feature column in the original DataFrame.\n    # We use np.where for a clean, conditional assignment.\n    # The score is only applied to 'ours' posts; competitors get NaN.\n    # Because df_merged has the same index as df, the composite_score series aligns correctly.\n    df['log_quantitative_benchmark_score'] = np.where(\n        df['source'] == 'ours',\n        composite_score,\n        np.nan\n    )\n\n    return df",
  "analysis": {
    "correlation": -0.12243678473285442,
    "p_value": 0.23719726036137684,
    "interpretation": "약한 음의 상관관계(-0.1224)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.2372)."
  }
}{
  "timestamp": "2025-07-22T05:20:03.365592",
  "attempt": 1,
  "status": "success",
  "feature_name": "quantitative_superiority_score",
  "hypothesis": "포스트의 정량적/점수 특성(단어 수, 가독성 점수, 유효 이미지 수, 주제 집중도 점수)이 경쟁자 평균보다 종합적으로 우월할수록 '비브랜드 유입량(non_brand_inflow)'이 높을 것이다. 이 종합적 우월성은 각 지표의 경쟁사 평균 대비 비율의 산술 평균으로 측정된 '정량적 우월성 점수(quantitative_superiority_score)'로 정량화할 수 있다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대해, 동일한 'representative_query'를 가진 'competitor' 포스트들의\n    주요 정량 지표(단어 수, 가독성 점수 등) 평균과 비교하여 상대적 우월성을 나타내는 점수를 계산합니다.\n\n    The score is calculated as the mean of the ratios of our post's metrics to the competitor average.\n    A score > 1 indicates superiority over the average competitor.\n    A score < 1 indicates inferiority.\n    \"\"\"\n    # 0. Check for empty DataFrame or required columns\n    feature_name = 'quantitative_superiority_score'\n    required_columns = ['source', 'representative_query', 'word_count', 'readability_score', 'valid_image_count', 'topic_focus_score']\n    if df.empty or not all(col in df.columns for col in required_columns):\n        if feature_name not in df.columns:\n            df[feature_name] = np.nan\n        return df\n\n    # 1. Define the quantitative metrics to benchmark\n    metrics_to_benchmark = [\n        'word_count',\n        'readability_score',\n        'valid_image_count',\n        'topic_focus_score'\n    ]\n\n    # 2. Initialize the feature column with a default value (NaN)\n    df[feature_name] = np.nan\n\n    # 3. Separate 'ours' and 'competitor' posts while preserving the original index\n    ours_df = df[df['source'] == 'ours']\n    competitors_df = df[df['source'] == 'competitor']\n\n    # 4. Exit if there are no 'ours' or 'competitor' posts to compare\n    if ours_df.empty or competitors_df.empty:\n        return df\n\n    # 5. Calculate the average of metrics for competitors, grouped by query.\n    competitor_avg_stats = competitors_df.groupby('representative_query')[metrics_to_benchmark].mean()\n\n    # 6. Prepare for merging and calculating ratios\n    # Use a temporary DataFrame for calculations to avoid modifying the original 'ours_df' prematurely\n    # We need to join the 'ours' posts with their corresponding competitor averages.\n    # The index of 'ours_df' must be preserved for the final assignment.\n    ours_with_comp_avg = ours_df[['representative_query'] + metrics_to_benchmark].join(\n        competitor_avg_stats, \n        on='representative_query', \n        rsuffix='_comp_avg'\n    )\n\n    # 7. Calculate the ratio for each metric. Add a small epsilon to the denominator to prevent division by zero.\n    ratios = pd.DataFrame(index=ours_with_comp_avg.index)\n    for metric in metrics_to_benchmark:\n        our_metric_col = metric\n        comp_avg_metric_col = f\"{metric}_comp_avg\"\n        \n        # Ensure the competitor average column exists (it might not if a query has no competitors)\n        if comp_avg_metric_col in ours_with_comp_avg.columns:\n            denominator = ours_with_comp_avg[comp_avg_metric_col].fillna(0) + 1e-6\n            ratios[f'{metric}_ratio'] = ours_with_comp_avg[our_metric_col] / denominator\n\n    # 8. Calculate the final score: the mean of the individual metric ratios for each post.\n    # This aggregates the different aspects of quantitative superiority into a single number.\n    final_scores = ratios.mean(axis=1)\n\n    # 9. Assign the calculated scores back to the original DataFrame using the preserved index.\n    # This is the critical step that ensures correct data alignment.\n    df.loc[final_scores.index, feature_name] = final_scores\n\n    return df",
  "analysis": {
    "correlation": -0.089224347154128,
    "p_value": 0.3898687454246375,
    "interpretation": "약한 음의 상관관계(-0.0892)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3899)."
  }
}{
  "timestamp": "2025-07-22T05:43:06.464916",
  "attempt": 1,
  "status": "success",
  "feature_name": "quantitative_superiority_score",
  "hypothesis": "우리 포스트가 경쟁자 그룹의 평균에 비해 단어 수, 가독성 점수, 유효 이미지 수 등 여러 정량적 지표에서 종합적으로 우월할수록 (즉, 이들 지표의 비율을 표준화하여 합산한 '정량적 우위 점수'가 높을수록), 비브랜드 유입 성과가 높을 것이다. 이는 검색엔진이 양적, 질적 풍부함을 종합적으로 평가한다는 가정에 기반한다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates a composite 'Quantitative Superiority Score' for our posts compared to competitors.\n\n    This score is an average of the normalized (z-scored) ratios of several quantitative metrics\n    (word count, readability, image count, etc.) between one of our posts and the average\n    of its competitors for the same representative query.\n    This avoids the low-variance issue of using a single, simple ratio.\n\n    Args:\n        df (pd.DataFrame): The input dataframe containing both 'ours' and 'competitor' posts.\n\n    Returns:\n        pd.DataFrame: The dataframe with the new 'quantitative_superiority_score' column added.\n    \"\"\"\n    if df.empty:\n        return df\n\n    # Define the quantitative features to benchmark\n    QUANT_COLS = ['word_count', 'readability_score', 'valid_image_count', 'char_count_without_space']\n\n    # Ensure required columns exist and are numeric, filling NaNs with 0\n    for col in QUANT_COLS + ['representative_query', 'source']:\n        if col not in df.columns:\n            # If a critical column is missing, we cannot proceed.\n            # Add an empty feature column and return.\n            df['quantitative_superiority_score'] = np.nan\n            return df\n\n    for col in QUANT_COLS:\n        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n\n    # Separate our posts from competitors, using .copy() to avoid SettingWithCopyWarning\n    ours_df = df[df['source'] == 'ours'].copy()\n    competitors_df = df[df['source'] == 'competitor'].copy()\n\n    # If there are no 'ours' or 'competitor' posts, we can't calculate the feature.\n    if ours_df.empty or competitors_df.empty:\n        df['quantitative_superiority_score'] = np.nan\n        return df\n\n    # Calculate average stats for competitors grouped by representative_query\n    competitor_avg_stats = competitors_df.groupby('representative_query')[QUANT_COLS].mean()\n    competitor_avg_stats.rename(columns={col: f\"{col}_competitor_avg\" for col in QUANT_COLS}, inplace=True)\n\n    # Merge competitor averages with our posts. Preserve the original index to ensure correct assignment later.\n    # This is a critical step to prevent data misalignment.\n    merged_df = ours_df.merge(\n        competitor_avg_stats,\n        on='representative_query',\n        how='left'\n    )\n\n    ratio_cols = []\n    # Calculate ratios for each quantitative column\n    for col in QUANT_COLS:\n        our_col = col\n        comp_avg_col = f\"{col}_competitor_avg\"\n        ratio_col_name = f\"{col}_ratio\"\n\n        # Use a small epsilon to prevent division by zero\n        denominator = merged_df[comp_avg_col] + 1e-6\n        merged_df[ratio_col_name] = merged_df[our_col] / denominator\n        \n        # If both our value and the competitor average are 0, the ratio should be 1 (parity), not 0.\n        merged_df.loc[(merged_df[our_col] == 0) & (merged_df[comp_avg_col] == 0), ratio_col_name] = 1.0\n        ratio_cols.append(ratio_col_name)\n\n    zscore_cols = []\n    # Calculate z-scores for each ratio to normalize them onto a common scale\n    for col in ratio_cols:\n        zscore_col_name = f\"{col}_zscore\"\n        mean = merged_df[col].mean()\n        std = merged_df[col].std()\n\n        if pd.notna(std) and std > 0:\n            merged_df[zscore_col_name] = (merged_df[col] - mean) / std\n        else:\n            # If standard deviation is 0 or NaN, all values are the same, so the z-score is 0.\n            merged_df[zscore_col_name] = 0\n        zscore_cols.append(zscore_col_name)\n\n    # The final composite score is the mean of the z-scores for each post.\n    # .fillna(0) handles posts that had no competitors (and thus NaN for all z-scores).\n    final_scores = merged_df[zscore_cols].mean(axis=1).fillna(0)\n    \n    # Set the index of the scores series to match the merged_df index (which is the original 'ours_df' index)\n    final_scores.index = merged_df.index\n\n    # Assign the calculated scores back to the original DataFrame using the index.\n    # This correctly maps scores to 'ours' rows and leaves NaNs for others.\n    df['quantitative_superiority_score'] = final_scores\n\n    return df",
  "analysis": {
    "correlation": 0.08429103143231317,
    "p_value": 0.4167124731355454,
    "interpretation": "약한 양의 상관관계(0.0843)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.4167)."
  }
}{
  "timestamp": "2025-07-22T06:02:54.278513",
  "attempt": 1,
  "status": "success",
  "feature_name": "quantitative_superiority_score",
  "hypothesis": "포스트의 주요 정량적 지표들(단어 수, 가독성, 이미지 수, 주제 집중도)이 해당 대표 검색어의 경쟁사 평균보다 종합적으로 우월할수록 (즉, 'quantitative_superiority_score'가 높을수록) 비브랜드 유입량이 증가하는 양의 상관관계를 보일 것이다. 이 점수는 각 지표의 '우리 포스트 값 / 경쟁사 평균 값'에 로그를 취한 값들의 평균으로, 0은 경쟁사와 동등, 양수는 우위, 음수는 열위를 나타낸다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대해, 동일 'representative_query'를 가진 경쟁사 그룹의\n    정량적 지표(단어 수, 가독성 점수 등) 평균과 비교하여 종합적인 우월성 점수를 계산합니다.\n\n    The score is calculated as the average of the log-ratios for several key quantitative metrics.\n    Log-ratio = log(our_post_value / competitor_group_average_value).\n    This centers the score around 0 (parity), with positive values indicating superiority\n    and negative values indicating inferiority.\n    \"\"\"\n    # 0. Check for empty DataFrame\n    if df.empty:\n        # Add the feature column with a default value if it doesn't exist\n        if 'quantitative_superiority_score' not in df.columns:\n            df['quantitative_superiority_score'] = np.nan\n        return df\n\n    # 1. Define the quantitative columns to benchmark\n    quant_cols = [\n        'word_count',\n        'readability_score',\n        'valid_image_count',\n        'topic_focus_score'\n    ]\n\n    # Ensure target columns exist and are numeric, fill NaNs with 0\n    for col in quant_cols:\n        if col not in df.columns:\n            df[col] = 0\n        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n\n    # 2. Calculate competitor average stats per representative_query\n    # Keep the original index to avoid misalignment issues\n    df_copy = df.copy()\n    competitors = df_copy[df_copy['source'] == 'competitor']\n\n    if not competitors.empty:\n        # Group by query and calculate the mean for each quantitative column\n        competitor_averages = competitors.groupby('representative_query')[quant_cols].mean().reset_index()\n\n        # Add a suffix to avoid column name collisions during merge\n        competitor_averages.columns = ['representative_query'] + [f'{col}_competitor_avg' for col in quant_cols]\n\n        # 3. Merge competitor averages back to the main DataFrame\n        # Use a left merge to ensure all 'ours' posts are kept, regardless of whether they have competitors\n        df_merged = pd.merge(df_copy, competitor_averages, on='representative_query', how='left')\n        # Restore the original index to ensure perfect alignment before assigning the new feature\n        df_merged.index = df_copy.index\n    else:\n        # If no competitors, create placeholder columns with NaNs to prevent errors\n        df_merged = df_copy\n        for col in quant_cols:\n            df_merged[f'{col}_competitor_avg'] = np.nan\n\n    # 4. Calculate log-ratios for each metric and the final composite score\n    log_ratios = []\n    for col in quant_cols:\n        our_values = df_merged[col]\n        competitor_avg_values = df_merged[f'{col}_competitor_avg']\n\n        # Add a small epsilon to denominators to avoid division by zero\n        ratio = our_values / (competitor_avg_values + 1e-6)\n\n        # Calculate log-ratio. Add epsilon to ratio to avoid log(0).\n        # This measures superiority (positive) or inferiority (negative) on a log scale.\n        log_ratio = np.log(ratio + 1e-6)\n        log_ratios.append(log_ratio)\n\n    # 5. Compute the final score by averaging the log-ratios\n    # Use np.stack to create a 2D array and then calculate the mean across columns (axis=0)\n    if log_ratios:\n        final_score = np.mean(np.stack(log_ratios, axis=0), axis=0)\n    else:\n        final_score = np.nan # Should not happen if quant_cols is not empty\n\n    # Assign the calculated score to the original DataFrame, preserving its index.\n    # Fill any NaNs (e.g., for posts with no competitors for their query) with 0, representing parity or no data.\n    df['quantitative_superiority_score'] = pd.Series(final_score, index=df_merged.index).fillna(0)\n\n    return df",
  "analysis": {
    "correlation": -0.021237334504877588,
    "p_value": 0.8381357200746802,
    "interpretation": "약한 음의 상관관계(-0.0212)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.8381)."
  }
}{
  "timestamp": "2025-07-22T06:22:03.726673",
  "attempt": 1,
  "status": "success",
  "feature_name": "quantitative_benchmark_score",
  "hypothesis": "우리 포스트의 단어 수와 가독성 점수를 경쟁사 평균과 비교하여 산출한 통합적인 '양적 벤치마크 점수'는 non-brand 유입량과 상관관계가 있을 것입니다. 이 점수는 경쟁사 대비 우리 포스트의 양적 특성(분량, 가독성)의 상대적 우위 또는 열위를 나타냅니다. 너무 많거나 적지 않은, 즉 경쟁사 그룹과 유사하거나 약간 우월한 특정 점수 구간에서 가장 높은 유입 성과를 보일 것이라고 가정합니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대해, 동일한 'representative_query'를 가진 'competitor' 포스트들의\n    평균적인 'word_count'와 'readability_score'를 계산합니다. \n    그 후 'ours' 포스트의 값과 경쟁사 평균 값의 로그 비율(log ratio)을 각각 계산하고,\n    두 로그 비율의 평균을 최종 피처 값으로 산출합니다.\n\n    이 피처는 경쟁사 대비 양적 프로필의 상대적 위치를 나타냅니다:\n    - 0: 경쟁사 평균과 정확히 일치\n    - 양수: 경쟁사보다 단어 수가 많고 가독성 점수가 높은 경향\n    - 음수: 경쟁사보다 단어 수가 적고 가독성 점수가 낮은 경향\n    \"\"\"\n    feature_name = 'quantitative_benchmark_score'\n    df[feature_name] = np.nan\n\n    if df.empty:\n        return df\n\n    # 원본 인덱스를 보존하기 위해 .copy() 사용\n    ours_df = df[df['source'] == 'ours'].copy()\n    competitor_df = df[df['source'] == 'competitor'].copy()\n\n    if ours_df.empty or competitor_df.empty:\n        df[feature_name] = df[feature_name].fillna(0.0)\n        return df\n\n    # 1. 대표 쿼리별로 경쟁사의 평균 메트릭 계산\n    competitor_metrics = ['word_count', 'readability_score']\n    competitor_averages = competitor_df.groupby('representative_query')[competitor_metrics].mean()\n    competitor_averages = competitor_averages.rename(columns={\n        'word_count': 'avg_comp_word_count',\n        'readability_score': 'avg_comp_readability_score'\n    })\n\n    # 2. 우리 포스트 데이터에 경쟁사 평균 메트릭을 병합\n    # merge는 인덱스를 재설정할 수 있으므로, 원본 인덱스를 보존하는 것이 중요\n    # ours_df는 원본 df의 인덱스를 그대로 가지고 있음\n    ours_with_benchmarks = ours_df.merge(\n        competitor_averages,\n        on='representative_query',\n        how='left'\n    )\n\n    # 병합으로 인해 인덱스가 유실되거나 순서가 바뀔 수 있으므로, 원본 인덱스를 다시 설정\n    ours_with_benchmarks.index = ours_df.index\n\n    # 3. 로그 비율 계산 (0으로 나누기 및 log(0) 오류 방지)\n    epsilon = 1e-9\n\n    # 단어 수 비율\n    wc_ratio = ours_with_benchmarks['word_count'] / (ours_with_benchmarks['avg_comp_word_count'] + epsilon)\n    # NaN이 발생한 경우(경쟁사 데이터 없는 경우) 비율을 1(동일)로 처리\n    wc_ratio = wc_ratio.fillna(1.0)\n    log_wc_ratio = np.log(wc_ratio.clip(lower=epsilon)) # 0이하 값 방지\n\n    # 가독성 점수 비율\n    rs_ratio = ours_with_benchmarks['readability_score'] / (ours_with_benchmarks['avg_comp_readability_score'] + epsilon)\n    rs_ratio = rs_ratio.fillna(1.0)\n    log_rs_ratio = np.log(rs_ratio.clip(lower=epsilon))\n\n    # 4. 두 로그 비율의 평균을 최종 점수로 계산\n    final_score = (log_wc_ratio + log_rs_ratio) / 2\n\n    # 5. 원본 DataFrame에 계산된 점수 할당 (인덱스 기반으로 정확하게 매칭)\n    df.loc[final_score.index, feature_name] = final_score\n\n    # 6. 피처가 계산되지 않은 모든 행(경쟁사, 매칭 안된 우리 포스트)을 중립적인 값 0으로 채움\n    df[feature_name] = df[feature_name].fillna(0.0)\n\n    return df",
  "analysis": {
    "correlation": 0.08693166161664657,
    "p_value": 0.4022129268095646,
    "interpretation": "약한 양의 상관관계(0.0869)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.4022)."
  }
}{
  "timestamp": "2025-07-22T06:42:47.889006",
  "attempt": 1,
  "status": "success",
  "feature_name": "quantitative_superiority_score",
  "hypothesis": "우리 포스트의 단어 수와 가독성 점수가 경쟁사 평균보다 일정 비율 이상 높을 때(즉, '양적 우월성 점수'가 1보다 클 때) 검색엔진이 콘텐츠의 깊이와 품질을 더 높게 평가하여, 비브랜드 유입량이 증가하는 경향을 보일 것이다. 이는 단순히 길기만 한 것이 아니라, 가독성도 함께 고려된 양질의 콘텐츠가 성과에 긍정적인 영향을 미친다는 가정에 기반한다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates a quantitative superiority score for each post.\n\n    The score is the geometric mean of the ratios of a post's quantitative \n    metrics (word_count, readability_score) compared to the average of its \n    competitors for the same representative query.\n\n    A score > 1 indicates the post is quantitatively \"superior\" on these metrics.\n    A score < 1 indicates it is \"inferior\".\n    A score = 1 is neutral (average or no competitors).\n    \"\"\"\n    feature_name = \"quantitative_superiority_score\"\n    quant_cols = ['word_count', 'readability_score']\n    \n    # Initialize the column with a neutral value of 1.0. This handles cases with no competitors.\n    df[feature_name] = 1.0\n    \n    # Check for empty dataframe or missing required columns\n    if df.empty or not all(c in df.columns for c in quant_cols + ['source', 'representative_query']):\n        return df\n\n    # 1. Isolate competitors and calculate their average stats per query\n    competitors = df[df['source'] == 'competitor']\n    if competitors.empty:\n        # No competitors in the entire dataset, all scores correctly remain neutral 1.0\n        return df\n\n    # Calculate mean for specified quantitative columns, adding a suffix for merging\n    competitor_avg_stats = competitors.groupby('representative_query')[quant_cols].mean().add_suffix('_competitor_avg').reset_index()\n\n    # 2. Merge competitor average stats back into the main dataframe\n    # CRITICAL: Preserve the original DataFrame's index to prevent misalignment.\n    # Merging can reorder rows, so we work on a copy and then map the results back.\n    original_index = df.index\n    merged_df = df.reset_index().merge(competitor_avg_stats, on='representative_query', how='left').set_index('index')\n    # Align the merged data back to the original DataFrame's order\n    merged_df = merged_df.reindex(original_index)\n\n    # 3. Calculate ratios safely, avoiding division by zero\n    # A small epsilon is added to the denominator.\n    epsilon = 1e-9\n    \n    wc_ratio = merged_df['word_count'] / (merged_df['word_count_competitor_avg'] + epsilon)\n    rs_ratio = merged_df['readability_score'] / (merged_df['readability_score_competitor_avg'] + epsilon)\n\n    # 4. Calculate the geometric mean of the ratios. np.sqrt is the gmean for 2 items.\n    # Using .values ensures we are working with NumPy arrays for performance.\n    score = np.sqrt(wc_ratio.values * rs_ratio.values)\n    \n    # 5. Assign the calculated score back to the original DataFrame\n    # The score is valid only where competitor stats existed (not NaN).\n    # For posts without competitors (where score is NaN), the original 1.0 is kept.\n    df[feature_name] = pd.Series(score, index=merged_df.index).fillna(1.0)\n    \n    return df",
  "analysis": {
    "correlation": 0.08405302323979183,
    "p_value": 0.418034093193541,
    "interpretation": "약한 양의 상관관계(0.0841)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.4180)."
  }
}{
  "timestamp": "2025-07-22T07:05:14.641960",
  "attempt": 1,
  "status": "success",
  "feature_name": "quantitative_benchmark_score",
  "hypothesis": "포스트의 주요 정량적 지표(단어 수, 가독성 점수, 유효 이미지 수)를 경쟁자 그룹의 평균과 비교하여 산출한 종합 점수가 높을수록, 즉 우리 포스트가 경쟁자보다 양적, 질적으로 우수할수록 비브랜드 유입 성과('non_brand_inflow')가 높을 것입니다. 이 종합 점수는 단일 지표보다 콘텐츠의 전반적인 우수성을 더 잘 반영하여 성과와 더 강한 긍정적 상관관계를 보일 것으로 예상됩니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    'ours' 소스의 포스트에 대해, 동일한 'representative_query'를 가진 경쟁자 포스트들의\n    정량적 지표(단어 수, 가독성 점수, 유효 이미지 수) 평균 대비 우리 포스트의 상대적 우수성을\n    나타내는 종합 벤치마크 점수를 계산합니다.\n\n    Args:\n        df (pd.DataFrame): 'source', 'representative_query', 'word_count',\n                           'readability_score', 'valid_image_count' 컬럼을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'quantitative_benchmark_score' 컬럼이 추가된 데이터프레임.\n                      이 점수는 'ours' 포스트에 대해서만 계산되며, 나머지는 NaN으로 채워집니다.\n    \"\"\"\n    feature_name = 'quantitative_benchmark_score'\n\n    # 1. 초기화 및 예외 처리\n    if df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    df[feature_name] = np.nan\n    metrics_to_compare = ['word_count', 'readability_score', 'valid_image_count']\n    required_cols = metrics_to_compare + ['source', 'representative_query']\n\n    if not all(col in df.columns for col in required_cols):\n        return df\n\n    # 2. 데이터 분리 및 벤치마크 계산\n    ours_df = df[df['source'] == 'ours'].copy()\n    competitors_df = df[df['source'] == 'competitor'].copy()\n\n    if ours_df.empty or competitors_df.empty:\n        return df\n\n    # 경쟁자 그룹의 대표 검색어별 지표 평균 계산\n    competitor_avg_metrics = competitors_df.groupby('representative_query')[metrics_to_compare].mean()\n    competitor_avg_metrics.rename(columns={\n        'word_count': 'competitor_avg_word_count',\n        'readability_score': 'competitor_avg_readability_score',\n        'valid_image_count': 'competitor_avg_valid_image_count'\n    }, inplace=True)\n\n    # 3. 'ours' 데이터에 경쟁자 벤치마크 병합\n    # 원본 인덱스를 보존하기 위해 ours_df를 직접 사용합니다.\n    # map을 사용하여 각 대표 검색어에 맞는 경쟁자 평균을 매핑합니다.\n    for metric, avg_metric_name in zip(metrics_to_compare, competitor_avg_metrics.columns):\n        ours_df[avg_metric_name] = ours_df['representative_query'].map(competitor_avg_metrics[avg_metric_name])\n\n    # 4. 비율 계산 및 종합 점수 산출\n    # 0으로 나누는 것을 방지하기 위해 작은 값(epsilon)을 더합니다.\n    epsilon = 1e-6\n\n    wc_ratio = ours_df['word_count'].div(ours_df['competitor_avg_word_count'] + epsilon)\n    rs_ratio = ours_df['readability_score'].div(ours_df['competitor_avg_readability_score'] + epsilon)\n    ic_ratio = ours_df['valid_image_count'].div(ours_df['competitor_avg_valid_image_count'] + epsilon)\n\n    # NaN이나 무한대 값을 중립적인 1.0으로 대체합니다.\n    ratios_df = pd.DataFrame({\n        'wc_ratio': wc_ratio.replace([np.inf, -np.inf], np.nan).fillna(1.0),\n        'rs_ratio': rs_ratio.replace([np.inf, -np.inf], np.nan).fillna(1.0),\n        'ic_ratio': ic_ratio.replace([np.inf, -np.inf], np.nan).fillna(1.0)\n    })\n\n    composite_score = ratios_df.mean(axis=1)\n\n    # 5. 최종 점수를 원본 DataFrame에 정확히 할당\n    # ours_df의 인덱스를 사용하여 원본 df의 정확한 위치에 값을 할당합니다.\n    df.loc[ours_df.index, feature_name] = composite_score\n\n    return df",
  "analysis": {
    "correlation": -0.08922442076795416,
    "p_value": 0.38986835275111875,
    "interpretation": "약한 음의 상관관계(-0.0892)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3899)."
  }
}{
  "timestamp": "2025-07-22T07:58:05.301317",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_word_count_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Generates the 'relative_word_count_ratio' feature.\n\n    This feature calculates the ratio of a post's word count to the average word count\n    of competitor posts for the same representative query.\n\n    - The calculation is performed for each 'ours' post.\n    - If a query group has no competitors, or if the competitor average word count is zero,\n      the feature value for 'ours' posts in that group defaults to a neutral 1.0.\n    - For all 'competitor' source posts, the value is also set to a neutral 1.0.\n\n    Args:\n        df (pd.DataFrame): The input dataframe containing post data.\n                           It must include 'source', 'representative_query', and 'word_count' columns.\n\n    Returns:\n        pd.DataFrame: The dataframe with the new 'relative_word_count_ratio' column added.\n    \"\"\"\n    # 1. Handle empty DataFrame immediately.\n    if df.empty:\n        return df\n\n    # 2. Create a copy to safely modify the DataFrame.\n    df_copy = df.copy()\n\n    # 3. Calculate the average word count for competitor posts per representative query.\n    # This creates a Series with 'representative_query' as the index.\n    # It will only contain queries where competitor posts exist.\n    competitor_avg_word_count = df_copy[df_copy['source'] == 'competitors'].groupby('representative_query')['word_count'].mean()\n\n    # 4. Map this average to each row in the DataFrame based on its query.\n    # This creates a temporary 'benchmark' column. Rows in queries without competitors will get NaN.\n    df_copy['benchmark_word_count'] = df_copy['representative_query'].map(competitor_avg_word_count)\n\n    # 5. Initialize the final feature column with a neutral default of 1.0.\n    # This value is used for all competitor posts and for 'ours' posts that cannot be compared.\n    df_copy['relative_word_count_ratio'] = 1.0\n\n    # 6. Define a mask to select only the 'ours' posts for which a valid comparison is possible.\n    # A valid benchmark must exist (not NaN) and be greater than 0 to avoid division by zero.\n    ours_mask = (\n        (df_copy['source'] == 'ours') &\n        (df_copy['benchmark_word_count'].notna()) &\n        (df_copy['benchmark_word_count'] > 0)\n    )\n\n    # 7. Calculate the ratio for the selected 'ours' posts.\n    # This operation is vectorized and only applies to the rows where the mask is True.\n    df_copy.loc[ours_mask, 'relative_word_count_ratio'] = \\\n        df_copy.loc[ours_mask, 'word_count'] / df_copy.loc[ours_mask, 'benchmark_word_count']\n\n    # 8. Clean up the intermediate benchmark column.\n    df_copy.drop(columns=['benchmark_word_count'], inplace=True)\n\n    return df_copy"
}{
  "timestamp": "2025-07-22T07:59:21.087322",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'word_count_vs_competitor_avg'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Analyzes the word count of 'our' posts relative to the average word count of all competitor posts.\n\n    This feature is designed to test the hypothesis that an optimal word count ratio exists for maximizing non-brand inflow.\n    To avoid the previous error of generating a constant value due to a lack of competitors in specific query groups,\n    this version calculates a single, robust benchmark: the average word count of ALL competitor posts in the DataFrame.\n    This global benchmark is then used to calculate a relative ratio for each 'our' post, ensuring variance in the feature column\n    as long as 'our' posts have different word counts.\n\n    Args:\n        df (pd.DataFrame): The input dataframe with columns 'source', 'word_count'.\n\n    Returns:\n        pd.DataFrame: The dataframe with the new feature column 'word_count_vs_competitor_avg'.\n    \"\"\"\n    # 1. Initialize the feature column with a neutral default value (1.0 for a ratio).\n    feature_name = 'word_count_vs_competitor_avg'\n    df[feature_name] = 1.0\n\n    if df.empty:\n        return df\n\n    # 2. Separate 'ours' and 'competitors' data.\n    ours_df = df[df['source'] == 'ours'].copy()\n    competitors_df = df[df['source'] == 'competitors']\n\n    # 3. If there are no 'ours' posts to calculate for, return early.\n    if ours_df.empty:\n        return df\n\n    # 4. Calculate a single, global average word count from all competitor posts.\n    # This creates a stable benchmark and avoids errors from query groups lacking competitors.\n    if not competitors_df.empty and competitors_df['word_count'].notna().any():\n        competitor_avg_word_count = competitors_df['word_count'].mean()\n    else:\n        # Fallback: If no competitors exist, no comparison is possible. Return with default values.\n        return df\n\n    # 5. Avoid division by zero. If the average is 0, no meaningful ratio can be calculated.\n    if competitor_avg_word_count > 0:\n        # Calculate the ratio for each 'our' post against the global competitor average.\n        # This ensures variance as long as 'our' posts have varying word counts.\n        ratios = ours_df['word_count'] / competitor_avg_word_count\n        \n        # 6. Assign the calculated ratios back to the main DataFrame using the original index.\n        # This is a critical step to ensure correct alignment.\n        df.loc[ours_df.index, feature_name] = ratios\n\n    return df"
}{
  "timestamp": "2025-07-22T08:02:44.774471",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'word_count_vs_competitor_avg'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    '우리' 포스트의 단어 수를 해당 대표 검색어 그룹의 '경쟁사' 포스트 평균 단어 수와 비교하여 비율을 계산합니다.\n\n    - 각 '우리' 포스트에 대해, 동일한 'representative_query'를 가진 '경쟁사' 포스트들의 평균 단어 수를 계산합니다.\n    - 이 평균을 벤치마크로 사용하여 '우리' 포스트 단어 수의 상대적 비율을 계산합니다.\n    - 만약 특정 쿼리 그룹에 경쟁사 포스트가 없는 경우, 전체 경쟁사 포스트의 평균 단어 수를 대체 벤치마크로 사용합니다.\n      이를 통해 모든 '우리' 포스트에 대해 의미 있는 비교 값을 생성하여 피처의 분산을 확보합니다.\n    - '경쟁사' 포스트의 피처 값은 비교 대상이 아니므로 중립적인 값인 1.0으로 설정됩니다.\n\n    Args:\n        df (pd.DataFrame): 'source', 'representative_query', 'word_count' 열을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'word_count_vs_competitor_avg' 피처가 추가된 데이터프레임.\n    \"\"\"\n    feature_name = 'word_count_vs_competitor_avg'\n\n    # 1. Check for required columns and empty DataFrame\n    if df.empty or not all(col in df.columns for col in ['source', 'word_count', 'representative_query']):\n        df[feature_name] = 1.0\n        return df\n\n    # 2. Initialize the feature column with a neutral default value.\n    df[feature_name] = 1.0\n\n    # 3. Separate 'ours' and 'competitors' data.\n    ours_mask = df['source'] == 'ours'\n    competitors_df = df[df['source'] == 'competitors']\n\n    # If there's no data for 'ours' posts or no competitor data for benchmarking, return with defaults.\n    if df[ours_mask].empty or competitors_df.empty:\n        return df\n\n    # 4. Calculate query-specific competitor average word count.\n    query_specific_avg = competitors_df.groupby('representative_query')['word_count'].mean()\n\n    # 5. Calculate the global competitor average word count as a fallback.\n    # This ensures a benchmark is always available.\n    global_competitor_avg = competitors_df['word_count'].mean()\n\n    # If global average is somehow invalid (NaN or 0), we can't create a meaningful ratio.\n    if pd.isna(global_competitor_avg) or global_competitor_avg == 0:\n        return df\n\n    # 6. For each 'ours' post, determine the correct benchmark.\n    # Map the query-specific average. If it's not found for a query, it will be NaN.\n    benchmark_values = df.loc[ours_mask, 'representative_query'].map(query_specific_avg)\n    \n    # Use the global average as a fallback for those NaN cases.\n    benchmark_values.fillna(global_competitor_avg, inplace=True)\n    \n    # Ensure the benchmark is not zero to avoid division by zero errors.\n    benchmark_values[benchmark_values == 0] = global_competitor_avg\n\n    # 7. Calculate the ratio for 'ours' posts.\n    # This calculation is performed element-wise and now has variance because each 'our' post's\n    # own 'word_count' is used in the numerator.\n    our_word_counts = df.loc[ours_mask, 'word_count']\n    ratios = our_word_counts / benchmark_values\n\n    # 8. Assign the calculated ratios back to the original DataFrame for 'ours' posts.\n    # Using .loc with the mask ensures values are assigned to the correct rows.\n    df.loc[ours_mask, feature_name] = ratios\n\n    return df"
}{
  "timestamp": "2025-07-22T08:04:05.463856",
  "attempt": 4,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_word_count_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트의 단어 수를 해당 대표 검색어에 대한 'competitors' 포스트들의 평균 단어 수와 비교하여 비율을 계산합니다.\n    이전 시도에서는 그룹별로 단일 값을 계산하여 모든 행에 적용했기 때문에 피처 값이 상수가 되는 문제가 있었습니다.\n    이 코드는 각 'ours' 포스트별로 고유한 비율을 계산하여 행 간의 분산을 보장합니다.\n\n    Args:\n        df (pd.DataFrame): 'post_identifier', 'source', 'representative_query', 'word_count' 열을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'relative_word_count_ratio' 피처가 추가된 데이터프레임.\n                        'ours' 포스트는 계산된 비율 값을 가지며, 'competitors'나 비교 대상이 없는 'ours' 포스트는 1.0을 가집니다.\n    \"\"\"\n    feature_name = 'relative_word_count_ratio'\n\n    # 1. 피처 열을 모든 행에 대해 중립적인 값 1.0으로 초기화합니다.\n    #    이는 'competitors' 행과, 경쟁사 그룹이 없는 'ours' 행에 대한 기본값 역할을 합니다.\n    df[feature_name] = 1.0\n\n    # 2. 데이터프레임이 비어있는 경우 즉시 반환하여 오류를 방지합니다.\n    if df.empty:\n        return df\n\n    # 3. 경쟁사 데이터만 필터링하여 벤치마크를 생성합니다.\n    competitors_df = df[df['source'] == 'competitors'].copy()\n\n    # 4. 경쟁사 데이터가 없는 경우, 모든 포스트의 피처 값은 1.0으로 유지되므로 그대로 반환합니다.\n    if competitors_df.empty:\n        return df\n\n    # 5. 대표 검색어별로 경쟁사의 평균 단어 수를 계산합니다.\n    #    결과는 'representative_query'를 인덱스로 갖는 Series가 됩니다.\n    competitor_avg_by_query = competitors_df.groupby('representative_query')['word_count'].mean()\n\n    # 6. 'ours' 포스트에 대해서만 계산을 수행하기 위해 마스크를 생성합니다.\n    ours_mask = df['source'] == 'ours'\n    if not ours_mask.any():\n        return df # 'ours' 포스트가 없으면 계산할 필요가 없습니다.\n\n    # 7. 'ours' 포스트의 대표 검색어를 사용하여 맵핑할 경쟁사 평균값을 가져옵니다.\n    #    map을 사용하면 각 'ours' 포스트에 해당하는 벤치마크 값을 효율적으로 할당할 수 있습니다.\n    #    만약 특정 쿼리에 경쟁사가 없다면 결과는 NaN이 됩니다.\n    competitor_benchmark = df.loc[ours_mask, 'representative_query'].map(competitor_avg_by_query)\n\n    # 8. 'ours' 포스트의 개별 단어 수를 가져옵니다.\n    our_word_counts = df.loc[ours_mask, 'word_count']\n\n    # 9. 비율을 계산합니다. 분모(경쟁사 평균)가 0이거나 NaN일 경우를 대비합니다.\n    #    np.divide를 사용하여 'where' 조건으로 0으로 나누는 경우를 안전하게 처리합니다.\n    #    분모가 0이거나 NaN이면 결과를 NaN으로 설정합니다.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        ratios = np.divide(our_word_counts.values, competitor_benchmark.values,\n                           where=(competitor_benchmark.values != 0) & (pd.notna(competitor_benchmark.values)))\n        # where 조건이 False인 경우, 결과는 np.divide의 out 인자나 초기 배열 값에 따라 달라질 수 있으므로,\n        # 명시적으로 다시 NaN으로 처리해줍니다.\n        ratios[~((competitor_benchmark.values != 0) & (pd.notna(competitor_benchmark.values)))] = np.nan\n\n    # 10. 계산된 비율(Series)을 생성하고, NaN 값을 중립적인 1.0으로 채웁니다.\n    #     이는 경쟁사가 없는 쿼리 그룹의 'ours' 포스트에 해당합니다.\n    ratio_series = pd.Series(ratios, index=df[ours_mask].index).fillna(1.0)\n\n    # 11. 계산된 값을 'ours' 포스트에만 할당합니다. 이제 각 'ours' 포스트는\n    #      자신의 단어 수에 기반한 고유한 비율 값을 갖게 되어 분산이 확보됩니다.\n    df.loc[ours_mask, feature_name] = ratio_series\n\n    return df"
}{
  "timestamp": "2025-07-22T08:05:35.389514",
  "attempt": 5,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'readability_relative_to_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트의 가독성 점수를 해당 대표 검색어에 대한 경쟁사 포스트들의 평균 가독성 점수와 비교하여 상대적 비율을 계산합니다.\n\n    이 피처는 다음과 같이 계산됩니다:\n    - 'ours' 포스트: 자신의 'readability_score' / 동일 'representative_query'를 가진 경쟁사들의 평균 'readability_score'\n    - 'competitors' 포스트: 기본값 1.0이 할당됩니다.\n    - 'ours' 포스트 중 해당 쿼리에 경쟁사가 없는 경우: 기본값 1.0이 할당됩니다.\n\n    Args:\n        df (pd.DataFrame): 'source', 'representative_query', 'readability_score' 열을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'readability_relative_to_competitors' 피처 열이 추가된 데이터프레임.\n    \"\"\"\n    feature_name = 'readability_relative_to_competitors'\n\n    # Handle empty DataFrame case\n    if df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # Create a working copy to avoid SettingWithCopyWarning\n    df_copy = df.copy()\n\n    # Isolate competitor posts to create the benchmark\n    competitors_df = df_copy[df_copy['source'] == 'competitors']\n\n    # If there are no competitors in the dataset, no benchmark can be created.\n    # Return a neutral value for all posts.\n    if competitors_df.empty:\n        df[feature_name] = 1.0\n        return df\n\n    # Calculate the average readability score for competitors, grouped by query.\n    # This creates a Series where the index is 'representative_query'.\n    competitor_avg_readability = competitors_df.groupby('representative_query')['readability_score'].mean()\n\n    # Map the competitor average to each row in the full dataframe based on its query.\n    # Rows in queries that have no competitors will get a NaN value.\n    df_copy['competitor_avg_readability'] = df_copy['representative_query'].map(competitor_avg_readability)\n\n    # Initialize the feature column with a neutral default value of 1.0.\n    # This value will be used for all competitor posts and for 'ours' posts that lack a competitor benchmark.\n    df[feature_name] = 1.0\n\n    # Create a boolean mask to identify only the 'ours' posts that have a valid competitor benchmark.\n    # A benchmark is valid if it's not NaN and not zero (to prevent division by zero).\n    ours_mask = (df_copy['source'] == 'ours')\n    valid_benchmark_mask = df_copy['competitor_avg_readability'].notna() & (df_copy['competitor_avg_readability'] > 0)\n    target_mask = ours_mask & valid_benchmark_mask\n\n    # Perform the calculation only for the targeted rows to ensure variance and prevent errors.\n    if target_mask.any():\n        our_scores = df_copy.loc[target_mask, 'readability_score']\n        competitor_benchmarks = df_copy.loc[target_mask, 'competitor_avg_readability']\n        \n        relative_ratio = our_scores / competitor_benchmarks\n        \n        # Assign the calculated ratios back to the original DataFrame using the mask.\n        df.loc[target_mask, feature_name] = relative_ratio\n\n    return df"
}{
  "timestamp": "2025-07-22T08:07:20.877256",
  "attempt": 6,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'word_count_relative_to_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Generates a feature that measures the word count of 'our' posts relative to the competitor average.\n\n    The hypothesis is that the relative word count ratio correlates with non-brand inflow. To overcome\n    the issue of constant values when no direct competitors exist for a query, this function implements\n    a robust fallback mechanism:\n\n    1.  It first attempts to benchmark against the average word count of competitors within the same 'representative_query' group.\n    2.  If a query group for an 'ours' post contains no competitors, it falls back to a global average word count calculated from all competitors in the dataset.\n    3.  This ensures that every 'ours' post receives a meaningful benchmark, thus creating variance in the feature column.\n    4.  Values for 'competitor' posts are defaulted to 1.0, as the feature's purpose is to evaluate 'our' content against the market.\n    5.  Handles edge cases like empty competitor sets or division by zero gracefully.\n\n    Args:\n        df (pd.DataFrame): The input dataframe with columns 'source', 'representative_query', and 'word_count'.\n\n    Returns:\n        pd.DataFrame: The dataframe with the new feature column 'word_count_relative_to_competitors'.\n    \"\"\"\n    feature_name = 'word_count_relative_to_competitors'\n    \n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # Set a default value. This will be the final value for all competitor posts.\n    df[feature_name] = 1.0\n\n    # Create boolean masks to identify 'ours' and 'competitors' posts.\n    ours_mask = df['source'] == 'ours'\n    competitors_mask = df['source'] == 'competitors'\n    \n    # If there are no 'ours' posts to calculate for, or no 'competitors' to benchmark against,\n    # the feature cannot be calculated meaningfully. Return the dataframe with the default value.\n    if not ours_mask.any() or not competitors_mask.any():\n        return df\n\n    # --- Create a robust benchmark for word count --- #\n    competitor_posts = df[competitors_mask]\n\n    # 1. Calculate per-query average word count from competitors.\n    avg_wc_by_query = competitor_posts.groupby('representative_query')['word_count'].mean()\n\n    # 2. Calculate a global average word count from all competitors to use as a fallback.\n    global_avg_wc = competitor_posts['word_count'].mean()\n    \n    # If the global average is invalid (NaN or 0), we can't create a reliable benchmark.\n    if pd.isna(global_avg_wc) or global_avg_wc == 0:\n        return df\n\n    # 3. Map the query-specific averages to the 'ours' posts.\n    # Posts in queries without competitors will get NaN.\n    benchmark_series = df.loc[ours_mask, 'representative_query'].map(avg_wc_by_query)\n\n    # 4. Fill NaN values with the global average. Now every 'ours' post has a benchmark.\n    benchmark_series = benchmark_series.fillna(global_avg_wc)\n\n    # Prevent division by zero. If a benchmark value is 0, replace it with the non-zero global average.\n    benchmark_series[benchmark_series == 0] = global_avg_wc\n\n    # --- Calculate and assign the feature value for 'ours' posts --- #\n    # The calculation is performed only on the 'ours' subset.\n    relative_word_count = df.loc[ours_mask, 'word_count'] / benchmark_series\n    \n    # Replace potential inf/NaN from division issues with the neutral value 1.0.\n    relative_word_count = relative_word_count.replace([np.inf, -np.inf], np.nan).fillna(1.0)\n\n    # Assign the calculated values back to the original DataFrame using the 'ours' mask.\n    # This ensures correct alignment and that only 'ours' posts are updated.\n    df.loc[ours_mask, feature_name] = relative_word_count\n\n    return df"
}{
  "timestamp": "2025-07-22T08:09:32.448938",
  "attempt": 7,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'word_count_relative_to_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트의 단어 수를 해당 대표 검색어의 경쟁자 포스트 그룹의 평균 단어 수와 비교하여\n    상대적인 비율을 계산합니다. 이 피처는 개별 'ours' 포스트마다 다른 값을 가지므로, 그룹 내 변동성을 생성하여\n    상관관계 분석을 가능하게 합니다. 경쟁사 데이터가 없는 경우, 비율은 1.0으로 처리됩니다.\n\n    Args:\n        df (pd.DataFrame): 'source', 'representative_query', 'word_count' 열을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'word_count_relative_to_competitors' 피처 열이 추가된 데이터프레임.\n    \"\"\"\n    feature_name = 'word_count_relative_to_competitors'\n\n    # 0. 입력 데이터프레임이 비어있는 경우, 원본을 그대로 반환\n    if df.empty:\n        df[feature_name] = pd.Series(dtype='float64')\n        return df\n\n    # 1. 'word_count'를 숫자형으로 변환 (오류 발생 시 NaN 처리)\n    df['word_count'] = pd.to_numeric(df['word_count'], errors='coerce')\n\n    # 2. 경쟁사 데이터만 분리하고, 쿼리별 평균 단어 수 계산\n    competitors_df = df[df['source'] == 'competitors'].copy()\n\n    # 경쟁사 데이터가 전혀 없는 경우, 모든 포스트의 비율을 1.0으로 설정하고 반환\n    if competitors_df.empty or competitors_df['word_count'].isna().all():\n        df[feature_name] = 1.0\n        return df\n\n    # 쿼리별 경쟁사 평균 단어 수 계산 (NaN 값은 제외)\n    competitor_avg_wc = competitors_df.dropna(\n        subset=['representative_query', 'word_count']\n    ).groupby('representative_query')['word_count'].mean()\n\n    # 유효한 경쟁사 평균이 없는 경우에도 1.0으로 설정하고 반환\n    if competitor_avg_wc.empty:\n        df[feature_name] = 1.0\n        return df\n\n    # 3. 계산된 경쟁사 평균을 원본 데이터프레임에 매핑\n    df['competitor_avg'] = df['representative_query'].map(competitor_avg_wc)\n\n    # 4. 'ours' 포스트에 대한 상대적 비율 계산\n    # 기본값을 1.0으로 설정. 이는 경쟁사 또는 비교할 평균값이 없는 'ours' 포스트에 적용됨.\n    df[feature_name] = 1.0\n\n    # 'ours' 포스트이면서 유효한 경쟁사 평균(0보다 크고 non-NaN)이 있는 경우에만 계산 수행\n    mask = (\n        (df['source'] == 'ours') &\n        (df['competitor_avg'].notna()) &\n        (df['competitor_avg'] > 0) &\n        (df['word_count'].notna())\n    )\n\n    # 마스크에 해당하는 행에 대해서만 개별 포스트의 단어 수를 경쟁사 평균으로 나눔\n    # 이 방식은 'ours' 포스트마다 다른 값을 생성하여 피처의 분산을 확보함\n    df.loc[mask, feature_name] = df.loc[mask, 'word_count'] / df.loc[mask, 'competitor_avg']\n\n    # 5. 임시로 사용한 열 제거 및 최종 정리\n    df.drop(columns=['competitor_avg'], inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T08:10:23.584509",
  "attempt": 8,
  "status": "success",
  "feature_name": "word_count_percentile_in_query",
  "hypothesis": "우리 포스트의 단어 수가 해당 대표 검색어 그룹(경쟁사 포함) 내에서 차지하는 백분위 순위가 높을수록, 더 종합적인 콘텐츠임을 나타내어 더 높은 비브랜드 유입과 관련이 있을 것입니다. 백분위 순위가 높다는 것은 동일 주제의 다른 문서들보다 단어 수가 많다는 의미입니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 포스트의 단어 수가 해당 대표 검색어 그룹 내에서 차지하는 백분위 순위를 계산합니다.\n\n    가설:\n    우리 포스트의 단어 수가 해당 대표 검색어 그룹(경쟁사 포함) 내에서 차지하는 백분위 순위가 높을수록,\n    더 종합적인 콘텐츠임을 나타내어 더 높은 비브랜드 유입과 관련이 있을 것입니다.\n    백분위 순위가 높다는 것은 동일 주제의 다른 문서들보다 단어 수가 많다는 의미입니다.\n\n    Root Cause of Previous Error:\n    이전 코드는 '우리' 포스트의 개별 단어 수를 '경쟁사' 포스트들의 '평균' 단어 수라는 단일 벤치마크 값으로 나누어 계산했습니다.\n    만약 테스트 데이터셋에 특정 대표 검색어 그룹이 하나만 있거나, 경쟁사 데이터가 없는 경우,\n    모든 '우리' 포스트가 동일한 벤치마크 값으로 비교되어 결과 피처 값이 상수로 생성되는 문제가 있었습니다.\n    이는 상관관계 분석에 필요한 분산(variance)을 없애는 결과를 초래했습니다.\n\n    Correction:\n    이 문제를 해결하기 위해, 그룹별 '평균'이라는 단일 값 벤치마크를 사용하는 대신, 그룹 내 순위(rank)를 사용하는 방식으로 변경합니다.\n    `groupby('representative_query')['word_count'].rank(pct=True)`를 사용하여 각 포스트의 단어 수를 해당 검색어 그룹에 속한\n    모든 포스트(자사, 경쟁사 포함)와 비교하여 백분위 순위를 계산합니다. 이 방식은 다음과 같은 장점이 있습니다.\n    1. 그룹 내에 포스트가 여러 개고 단어 수가 다르다면 항상 다른 순위 값이 부여되어 분산이 보장됩니다.\n    2. 경쟁사 데이터가 없는 그룹의 경우, 우리 포스트끼리 순위가 매겨져 피처가 유의미한 값을 갖게 됩니다.\n    3. 그룹 평균이라는 집계된 값 대신 개별 값을 비교하므로, 데이터의 미묘한 차이를 피처에 반영할 수 있습니다.\n    \"\"\"\n    feature_name = 'word_count_percentile_in_query'\n\n    if df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # 원본 데이터프레임의 수정을 피하기 위해 복사본 사용\n    df_copy = df.copy()\n\n    # 'word_count'가 숫자형인지 확인하고, 아니거나 NaN이면 0으로 처리\n    df_copy['word_count'] = pd.to_numeric(df_copy['word_count'], errors='coerce').fillna(0)\n\n    # 'representative_query' 그룹 내에서 'word_count'의 백분위 순위 계산\n    # rank(pct=True)는 0.0에서 1.0 사이의 백분위 순위를 반환합니다.\n    # 이 방법은 그룹에 포스트가 하나만 있는 경우(순위 1.0 반환)에도 작동하며,\n    # 경쟁사가 없는 그룹의 경우에도 'ours' 포스트끼리 순위가 매겨집니다.\n    # 이는 그룹 내 포스트들의 단어 수가 다른 한, 항상 분산을 생성합니다.\n    df[feature_name] = df_copy.groupby('representative_query')['word_count'].rank(pct=True, method='average')\n\n    # 그룹이 비어 있거나 다른 문제로 인해 발생할 수 있는 NaN 값을 처리합니다.\n    # 백분위의 중간값인 0.5로 채우는 것이 합리적인 기본값입니다.\n    df[feature_name] = df[feature_name].fillna(0.5)\n\n    return df",
  "analysis": {
    "correlation": 0.09295430879697471,
    "p_value": 0.37027708242742285,
    "interpretation": "약한 양의 상관관계(0.0930)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3703)."
  }
}{
  "timestamp": "2025-07-22T10:08:29.267478",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'word_count_optimality_score'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    경쟁사 평균 단어 수 대비 우리 포스트 단어 수의 비율이 이상적인 값(1.2)에 얼마나 가까운지를 측정합니다.\n\n    가설: 이상적인 비율에 가까울수록(즉, 점수가 0에 가까울수록) 성과가 높을 것이다.\n    계산: score = -abs((our_word_count / competitor_avg_word_count) - 1.2)\n    - 경쟁사가 없는 경우, 전체 경쟁사 평균을 벤치마크로 사용합니다.\n    - 'ours' 포스트에 대해서만 계산되며, 'competitors' 포스트는 NaN으로 남습니다.\n    \"\"\"\n    feature_name = 'word_count_optimality_score'\n    df[feature_name] = np.nan\n\n    if df.empty:\n        return df\n\n    # 1. Define the ideal ratio based on the hypothesis\n    IDEAL_RATIO = 1.2\n\n    # 2. Separate 'ours' and 'competitors' data, preserving original index\n    ours_df = df[df['source'] == 'ours']\n    competitors_df = df[df['source'] == 'competitors']\n\n    if ours_df.empty:\n        return df # No 'ours' posts to calculate the feature for\n\n    # 3. Calculate competitor benchmarks\n    # Benchmark 1: Per-query average word count\n    competitor_avg_by_query = competitors_df.groupby('representative_query')['word_count'].mean()\n\n    # Benchmark 2: Global average for fallback\n    if not competitors_df.empty:\n        global_competitor_avg = competitors_df['word_count'].mean()\n    else:\n        # If no competitors exist at all, the feature cannot be calculated meaningfully.\n        # Let it remain NaN for all posts.\n        return df\n\n    # 4. Map the per-query benchmark to each 'ours' post\n    # A temporary Series to hold the benchmark value for each 'ours' post\n    benchmark_wc = ours_df['representative_query'].map(competitor_avg_by_query)\n\n    # 5. Apply the global fallback for 'ours' posts in queries without competitors\n    benchmark_wc.fillna(global_competitor_avg, inplace=True)\n\n    # 6. Calculate the optimality score only for 'ours' posts\n    # Ensure the denominator is not zero or NaN to avoid errors\n    valid_benchmark_mask = benchmark_wc.notna() & (benchmark_wc > 0)\n    \n    if valid_benchmark_mask.any():\n        # Calculate ratio only for rows with a valid benchmark\n        our_word_counts = ours_df.loc[valid_benchmark_mask, 'word_count']\n        valid_benchmarks = benchmark_wc[valid_benchmark_mask]\n        \n        ratios = our_word_counts / valid_benchmarks\n        \n        # The score is the negative absolute deviation from the ideal ratio.\n        # A score closer to 0 is better.\n        scores = -abs(ratios - IDEAL_RATIO)\n        \n        # 7. Assign the calculated scores back to the original DataFrame\n        df.loc[scores.index, feature_name] = scores\n\n    return df"
}{
  "timestamp": "2025-07-22T10:10:14.365826",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'numeric_density_ratio_vs_competitor_avg'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    우리 포스트의 수치 데이터 밀도를 경쟁사 평균과 비교하여 상대적 우월성 지표를 생성합니다.\n\n    이 피처는 각 'ours' 포스트의 'numeric_data_density'를 해당 'representative_query'에 속하는\n    경쟁사 포스트들의 평균 'numeric_data_density'로 나눈 값입니다. 경쟁사 데이터가 없는 쿼리의 경우,\n    전체 경쟁사의 글로벌 평균을 대체 벤치마크로 사용합니다.\n\n    Args:\n        df (pd.DataFrame): 'source', 'representative_query', 'numeric_data_density' 열을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'numeric_density_ratio_vs_competitor_avg' 열이 추가된 데이터프레임.\n    \"\"\"\n    feature_name = 'numeric_density_ratio_vs_competitor_avg'\n\n    # 필수 열 존재 여부 및 데이터프레임 비어있는지 확인\n    required_cols = ['source', 'representative_query', 'numeric_data_density']\n    if df.empty or not all(col in df.columns for col in required_cols):\n        df[feature_name] = 1.0\n        return df\n\n    # 피처 열을 기본값 1.0으로 초기화합니다. 이 값은 경쟁사 포스트나 계산이 불가능한 우리 포스트에 유지됩니다.\n    df[feature_name] = 1.0\n\n    # 벤치마크 계산을 위해 경쟁사 데이터 필터링\n    competitors = df[df['source'] == 'competitors'].copy()\n\n    # 경쟁사 데이터가 없으면 벤치마크를 생성할 수 없으므로 기본값(1.0)을 가진 df를 반환합니다.\n    if competitors.empty or competitors['numeric_data_density'].isnull().all():\n        return df\n\n    # 1. 기본 벤치마크: 쿼리별 경쟁사 평균 수치 밀도\n    competitor_avg_per_query = competitors.groupby('representative_query')['numeric_data_density'].mean()\n\n    # 2. 대체 벤치마크: 전체 경쟁사의 글로벌 평균 수치 밀도 (쿼리별 벤치마크가 없는 경우 사용)\n    global_competitor_avg = competitors['numeric_data_density'].mean()\n\n    # 각 포스트에 해당하는 벤치마크 값을 매핑하기 위한 임시 열 생성\n    # 쿼리별 평균을 먼저 매핑하고, 매핑되지 않은 (NaN) 경우 글로벌 평균으로 채웁니다.\n    df['benchmark_density'] = df['representative_query'].map(competitor_avg_per_query)\n    df['benchmark_density'].fillna(global_competitor_avg, inplace=True)\n\n    # 'ours' 포스트만 선택하여 피처 계산을 수행합니다.\n    ours_mask = df['source'] == 'ours'\n    if not ours_mask.any():\n        df.drop(columns=['benchmark_density'], inplace=True)\n        return df\n\n    our_values = df.loc[ours_mask, 'numeric_data_density']\n    benchmark_values = df.loc[ours_mask, 'benchmark_density']\n\n    # 0으로 나누는 것을 방지하기 위해 벤치마크 값이 0이 아닌 유효한 경우만 계산합니다.\n    # np.isscalar로 global_competitor_avg가 단일 값인지 확인 후 0과 비교\n    valid_benchmark_mask = (benchmark_values.notna()) & (benchmark_values != 0)\n    \n    if valid_benchmark_mask.any():\n        # 유효한 벤치마크를 가진 'ours' 포스트의 인덱스를 가져옵니다.\n        valid_indices = df.loc[ours_mask & valid_benchmark_mask].index\n        \n        # 해당 인덱스에 대해서만 비율을 계산합니다.\n        ratios = our_values.loc[valid_indices] / benchmark_values.loc[valid_indices]\n        \n        # 계산된 비율을 원래 데이터프레임의 피처 열에 할당합니다.\n        df.loc[valid_indices, feature_name] = ratios\n\n    # 임시로 사용한 벤치마크 열을 삭제합니다.\n    df.drop(columns=['benchmark_density'], inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T10:10:59.134758",
  "attempt": 3,
  "status": "success",
  "feature_name": "readability_percentile_rank_in_query",
  "hypothesis": "사용자가 콘텐츠를 얼마나 쉽게 이해할 수 있는지를 나타내는 '가독성 점수'는 중요한 품질 지표입니다. 특정 검색어 그룹 내에서 우리 포스트의 가독성 점수 백분위 순위(readability_percentile_rank_in_query)가 높을수록 (즉, 경쟁자들보다 읽기 쉬울수록) 사용자의 만족도가 높아져 체류 시간이 길어지고, 이는 검색 엔진에 긍정적인 신호로 작용하여 'non_brand_inflow'와 유의미한 양의 상관관계를 보일 것입니다. 이 순위는 그룹 내 직접적인 경쟁을 반영하므로 단순 비율보다 더 정확한 상대적 품질을 측정합니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 대표 검색어 그룹 내에서 'readability_score'의 백분위 순위를 계산하여\n    경쟁 환경 내에서의 상대적 가독성 위치를 나타내는 피처를 생성합니다.\n\n    Args:\n        df (pd.DataFrame): 'representative_query'와 'readability_score' 열을 포함하는 데이터프레임.\n\n    Returns:\n        pd.DataFrame: 'readability_percentile_rank_in_query' 열이 추가된 데이터프레임.\n    \"\"\"\n    # 1. 입력 데이터프레임 유효성 검사\n    if df.empty or 'representative_query' not in df.columns or 'readability_score' not in df.columns:\n        # 필수 컬럼이 없거나 비어있는 경우, 원본 DataFrame 반환\n        if 'readability_percentile_rank_in_query' not in df.columns:\n             df['readability_percentile_rank_in_query'] = 0.5 # 중간값으로 채움\n        return df\n\n    # 2. 이전 오류(상수 값) 해결 로직:\n    #    - 이전 방식: 'ours' 포스트를 'competitors' 평균과 직접 비교하는 방식은\n    #      경쟁사 데이터가 없는 그룹에서 NaN/기본값을 생성하여 상수 피처를 유발했습니다.\n    #    - 새 방식: 'ours'와 'competitors'를 모두 포함하여 그룹 전체에서 순위를 매깁니다.\n    #      이 방식은 경쟁사가 없는 그룹에서도 자체적으로 순위를 매겨 유효한 값을 생성하고,\n    #      그룹별로 다른 순위 분포를 가져 전체 피처의 분산을 보장합니다.\n\n    # 3. 'representative_query'로 그룹화하여 'readability_score'의 백분위 순위(percentile rank) 계산\n    #    pct=True는 결과를 0과 1 사이의 백분위로 변환합니다.\n    #    method='average'는 동점일 경우 평균 순위를 부여합니다.\n    df['readability_percentile_rank_in_query'] = df.groupby('representative_query')['readability_score'].rank(method='average', pct=True)\n\n    # 4. 계산 과정에서 발생할 수 있는 NaN 값을 처리 (예: 그룹 내 모든 가독성 점수가 NaN인 경우)\n    #    이런 경우 중간값인 0.5로 채워 통계적 왜곡을 최소화합니다.\n    df['readability_percentile_rank_in_query'].fillna(0.5, inplace=True)\n\n    return df",
  "analysis": {
    "correlation": -0.16891279605037834,
    "p_value": 0.1017675697292799,
    "interpretation": "약한 음의 상관관계(-0.1689)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.1018)."
  }
}