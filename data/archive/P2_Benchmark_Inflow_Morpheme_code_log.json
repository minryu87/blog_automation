{
  "timestamp": "2025-07-22T04:06:06.290161",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'morpheme_relevance_ratio_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n# konlpy is a required external library.\n# It might need to be installed via: pip install konlpy\n# It also requires a Java installation on the system.\nfrom konlpy.tag import Okt\n\n# 1. Lazy-load the morpheme analyzer model to avoid re-initializing it on every call.\n_okt = None\n\ndef get_okt():\n    \"\"\"Initializes and returns a singleton Okt instance.\"\"\"\n    global _okt\n    if _okt is None:\n        _okt = Okt()\n    return _okt\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Generates a feature benchmarking our post's morpheme relevance to the query\n    against the average relevance of competitor posts.\n    \"\"\"\n    feature_name = 'morpheme_relevance_ratio_vs_competitors'\n    df[feature_name] = np.nan\n\n    if df.empty:\n        return df\n\n    required_cols = ['representative_query', 'morpheme_words', 'source']\n    if not all(col in df.columns for col in required_cols):\n        return df\n\n    try:\n        okt = get_okt()\n    except Exception:\n        # Silently fail and return the original DataFrame if konlpy/Java is not available.\n        # In a production environment, this should be logged.\n        return df\n\n    # --- Step 1: Calculate Jaccard relevance for all posts ---\n    # Memoize morphemes from queries to avoid redundant computation\n    unique_queries = df['representative_query'].dropna().unique()\n    query_morphemes_cache = {\n        query: set(okt.morphs(query)) for query in unique_queries\n    }\n    \n    # Helper function to compute Jaccard score for a row\n    def calculate_jaccard(row):\n        query = row['representative_query']\n        morpheme_str = row['morpheme_words']\n        \n        if pd.isna(query) or pd.isna(morpheme_str):\n            return 0.0\n            \n        query_set = query_morphemes_cache.get(query, set())\n        # The morpheme_words column is a pre-tokenized, comma-separated string\n        post_set = set(m.strip() for m in morpheme_str.split(',') if m.strip())\n        \n        # Handle cases with empty sets\n        if not query_set and not post_set: return 1.0 # Parity if both are empty\n        if not query_set or not post_set: return 0.0 # No overlap if one is empty\n        \n        intersection = len(query_set.intersection(post_set))\n        union = len(query_set.union(post_set))\n        \n        return intersection / union if union > 0 else 0.0\n\n    # Apply the function to get relevance scores for all posts\n    df['jaccard_relevance'] = df.apply(calculate_jaccard, axis=1)\n\n    # --- Step 2: Calculate competitor average and the final ratio ---\n    # Use transform to broadcast the competitor group's average relevance to all rows in that group.\n    # This correctly handles groups and preserves the original DataFrame structure.\n    df['competitor_avg_relevance'] = df.groupby('representative_query')['jaccard_relevance'].transform(\n        lambda x: x[df.loc[x.index, 'source'] == 'competitor'].mean()\n    )\n    \n    # Calculate the ratio only for 'ours' posts\n    our_rows_mask = df['source'] == 'ours'\n    if our_rows_mask.any():\n        our_relevance = df.loc[our_rows_mask, 'jaccard_relevance']\n        competitor_avg = df.loc[our_rows_mask, 'competitor_avg_relevance']\n\n        # Perform division, ignoring errors for now to handle them explicitly\n        with np.errstate(divide='ignore', invalid='ignore'):\n            ratio = our_relevance / competitor_avg\n\n        # --- Step 3: Handle edge cases from division ---\n        # Case 1: our > 0, comp_avg = 0 -> inf. Our post is relevant, competitors are not. Cap at 2.0 for stability.\n        ratio.replace([np.inf, -np.inf], 2.0, inplace=True)\n        \n        # Case 2: our = 0, comp_avg = 0 -> NaN. Parity. Both are irrelevant. Set to 1.0.\n        # We select only the NaNs that arose from a 0/0 division.\n        is_zero_zero_nan = (our_relevance == 0) & (competitor_avg == 0)\n        ratio.loc[is_zero_zero_nan] = 1.0\n        \n        # Case 3: comp_avg is NaN (no competitors in group). The ratio will be NaN. This is the desired outcome.\n        \n        # Assign the final calculated values back to the original DataFrame\n        df.loc[our_rows_mask, feature_name] = ratio\n\n    # --- Step 4: Clean up temporary columns ---\n    df.drop(columns=['jaccard_relevance', 'competitor_avg_relevance'], inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T04:07:05.412612",
  "attempt": 2,
  "status": "success",
  "feature_name": "core_morpheme_freq_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹보다 대표 검색어의 핵심 형태소를 더 높은 빈도로 사용할수록, 해당 검색어 의도에 더 최적화되어 비브랜드 유입량이 증가할 것입니다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 검색어의 핵심 형태소 사용 빈도를 우리 포스트와 경쟁자 포스트 그룹 간에 비교하여 비율을 계산합니다.\n\n    이 피처는 우리 포스트가 경쟁사보다 핵심 주제어에 얼마나 더 집중하고 있는지를 측정합니다.\n    비율이 1보다 크면 우리 포스트가 경쟁사 평균보다 핵심 형태소를 더 자주 사용했음을 의미합니다.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'core_morpheme_freq_ratio'\n    df[feature_name] = np.nan\n\n    # Helper function to safely process morpheme strings\n    def _get_morphemes_list(text):\n        if isinstance(text, str):\n            return text.split()\n        return []\n\n    # Group by representative query to create context-specific benchmarks\n    grouped = df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        # Ensure the query is a valid string to process\n        if not isinstance(query, str) or not query.strip():\n            continue\n\n        # 1. Define core morphemes from the query itself.\n        core_morphemes = set(_get_morphemes_list(query))\n        if not core_morphemes:\n            continue\n\n        # 2. Isolate 'ours' and 'competitor' posts for the current group\n        competitors_df = group_df[group_df['source'] == 'competitor']\n        ours_df = group_df[group_df['source'] == 'ours']\n\n        # A comparison is only possible if both groups exist\n        if competitors_df.empty or ours_df.empty:\n            continue\n\n        # 3. Calculate the frequency of core morphemes for each competitor\n        competitor_freqs = competitors_df['morpheme_words'].apply(\n            lambda text: sum(1 for morpheme in _get_morphemes_list(text) if morpheme in core_morphemes)\n        )\n        competitor_avg_freq = competitor_freqs.mean()\n\n        # 4. Calculate the frequency for each of our own posts\n        # This ensures each 'ours' post gets a unique score based on its own content\n        ours_freqs = ours_df['morpheme_words'].apply(\n            lambda text: sum(1 for morpheme in _get_morphemes_list(text) if morpheme in core_morphemes)\n        )\n\n        # 5. Calculate the ratio, handling division-by-zero scenarios\n        if competitor_avg_freq > 0:\n            ratio = ours_freqs / competitor_avg_freq\n        else:\n            # If competitors don't use the terms, any usage by us is significantly better.\n            # We assign a high value (e.g., 5.0) for posts that use the term, and 1.0 (on-par) if we also don't.\n            ratio = ours_freqs.apply(lambda x: 5.0 if x > 0 else 1.0)\n\n        # 6. Safely assign the calculated ratios back to the original dataframe using index\n        df.loc[ours_df.index, feature_name] = ratio\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T04:25:55.455468",
  "attempt": 1,
  "status": "execution_error",
  "error": "코드 실행 실패:\n  File \"/Users/min/codes/medilawyer_sales/blog_automation/agents/_temp_feature_generator.py\", line 20\n    try\n       ^\nSyntaxError: expected ':'\n",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\nfrom itertools import chain\n\ndef _parse_morpheme_list(morpheme_str):\n    \"\"\"Safely parses a string representation of a list into a Python list.\"\"\"\n    if not isinstance(morpheme_str, str) or not morpheme_str.startswith('['):\n        return []\n    try\n        return ast.literal_eval(morpheme_str)\n    except (ValueError, SyntaxError):\n        return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the morpheme differentiation score for each of our posts.\n    This score represents the proportion of morphemes in our post that are unique\n    compared to the entire set of morphemes used by competitors for the same query.\n    A higher score indicates greater morphemic differentiation.\n    \"\"\"\n    feature_name = 'morpheme_differentiation_score'\n\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # Use a copy for intermediate calculations to avoid SettingWithCopyWarning\n    df_copy = df.copy()\n    df_copy[feature_name] = np.nan\n\n    # Pre-process the morpheme_words column into lists for efficiency\n    df_copy['morpheme_list'] = df_copy['morpheme_words'].apply(_parse_morpheme_list)\n\n    # Group by representative_query to handle each benchmark set individually\n    grouped = df_copy.groupby('representative_query')\n\n    for _, group_df in grouped:\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        # Proceed only if both our posts and competitor posts exist for the query\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        # Create a single set of all unique morphemes used by all competitors in the group\n        all_competitor_morphemes = set(chain.from_iterable(competitor_posts['morpheme_list']))\n\n        # Calculate the score for each of our posts in the group\n        for idx, our_post in ours_posts.iterrows():\n            our_morphemes = set(our_post['morpheme_list'])\n\n            if not our_morphemes:  # Handle cases with no morphemes\n                score = 0.0\n            else:\n                # Find morphemes that are in our post but not in any competitor post\n                unique_to_ours = our_morphemes.difference(all_competitor_morphemes)\n                # Calculate the differentiation score as a ratio\n                score = len(unique_to_ours) / len(our_morphemes)\n\n            # CRITICAL: Assign the calculated score back to the original DataFrame using its index\n            df.loc[idx, feature_name] = score\n            \n    # For 'ours' posts in groups without competitors, the score remains NaN. Fill with 0.\n    df[feature_name].fillna(0.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T04:26:54.133668",
  "attempt": 2,
  "status": "success",
  "feature_name": "morpheme_expansion_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹의 전체 형태소 어휘집에 포함되지 않은 '확장' 형태소를 더 높은 비율로 포함할수록, 이는 콘텐츠의 독창성과 깊이를 나타내어 사용자의 탐색적 의도를 충족시키고 더 높은 비브랜드 유입을 유도할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the morpheme expansion ratio for each of 'our' posts compared to its competitors for the same query.\n    The ratio is defined as:\n    (Number of unique morphemes in our post that are NOT in the competitor vocabulary) / (Total number of unique morphemes in our post)\n\n    This feature aims to quantify content differentiation at the morpheme level, testing the hypothesis that\n    using a unique vocabulary beyond what competitors use correlates with better performance.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'morpheme_expansion_ratio'\n    # Initialize or clean the feature column to prevent errors\n    df[feature_name] = pd.to_numeric(df.get(feature_name), errors='coerce')\n\n    def parse_morphemes(morpheme_string: str) -> set:\n        \"\"\"Safely parses the morpheme string from the 'morpheme_words' column into a set of unique morphemes.\"\"\"\n        if not isinstance(morpheme_string, str) or not morpheme_string.strip():\n            return set()\n        # Handles cases like 'morpheme1, morpheme2, ...' and removes empty strings from split\n        return set(m.strip() for m in morpheme_string.split(',') if m.strip())\n\n    # Use a temporary column for parsed sets to avoid repeated parsing\n    df['morpheme_sets'] = df['morpheme_words'].apply(parse_morphemes)\n\n    results = []\n\n    # Group by 'representative_query' to create a benchmark for each query\n    for query, group in df.groupby('representative_query'):\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitors']\n\n        # Skip if there are no 'ours' posts or no competitors to compare against\n        if ours_posts.empty or competitor_posts.empty:\n            for idx in ours_posts.index:\n                results.append({'index': idx, 'score': 0.0})\n            continue\n\n        # Create a single vocabulary set containing all unique morphemes used by all competitors\n        competitor_vocab = set().union(*competitor_posts['morpheme_sets'])\n\n        # Calculate the expansion ratio for each of our posts in the current query group\n        for idx, row in ours_posts.iterrows():\n            our_morphemes = row['morpheme_sets']\n\n            if not our_morphemes:\n                results.append({'index': idx, 'score': 0.0})\n                continue\n\n            # Find morphemes that are in our post but not in the competitor vocabulary\n            expansion_morphemes = our_morphemes.difference(competitor_vocab)\n            \n            total_our_morphemes = len(our_morphemes)\n            \n            # Calculate the ratio. If our post has no morphemes, the ratio is 0.\n            ratio = len(expansion_morphemes) / total_our_morphemes if total_our_morphemes > 0 else 0.0\n            \n            results.append({'index': idx, 'score': ratio})\n\n    # Efficiently assign the calculated scores back to the main DataFrame\n    if results:\n        results_df = pd.DataFrame(results).set_index('index')\n        df[feature_name] = results_df['score']\n\n    # Clean up the temporary column\n    df.drop(columns=['morpheme_sets'], inplace=True)\n    \n    # Ensure any 'ours' post that couldn't be scored (e.g., no competitors for its query)\n    # defaults to 0.0 instead of NaN.\n    our_indices = df[df['source'] == 'ours'].index\n    df.loc[our_indices, feature_name] = df.loc[our_indices, feature_name].fillna(0.0)\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T04:44:07.552593",
  "attempt": 1,
  "status": "success",
  "feature_name": "relative_morpheme_expansion",
  "hypothesis": "우리 포스트가 대표 검색어의 핵심 형태소를 포함하는 파생/관련 형태소를 경쟁자 그룹의 평균보다 더 다양하게 사용할수록, 검색 의도에 대한 깊이 있는 답변으로 인식되어 비브랜드 유입량이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Generates the 'relative_morpheme_expansion' feature.\n\n    This feature quantifies how diversely our post expands on core morphemes from the\n    representative query, compared to the average competitor.\n\n    1.  Identifies core morphemes from the 'representative_query'.\n    2.  For each post, counts the number of unique morphemes in 'morpheme_words' that\n        contain any of the core morphemes (the 'variety').\n    3.  For each query, calculates the average variety for all 'competitors' posts.\n    4.  For each 'ours' post, calculates the ratio: (our_variety) / (competitor_average_variety).\n    \"\"\"\n    if df.empty:\n        return df\n\n    # Use a temporary DataFrame to avoid modifying the original during intermediate steps\n    temp_df = df[['representative_query', 'morpheme_words', 'source']].copy()\n    temp_df.index = df.index  # Preserve original index\n\n    # 1. Pre-process data: create lists of morphemes from strings\n    temp_df['morpheme_list'] = temp_df['morpheme_words'].fillna('').str.split(', ')\n    temp_df['core_morphemes'] = temp_df['representative_query'].fillna('').str.split()\n\n    # Helper function to calculate the variety of expanded morphemes for a single post\n    def calculate_variety(morpheme_list, core_morphemes):\n        if not core_morphemes or not morpheme_list:\n            return 0\n        # Use a set for efficient collection of unique morphemes\n        expanded_set = {\n            morpheme\n            for morpheme in morpheme_list\n            for core in core_morphemes\n            if core in morpheme\n        }\n        return len(expanded_set)\n\n    # 2. Calculate the variety for every post using an efficient list comprehension\n    temp_df['variety'] = [\n        calculate_variety(m_list, c_list)\n        for m_list, c_list in zip(temp_df['morpheme_list'], temp_df['core_morphemes'])\n    ]\n\n    # 3. Calculate the average variety for competitors, grouped by query\n    competitors_df = temp_df[temp_df['source'] == 'competitors']\n    avg_competitor_variety = competitors_df.groupby('representative_query')['variety'].mean().rename('avg_competitor_variety')\n\n    # 4. Map the competitor average back to the main temp_df\n    temp_df = temp_df.merge(avg_competitor_variety, on='representative_query', how='left')\n\n    # 5. For 'ours' posts only, calculate the final ratio\n    ours_mask = temp_df['source'] == 'ours'\n    our_varieties = temp_df.loc[ours_mask, 'variety']\n    our_competitor_avgs = temp_df.loc[ours_mask, 'avg_competitor_variety']\n\n    # Handle cases with no competitors (avg is NaN) by filling with 0\n    # Add a small epsilon to the denominator to prevent division by zero\n    ratios = our_varieties / (our_competitor_avgs.fillna(0) + 1e-6)\n\n    # 6. Assign the calculated ratios back to the original DataFrame's new column\n    # .loc assignment with the mask ensures values are placed in the correct rows\n    df['relative_morpheme_expansion'] = ratios\n\n    return df",
  "analysis": {
    "correlation": 0.012581772873433764,
    "p_value": 0.9036805053198543,
    "interpretation": "약한 양의 상관관계(0.0126)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.9037)."
  }
}{
  "timestamp": "2025-07-22T05:04:19.556386",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'morpheme_exclusivity_score'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef parse_morphemes(morpheme_string: str) -> set:\n    \"\"\"\n    Parses a comma-separated morpheme string into a set of unique morphemes.\n    Handles potential NaN values and ensures clean, non-empty morphemes.\n    \"\"\"\n    if pd.isna(morpheme_string) or not morpheme_string:\n        return set()\n    # Split by comma, strip whitespace from each item, and filter out any empty strings\n    return {morpheme.strip() for morpheme in morpheme_string.split(',') if morpheme.strip()}\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the morpheme exclusivity score for our posts compared to competitors.\n\n    This feature measures the proportion of unique morphemes in our post\n    that are NOT used by any competitor for the same representative query.\n    A higher score indicates a more unique lexical structure, suggesting\n    differentiated and potentially more valuable content.\n    \"\"\"\n    # Initialize the feature column with a default value.\n    df['morpheme_exclusivity_score'] = 0.0\n\n    # Check if essential columns are missing to prevent errors.\n    if 'morpheme_words' not in df.columns or 'representative_query' not in df.columns:\n        return df\n    \n    # Check for empty DataFrame to avoid errors on groupby\n    if df.empty:\n        return df\n\n    # Group by the representative query to analyze each SERP landscape individually.\n    grouped = df.groupby('representative_query')\n\n    for _, group_df in grouped:\n        # Separate 'ours' from 'competitors' while preserving the original index.\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitors']\n\n        # Proceed only if we have both our posts and competitor data for comparison.\n        if competitors_df.empty or ours_df.empty:\n            continue\n\n        # Create a comprehensive set of all unique morphemes used by all competitors in the group.\n        competitor_morpheme_sets = competitors_df['morpheme_words'].apply(parse_morphemes).tolist()\n        competitor_universe = set.union(*competitor_morpheme_sets) if competitor_morpheme_sets else set()\n\n        # Calculate the exclusivity score for each of our posts within the group.\n        for index, row in ours_df.iterrows():\n            our_morphemes_set = parse_morphemes(row['morpheme_words'])\n            \n            if not our_morphemes_set:\n                # If our post has no morphemes, its exclusivity score is 0.\n                score = 0.0\n            else:\n                # Identify morphemes present in our post but absent from the entire competitor universe.\n                exclusive_morphemes = our_morphemes_set.difference(competitor_universe)\n                \n                # The score is the ratio of exclusive morphemes to the total number of unique morphemes.\n                score = len(exclusive_morphemes) / len(our_morphemes_set)\n            \n            # Safely assign the calculated score back to the main DataFrame using the original index.\n            df.loc[index, 'morpheme_exclusivity_score'] = score\n            \n    return df"
}{
  "timestamp": "2025-07-22T05:05:21.008247",
  "attempt": 2,
  "status": "success",
  "feature_name": "core_morpheme_structural_ratio",
  "hypothesis": "경쟁사 그룹에서 가장 빈번하게 사용되는 핵심 형태소(Core Morphemes)는 해당 주제의 핵심 구조를 나타냅니다. 우리 포스트가 이 핵심 형태소들을 경쟁사 평균과 유사하거나 약간 더 높은 비율로 포함할 때 더 나은 성과를 보일 것입니다. 이 비율이 1.0에 가까우면 주제 초점이 잘 맞춰졌음을 의미하며, 너무 낮으면 내용이 부실하고, 너무 높으면 키워드 스터핑으로 인식될 수 있습니다.",
  "code": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\n\ndef _parse_morphemes_to_list(morpheme_string):\n    \"\"\"Parses a comma-separated string of morphemes into a list of strings.\"\"\"\n    if pd.isna(morpheme_string) or not morpheme_string:\n        return []\n    return [m.strip() for m in morpheme_string.split(',')]\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    우리 포스트가 경쟁사 그룹의 '핵심 형태소'를 얼마나 집중적으로 다루는지 측정합니다.\n    1. 각 대표 쿼리별로 경쟁사 그룹의 형태소 사용 빈도를 분석하여 상위 N개의 '핵심 형태소'를 정의합니다.\n    2. 경쟁사 포스트들이 평균적으로 얼마나 이 핵심 형태소를 포함하는지 '경쟁사 평균 핵심 비율'을 계산합니다.\n    3. 우리 각 포스트의 '핵심 형태소 포함 비율'을 계산합니다.\n    4. '우리 포스트 비율' / '경쟁사 평균 비율'을 계산하여 최종 점수를 부여합니다. 1보다 크면 경쟁사보다 핵심 주제에 더 집중했음을 의미합니다.\n    \"\"\"\n    feature_name = 'core_morpheme_structural_ratio'\n    df[feature_name] = np.nan\n\n    if df.empty:\n        return df\n\n    required_cols = ['representative_query', 'source', 'morpheme_words']\n    if not all(col in df.columns for col in required_cols):\n        # One of the required columns is missing.\n        return df\n\n    # Hyperparameter: Define how many of the most frequent competitor morphemes constitute the \"core\"\n    TOP_N_MORPHEMES = 10\n\n    grouped = df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        # Preserve original index for safe assignment later\n        our_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        if competitor_posts.empty or our_posts.empty:\n            continue\n\n        # Step 1: Determine the \"core\" morphemes from the competitor group\n        all_competitor_morphemes = []\n        for morphemes_str in competitor_posts['morpheme_words'].dropna():\n            all_competitor_morphemes.extend(_parse_morphemes_to_list(morphemes_str))\n\n        if not all_competitor_morphemes:\n            continue\n\n        morpheme_counts = Counter(all_competitor_morphemes)\n        core_morphemes = set([m for m, count in morpheme_counts.most_common(TOP_N_MORPHEMES)])\n\n        if not core_morphemes:\n            continue\n\n        # Step 2: Calculate the average core ratio for competitors (the benchmark)\n        competitor_ratios = []\n        for index, row in competitor_posts.iterrows():\n            competitor_morpheme_list = _parse_morphemes_to_list(row['morpheme_words'])\n            if not competitor_morpheme_list:\n                continue\n\n            core_count = sum(1 for m in competitor_morpheme_list if m in core_morphemes)\n            ratio = core_count / len(competitor_morpheme_list)\n            competitor_ratios.append(ratio)\n\n        if not competitor_ratios or np.mean(competitor_ratios) == 0:\n            # If benchmark ratio is 0 or cannot be calculated, comparison is meaningless.\n            continue\n\n        competitor_avg_core_ratio = np.mean(competitor_ratios)\n\n        # Step 3 & 4: Calculate the score for each of our posts relative to the benchmark\n        for index, row in our_posts.iterrows():\n            our_morpheme_list = _parse_morphemes_to_list(row['morpheme_words'])\n\n            if not our_morpheme_list:\n                our_post_core_ratio = 0.0\n            else:\n                our_core_count = sum(1 for m in our_morpheme_list if m in core_morphemes)\n                our_post_core_ratio = our_core_count / len(our_morpheme_list)\n\n            # Calculate the final feature value relative to the competitor benchmark\n            final_score = our_post_core_ratio / competitor_avg_core_ratio\n            df.loc[index, feature_name] = final_score\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T05:26:31.043175",
  "attempt": 1,
  "status": "success",
  "feature_name": "morpheme_differentiation_score",
  "hypothesis": "우리 포스트가 동일 검색어에 대한 경쟁 포스트들에서 잘 사용되지 않는, 차별화된 형태소 집합을 사용할수록, 틈새 사용자 의도를 더 잘 포착하고 더 넓은 범위의 롱테일 키워드에 대해 순위를 확보하여, 결과적으로 더 높은 비브랜드 유입을 유도할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef _safe_literal_eval(val):\n    \"\"\"\n    Safely evaluates a string that looks like a list.\n    Handles NaNs, non-string inputs, and malformed strings.\n    \"\"\"\n    if isinstance(val, list):\n        return val\n    try:\n        # Ensure the input is a string before trying to evaluate\n        if isinstance(val, str):\n            return ast.literal_eval(val)\n    except (ValueError, SyntaxError, TypeError, MemoryError):\n        # Return an empty list if evaluation fails for any reason\n        pass\n    return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates a morpheme differentiation score for each 'ours' post.\n    This score represents the proportion of a post's unique morphemes\n    that are NOT used by any competitor for the same representative query.\n    \"\"\"\n    feature_name = 'morpheme_differentiation_score'\n    \n    # 1. Pre-computation and edge case handling\n    if df.empty or 'morpheme_words' not in df.columns or 'source' not in df.columns or 'representative_query' not in df.columns:\n        df[feature_name] = np.nan\n        return df\n\n    # Initialize the feature column with a default value (np.nan).\n    # This ensures rows that cannot be scored (e.g., competitors, no-query posts) have a null value.\n    df[feature_name] = np.nan\n\n    # 2. Convert morpheme string representations into actual lists of strings.\n    # A temporary column is created for this processed data.\n    df['_morpheme_list'] = df['morpheme_words'].apply(_safe_literal_eval)\n\n    # 3. Group by representative query to build competitor benchmarks.\n    # We iterate through each query's ecosystem.\n    # Using .copy() on the grouped data avoids SettingWithCopyWarning\n    grouped = df.groupby('representative_query')\n    for query, group_df in grouped:\n        if pd.isna(query):\n            continue\n\n        # Separate our posts from competitor posts within the group\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        # If there are no competitors to benchmark against, or no 'ours' posts to score, skip.\n        if competitor_posts.empty or ours_posts.empty:\n            continue\n\n        # 4. Create a comprehensive vocabulary set from all competitors for this query.\n        # This set is our benchmark for \"common\" morphemes.\n        competitor_vocab = set()\n        for morpheme_list in competitor_posts['_morpheme_list']:\n            competitor_vocab.update(morpheme_list)\n\n        # 5. Calculate the differentiation score for each of our posts.\n        for index, our_post_row in ours_posts.iterrows():\n            our_morphemes_set = set(our_post_row['_morpheme_list'])\n            \n            # If our post has no morphemes, its differentiation score is 0.\n            if not our_morphemes_set:\n                df.loc[index, feature_name] = 0.0\n                continue\n            \n            # Find the set of morphemes that are exclusive to our post.\n            exclusive_morphemes = our_morphemes_set.difference(competitor_vocab)\n            \n            # The score is the ratio of exclusive morphemes to our total unique morphemes.\n            # This normalizes the score between 0 and 1.\n            score = len(exclusive_morphemes) / len(our_morphemes_set)\n            \n            # Assign the calculated score back to the original DataFrame using the correct index.\n            df.loc[index, feature_name] = score\n\n    # Clean up the temporary column before returning the final DataFrame.\n    df.drop(columns=['_morpheme_list'], inplace=True)\n    \n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T05:46:53.842774",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'morpheme_expansion_ratio_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\n# 1. Lazy-load the morpheme analyzer model to avoid re-initializing it on every call.\n_kiwi = None\n\ndef get_kiwi():\n    \"\"\"Initializes and returns a singleton Kiwi instance.\"\"\"\n    global _kiwi\n    if _kiwi is None:\n        try:\n            from kiwipiepy import Kiwi\n            _kiwi = Kiwi()\n        except ImportError:\n            raise ImportError(\"Kiwipiepy is not installed. Please install it using 'pip install kiwipiepy'\")\n    return _kiwi\n\ndef safe_literal_eval(val):\n    \"\"\"Safely evaluate a string that is a Python literal (like a list).\n       Returns an empty list if the input is not a valid literal string.\n    \"\"\"\n    if not isinstance(val, str):\n        return [] # Return empty list for non-string types (e.g., NaN)\n    try:\n        return ast.literal_eval(val)\n    except (ValueError, SyntaxError, MemoryError, TypeError):\n        return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\" \n    Calculates the morpheme expansion ratio. This feature measures how diversely a post expands on the core morphemes of its representative query compared to competitors.\n    \n    1.  For each query group, identifies core morphemes from the query string.\n    2.  For each post, counts how many unique morphemes are 'expansions' of the core morphemes (i.e., contain a core morpheme).\n    3.  For 'ours' posts, calculates the ratio of its expansion count to the average expansion count of its competitors.\n    \"\"\"\n    feature_name = 'morpheme_expansion_ratio_vs_competitors'\n    \n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # Initialize the feature column with a neutral value of 1.0\n    df[feature_name] = 1.0\n\n    # 2. Efficiently prepare data for processing\n    # Ensure the morpheme_words column is parsed into lists safely\n    if 'morpheme_words' not in df.columns or 'representative_query' not in df.columns:\n        return df\n        \n    df_copy = df[['representative_query', 'source', 'morpheme_words']].copy()\n    df_copy['morphemes'] = df_copy['morpheme_words'].apply(safe_literal_eval)\n    \n    try:\n        kiwi = get_kiwi()\n    except ImportError as e:\n        print(f\"Skipping feature generation: {e}\")\n        return df\n\n    results = {}\n\n    # Group by the representative query to handle each benchmark set\n    for query, group in df_copy.groupby('representative_query'):\n        if not isinstance(query, str) or not query:\n            continue\n\n        # 1. Identify core morphemes from the query itself (e.g., nouns, verbs, roots)\n        core_morpheme_tags = {'NNG', 'NNP', 'NP', 'VV', 'VA', 'XR'}\n        try:\n            analyzed_query = kiwi.analyze(query)\n            # The result is a list of sentences, each with tokens. We flatten it.\n            core_morphemes = {token.form for sentence in analyzed_query for token in sentence[0] if token.tag in core_morpheme_tags}\n        except Exception:\n            core_morphemes = set()\n\n        if not core_morphemes:\n            continue\n\n        # 2. Calculate expansion score for every post in the group\n        def calculate_expansion_score(post_morphemes):\n            if not isinstance(post_morphemes, list):\n                return 0\n            expanded_morphemes = set()\n            for post_morph in post_morphemes:\n                for core_morph in core_morphemes:\n                    if core_morph in post_morph:\n                        expanded_morphemes.add(post_morph)\n                        break # Move to the next post_morph once a core match is found\n            return len(expanded_morphemes)\n\n        expansion_scores = group['morphemes'].apply(calculate_expansion_score)\n\n        # 3. Benchmark 'ours' against 'competitors'\n        competitor_scores = expansion_scores[group['source'] == 'competitor']\n        our_indices = group[group['source'] == 'ours'].index\n\n        if competitor_scores.empty:\n            # If no competitors, the concept of a ratio is undefined. Use a neutral value.\n            avg_competitor_score = 1.0\n        else:\n            avg_competitor_score = competitor_scores.mean()\n        \n        # Avoid division by zero or inflating scores with a near-zero denominator.\n        # If competitors have no expansion, a single expansion by us is infinitely better.\n        # Capping the denominator at 1.0 provides a more stable ratio.\n        denominator = max(avg_competitor_score, 1.0)\n\n        for idx in our_indices:\n            our_score = expansion_scores.loc[idx]\n            ratio = our_score / denominator\n            results[idx] = ratio\n\n    # 3. Assign the calculated features back to the original DataFrame, preserving the index.\n    if results:\n        df[feature_name] = df.index.map(results).fillna(1.0)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:47:50.083115",
  "attempt": 2,
  "status": "success",
  "feature_name": "core_morpheme_structural_diversity",
  "hypothesis": "우리 포스트가 대표 검색어의 핵심 형태소를 포함하는 파생/조합 형태소를, 상위 경쟁자 그룹의 평균보다 더 다양하게 사용할수록, 콘텐츠의 깊이와 전문성이 높게 평가되어 비브랜드 유입에 긍정적인 영향을 미칠 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 검색어의 핵심 형태소를 기반으로 '우리' 포스트와 '경쟁' 포스트의 형태소 구조적 다양성을 비교합니다.\n\n    1. 각 대표 검색어 그룹별로 분석을 수행합니다.\n    2. 대표 검색어를 공백으로 분리하여 '핵심 형태소'를 정의합니다. (예: '송곳니 충치' -> ['송곳니', '충치'])\n    3. 각 포스트의 'morpheme_words'에서 핵심 형태소를 포함하는 고유한 파생/조합 형태소의 수를 계산하여 '구조적 다양성 점수'를 부여합니다.\n    4. '경쟁자' 그룹 내에서 non_brand_inflow가 중앙값 이상인 '상위 경쟁자' 그룹을 정의합니다.\n    5. '우리' 포스트의 다양성 점수를 '상위 경쟁자' 그룹의 평균 다양성 점수로 나누어 최종 피처 값을 계산합니다.\n    6. 이 피처는 우리 콘텐츠가 핵심 주제를 얼마나 다채롭게 변주하여 설명하는지를 경쟁사와 비교하는 지표입니다.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'core_morpheme_structural_diversity'\n    df[feature_name] = np.nan\n\n    # 'morpheme_words'가 문자열이 아닌 경우를 대비해 안전하게 처리하는 함수\n    def parse_morphemes(morpheme_string):\n        if not isinstance(morpheme_string, str):\n            return set()\n        return set(word.strip() for word in morpheme_string.split(',') if word.strip())\n\n    # 계산 효율성을 위해 전처리된 형태소 집합을 새 열에 저장\n    df['morpheme_set'] = df['morpheme_words'].apply(parse_morphemes)\n\n    results = {}\n\n    # 대표 검색어 별로 그룹화하여 처리\n    for query, group in df.groupby('representative_query'):\n        if pd.isna(query) or not query:\n            continue\n\n        core_morphemes = query.split()\n        if not core_morphemes:\n            continue\n\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        # 상위 경쟁자 정의: non_brand_inflow가 그룹 내 중앙값 이상인 포스트\n        competitor_median_inflow = competitor_posts['non_brand_inflow'].median()\n        # 중앙값이 0이거나 NaN인 경우, 모든 경쟁사를 대상으로 함으로써 데이터 부족 문제 완화\n        if pd.isna(competitor_median_inflow) or competitor_median_inflow == 0:\n            high_performing_competitors = competitor_posts\n        else:\n            high_performing_competitors = competitor_posts[competitor_posts['non_brand_inflow'] >= competitor_median_inflow]\n        \n        # 만약 필터링 후 상위 경쟁자가 없으면 전체 경쟁사를 대상으로 함\n        if high_performing_competitors.empty:\n            high_performing_competitors = competitor_posts\n\n        # 상위 경쟁자들의 평균 구조적 다양성 계산\n        competitor_diversities = []\n        for _, comp_row in high_performing_competitors.iterrows():\n            comp_morphemes = comp_row['morpheme_set']\n            if not comp_morphemes:\n                competitor_diversities.append(0)\n                continue\n            \n            diversity_count = sum(1 for m in comp_morphemes if any(core in m for core in core_morphemes))\n            competitor_diversities.append(diversity_count)\n            \n        avg_competitor_diversity = np.mean(competitor_diversities) if competitor_diversities else 0\n\n        # 우리 포스트 각각에 대해 구조적 다양성 비율 계산\n        for _, our_row in ours_posts.iterrows():\n            post_identifier = our_row['post_identifier']\n            our_morphemes = our_row['morpheme_set']\n            \n            if not our_morphemes:\n                our_diversity = 0\n            else:\n                our_diversity = sum(1 for m in our_morphemes if any(core in m for core in core_morphemes))\n            \n            # 0으로 나누기 방지 및 비율 계산\n            if avg_competitor_diversity > 0:\n                ratio = our_diversity / avg_competitor_diversity\n            else:\n                # 경쟁자 다양성이 0일 때, 우리 다양성이 0보다 크면 우월(2.0), 둘 다 0이면 동등(1.0)\n                ratio = 2.0 if our_diversity > 0 else 1.0\n            \n            results[post_identifier] = ratio\n\n    # 계산된 결과를 post_identifier를 키로 사용하여 원본 DataFrame에 매핑\n    # 이 방식은 인덱스가 뒤섞여도 정확한 행에 값을 할당\n    df[feature_name] = df['post_identifier'].map(results)\n    \n    # 임시로 사용한 열 삭제\n    df.drop(columns=['morpheme_set'], inplace=True)\n\n    return df",
  "analysis": {
    "correlation": 0.18593927315948655,
    "p_value": 0.0712175932261643,
    "interpretation": "약한 양의 상관관계(0.1859)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.0712)."
  }
}{
  "timestamp": "2025-07-22T06:06:23.222257",
  "attempt": 1,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹보다 대표 쿼리의 핵심 형태소를 제외한 파생 형태소를 더 다양하게(풍부하게) 포함할수록, 비브랜드 유입 성과가 높을 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 쿼리의 핵심 형태소를 제외한 '파생 형태소'의 다양성(개수)을 우리 포스트와 경쟁자 그룹 간에 비교합니다.\n\n    1. 각 'representative_query'를 기준으로 그룹화합니다.\n    2. 대표 쿼리를 공백으로 분리하여 '핵심 형태소' 집합을 정의합니다.\n    3. 각 포스트의 'morpheme_words'에서 핵심 형태소를 제외한 '파생 형태소'의 고유 개수(풍부도)를 계산합니다.\n    4. 각 'ours' 포스트에 대해, 동일 쿼리 그룹 내 경쟁자들의 평균 파생 형태소 풍부도 대비 우리 포스트의 풍부도 비율을 계산합니다.\n    5. 이 비율은 우리 콘텐츠가 핵심 주제 외에 얼마나 더 넓은 의미론적 범위를 다루는지를 나타내는 지표가 됩니다.\n    \"\"\"\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        return df\n\n    # 결과 컬럼 초기화 (비교 대상이 없는 경우를 대비한 기본값 설정)\n    feature_name = 'derivative_morpheme_richness_ratio'\n    df[feature_name] = 1.0\n\n    # 전처리: morpheme_words를 파싱하여 고유 형태소 집합(set)으로 변환\n    # NaN 값은 빈 문자열로 처리 후, 쉼표와 공백으로 분리하여 공백 제거 후 set 생성\n    df['temp_morpheme_set'] = df['morpheme_words'].fillna('').str.split(', ').apply(\n        lambda x: {m.strip() for m in x if m.strip()}\n    )\n\n    # 대표 쿼리별로 그룹화\n    grouped = df.groupby('representative_query')\n\n    # 각 쿼리 그룹에 대해 피처 계산\n    for query, group in grouped:\n        if not isinstance(query, str) or not query.strip():\n            continue\n\n        # 대표 쿼리에서 핵심 형태소 집합 생성\n        core_morphemes = set(query.split())\n\n        # 그룹 내 'ours'와 'competitor' 포스트 분리\n        ours_posts_indices = group[group['source'] == 'ours'].index\n        competitor_posts_indices = group[group['source'] == 'competitor'].index\n\n        # 비교를 위해 우리 포스트와 경쟁자 포스트가 모두 존재해야 함\n        if ours_posts_indices.empty or competitor_posts_indices.empty:\n            continue\n\n        # 각 포스트의 파생 형태소 풍부도(고유 개수) 계산\n        # 파생 형태소 = 전체 형태소 - 핵심 형태소\n        derivative_richness = group['temp_morpheme_set'].apply(lambda morphemes: len(morphemes - core_morphemes))\n\n        # 경쟁자 그룹의 평균 파생 형태소 풍부도 계산\n        avg_competitor_richness = derivative_richness.loc[competitor_posts_indices].mean()\n\n        # 0으로 나누는 것을 방지하기 위해 작은 값(epsilon) 추가\n        epsilon = 1e-9\n        \n        # 우리 포스트의 파생 형태소 풍부도 계산 및 비율 산정\n        ours_richness = derivative_richness.loc[ours_posts_indices]\n        ratio = ours_richness / (avg_competitor_richness + epsilon)\n\n        # 계산된 비율을 원본 DataFrame에 할당 (인덱스를 사용하여 정확한 위치에 업데이트)\n        df.loc[ours_posts_indices, feature_name] = ratio\n\n    # 임시로 사용한 컬럼 제거\n    df.drop(columns=['temp_morpheme_set'], inplace=True)\n\n    return df",
  "analysis": {
    "correlation": 0.13405119610371605,
    "p_value": 0.19527646982997224,
    "interpretation": "약한 양의 상관관계(0.1341)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.1953)."
  }
}{
  "timestamp": "2025-07-22T06:26:58.135067",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'morpheme_expansion_diversity_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef _get_morphemes_from_text(text):\n    \"\"\"Helper function to safely split a string of morphemes into a set, handling NaN/empty cases.\"\"\"\n    if not isinstance(text, str) or not text.strip():\n        return set()\n    return set(text.split())\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of our post's morpheme expansion diversity to the competitor average for the same query.\n\n    - Morpheme Expansion Diversity: The number of unique morphemes in a post that are not part of the representative query.\n    - Benchmark: The average morpheme expansion diversity across all competitor posts for that query.\n    \"\"\"\n    # 1. Safety Check: Handle empty DataFrame.\n    if df.empty:\n        return df\n\n    feature_name = 'morpheme_expansion_diversity_ratio'\n    df[feature_name] = np.nan\n\n    # Ensure required columns are of the correct type, handling potential NaN values.\n    df['morpheme_words'] = df['morpheme_words'].astype(str).fillna('')\n    df['representative_query'] = df['representative_query'].astype(str).fillna('')\n\n    # 2. Group by representative query to process each query's ecosystem.\n    # Using the original DataFrame's index is crucial to avoid misalignment.\n    grouped = df.groupby('representative_query')\n\n    for query, group in grouped:\n        if not query.strip():\n            continue\n\n        query_morphemes = _get_morphemes_from_text(query)\n\n        # 3. Separate our posts from competitors within the group.\n        ours_df = group[group['source'] == 'ours']\n        competitors_df = group[group['source'] == 'competitors']\n\n        # Continue if there are no competitors to benchmark against or no 'ours' posts to score.\n        if competitors_df.empty or ours_df.empty:\n            continue\n\n        # 4. Calculate the average expansion richness for the competitor group.\n        # This computes the richness for each competitor individually and then averages the scores,\n        # providing a more robust benchmark than aggregating all text first.\n        competitor_richness_scores = []\n        for morpheme_text in competitors_df['morpheme_words']:\n            competitor_morphemes = _get_morphemes_from_text(morpheme_text)\n            expansion_richness = len(competitor_morphemes - query_morphemes)\n            competitor_richness_scores.append(expansion_richness)\n        \n        avg_competitor_richness = np.mean(competitor_richness_scores) if competitor_richness_scores else 0\n\n        # 5. Calculate the ratio for each of our posts and assign it back to the main DataFrame.\n        for index, row in ours_df.iterrows():\n            our_morphemes = _get_morphemes_from_text(row['morpheme_words'])\n            our_richness = len(our_morphemes - query_morphemes)\n            \n            # Add a small epsilon to the denominator to prevent division by zero.\n            ratio = our_richness / (avg_competitor_richness + 1e-6)\n            \n            # Use .loc with the original index to ensure correct assignment.\n            df.loc[index, feature_name] = ratio\n\n    return df"
}{
  "timestamp": "2025-07-22T06:27:41.300692",
  "attempt": 2,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹보다 대표 쿼리의 핵심 형태소를 포함하면서도, 그 외의 파생/관련 형태소를 더 풍부하고 다양하게 사용할수록, 콘텐츠의 깊이와 전문성이 높게 평가되어 비브랜드 유입(non_brand_inflow)이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 쿼리의 핵심 형태소를 제외한 파생/관련 형태소의 사용량을 경쟁사와 비교하여 비율을 계산합니다.\n\n    - 핵심 로직:\n      1. 'representative_query'로 데이터를 그룹화합니다.\n      2. 각 그룹 내에서 'ours' 포스트와 'competitor' 포스트를 구분합니다.\n      3. 대표 쿼리 자체를 '핵심 형태소'의 집합으로 정의합니다.\n      4. 각 포스트의 'morpheme_words'에서 핵심 형태소를 제외한 '파생 형태소'의 개수를 계산합니다.\n      5. 'ours' 포스트 각각에 대해, 해당 포스트의 파생 형태소 개수를 \n         경쟁사 그룹의 평균 파생 형태소 개수로 나눈 비율을 계산합니다.\n      6. 이 비율은 우리 포스트가 경쟁사 대비 얼마나 더 풍부한 관련 어휘를 사용하는지 나타냅니다.\n\n    - 이전 오류 수정:\n      - 모든 행에 대해 동일한 값이 생성되는 문제를 해결했습니다.\n      - 각 'ours' 포스트마다 고유한 '파생 형태소 개수'를 계산하고, \n        이를 해당 쿼리 그룹의 '경쟁사 평균'과 비교함으로써 각 행에 대해 다른 피처 값을 생성합니다.\n        이로써 피처의 분산이 0이 되는 문제를 방지하고 유의미한 상관관계 분석을 가능하게 합니다.\n    \"\"\"\n    if df.empty:\n        df['derivative_morpheme_richness_ratio'] = pd.Series(dtype=float)\n        return df\n\n    df_copy = df.copy()\n\n    # 'morpheme_words'를 처리하여 형태소 set으로 변환\n    # NaN은 빈 문자열로, 각 문자열은 쉼표와 공백으로 분리된 리스트로 변환 후 중복 제거를 위해 set으로 변환\n    df_copy['morpheme_set'] = df_copy['morpheme_words'].fillna('').apply(\n        lambda x: set(m.strip() for m in x.split(',') if m.strip()))\n\n    # 결과를 저장할 Series를 원본 DataFrame의 인덱스로 초기화하여 정렬 문제를 방지\n    results = pd.Series(index=df.index, dtype=float)\n\n    # 대표 쿼리로 그룹화\n    grouped = df_copy.groupby('representative_query')\n\n    for query, group in grouped:\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        # 우리 포스트나 경쟁사 포스트가 없는 경우 해당 그룹은 건너뜀\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        # 대표 쿼리를 공백으로 분리하여 핵심 형태소 set으로 정의 (간단하지만 강건한 접근)\n        core_morphemes = set(query.split())\n\n        # 경쟁사들의 평균 파생 형태소 풍부도 계산\n        competitor_derivative_counts = []\n        for idx, row in competitor_posts.iterrows():\n            competitor_morphemes = row['morpheme_set']\n            derivative_morphemes = competitor_morphemes - core_morphemes\n            competitor_derivative_counts.append(len(derivative_morphemes))\n        \n        # 경쟁사 데이터가 있을 경우 평균 계산, 없을 경우 0\n        avg_competitor_richness = np.mean(competitor_derivative_counts) if competitor_derivative_counts else 0\n\n        # 각 'ours' 포스트에 대해 피처 값 계산\n        for idx, row in ours_posts.iterrows():\n            our_morphemes = row['morpheme_set']\n            our_derivative_richness = len(our_morphemes - core_morphemes)\n\n            # 0으로 나누는 것을 방지. 경쟁사 평균이 0이면, 우리 포스트와 동등하다고 가정하여 1.0 부여\n            if avg_competitor_richness > 0:\n                ratio = our_derivative_richness / avg_competitor_richness\n            else:\n                ratio = 1.0\n            \n            # 원본 인덱스(idx)를 사용하여 결과 저장\n            results.loc[idx] = ratio\n\n    # 계산된 결과를 원본 DataFrame에 새로운 컬럼으로 추가\n    df['derivative_morpheme_richness_ratio'] = results\n\n    # 피처가 계산되지 않은 행(예: 경쟁사가 없는 그룹)은 1.0 (중립값)으로 채움\n    df['derivative_morpheme_richness_ratio'].fillna(1.0, inplace=True)\n\n    return df",
  "analysis": {
    "correlation": 0.1340511961030599,
    "p_value": 0.19527646983217894,
    "interpretation": "약한 양의 상관관계(0.1341)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.1953)."
  }
}{
  "timestamp": "2025-07-22T06:48:33.237185",
  "attempt": 1,
  "status": "execution_error",
  "error": "코드 실행 실패:\nError during script execution: [Errno 2] JVM DLL not found: /Library/Java/JavaVirtualMachines/jdk-21.0.2.jdk/Contents/MacOS/libjli.dylib\n",
  "code": "import pandas as pd\nimport numpy as np\nfrom konlpy.tag import Okt\n\n# 1. Lazy-load the morpheme analyzer to avoid re-initializing it on every call.\n_okt = None\n\ndef get_okt():\n    global _okt\n    if _okt is None:\n        _okt = Okt()\n    return _okt\n\ndef parse_morphemes_to_set(morpheme_str):\n    \"\"\"Parses a comma-separated string of morphemes into a set for efficient processing.\"\"\"\n    if pd.isna(morpheme_str) or not isinstance(morpheme_str, str):\n        return set()\n    # Split by comma and strip whitespace from each morpheme\n    return set(word.strip() for word in morpheme_str.split(',') if word.strip())\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of derivative morpheme richness of our post compared to the average of its competitors.\n    - Core Morphemes: Nouns extracted from the 'representative_query'.\n    - Derivative Morphemes: All other morphemes in the post's 'morpheme_words'.\n    - Richness: The count of unique derivative morphemes.\n    - Ratio: (Our Richness + 1) / (Competitor Avg Richness + 1) for smoothing.\n    \"\"\"\n    # 2. Check for empty DataFrame to prevent errors.\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        return df\n\n    feature_name = 'derivative_morpheme_richness_ratio'\n    df[feature_name] = np.nan  # Initialize the feature column\n\n    # 3. Get the morpheme analyzer.\n    okt = get_okt()\n\n    # 4. Pre-process a temporary copy to avoid SettingWithCopyWarning.\n    # This also ensures we don't modify the original df until the final assignment.\n    temp_df = df[['source', 'representative_query', 'morpheme_words']].copy()\n    temp_df['morpheme_set'] = temp_df['morpheme_words'].apply(parse_morphemes_to_set)\n\n    # 5. Group by the representative query to create comparison sets.\n    grouped = temp_df.groupby('representative_query')\n    results = {}  # Use a dictionary to map original index to feature value for safe assignment.\n\n    for query, group in grouped:\n        if pd.isna(query):\n            continue\n\n        # Extract core morphemes (nouns) from the query.\n        core_morphemes = set(okt.nouns(str(query)))\n\n        # Separate 'ours' from 'competitor' posts.\n        ours_df = group[group['source'] == 'ours']\n        competitors_df = group[group['source'] == 'competitor']\n\n        # Proceed only if both our posts and competitor posts exist for the query.\n        if ours_df.empty or competitors_df.empty:\n            continue\n\n        # 6. Calculate the benchmark: average derivative richness of competitors.\n        competitor_richness_scores = []\n        for _, row in competitors_df.iterrows():\n            post_morphemes = row['morpheme_set']\n            derivative_morphemes = post_morphemes - core_morphemes\n            competitor_richness_scores.append(len(derivative_morphemes))\n\n        avg_competitor_richness = np.mean(competitor_richness_scores) if competitor_richness_scores else 0.0\n\n        # 7. Calculate the feature for each of our posts in the group.\n        for index, row in ours_df.iterrows():\n            our_morphemes = row['morpheme_set']\n            our_derivative_morphemes = our_morphemes - core_morphemes\n            our_richness = len(our_derivative_morphemes)\n\n            # Use smoothed ratio to prevent division-by-zero errors and stabilize the feature.\n            ratio = (our_richness + 1) / (avg_competitor_richness + 1)\n            results[index] = ratio\n\n    # 8. Safely map the calculated results back to the original DataFrame using its index.\n    # This is a critical step to prevent data misalignment.\n    if results:\n        df[feature_name] = df.index.map(results).fillna(df[feature_name])\n\n    return df"
}{
  "timestamp": "2025-07-22T06:49:15.626898",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 코드는 실행됐지만 'derivative_morpheme_richness_ratio' 컬럼이 생성되지 않았습니다.",
  "code": "import pandas as pd\nimport numpy as np\nimport re\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Analyzes the richness of derivative morphemes in our posts compared to high-performing competitors.\n\n    The feature 'derivative_morpheme_richness_ratio' is calculated as follows:\n    1. Groups data by 'representative_query'.\n    2. For each query, identifies 'our' posts and 'competitor' posts.\n    3. Defines 'high-performing competitors' as those with non_brand_inflow above the median for that query's competitors.\n    4. Identifies 'core words' by splitting the query string.\n    5. For each post, calculates 'derivative morpheme richness': the count of unique morphemes from 'morpheme_words'\n       that contain a core word but are not the core word itself.\n    6. For each 'our' post, the feature is the ratio of its richness score to the average richness score of the\n       high-performing competitors.\n    7. This avoids dependencies on external libraries like KoNLPy that require a JVM, thus bypassing the JVM DLL error.\n    \"\"\"\n    # 0. Check for empty DataFrame and required columns\n    if df.empty or 'representative_query' not in df.columns or 'morpheme_words' not in df.columns or 'source' not in df.columns:\n        df['derivative_morpheme_richness_ratio'] = np.nan\n        return df\n\n    # 1. Ensure 'morpheme_words' is a string and handle missing values\n    df_copy = df.copy()\n    df_copy['morpheme_words'] = df_copy['morpheme_words'].fillna('').astype(str)\n\n    results = []\n\n    # 2. Group by representative query to create context-specific benchmarks\n    for query, group in df_copy.groupby('representative_query'):\n        if not query or pd.isna(query):\n            continue\n\n        our_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # 3. Define high-performing competitors as a benchmark\n        competitor_median_inflow = competitor_posts['non_brand_inflow'].median()\n        high_performing_competitors = competitor_posts[competitor_posts['non_brand_inflow'] >= competitor_median_inflow]\n\n        if high_performing_competitors.empty:\n            # If no high-performing competitors, use all competitors as a fallback\n            high_performing_competitors = competitor_posts\n        \n        # 4. Define core words from the query\n        # Use regex to split by space, handling multiple spaces\n        core_words = set(re.split(r'\\s+', query.strip()))\n\n        # 5. Calculate derivative richness for the benchmark group\n        competitor_richness_scores = []\n        for morphemes_str in high_performing_competitors['morpheme_words']:\n            morphemes = set(morphemes_str.split())\n            derivative_morphemes = set()\n            for core_word in core_words:\n                for morpheme in morphemes:\n                    if core_word in morpheme and core_word != morpheme:\n                        derivative_morphemes.add(morpheme)\n            competitor_richness_scores.append(len(derivative_morphemes))\n\n        # Use a small epsilon to avoid division by zero\n        avg_competitor_richness = np.mean(competitor_richness_scores) if competitor_richness_scores else 0\n        avg_competitor_richness_safe = avg_competitor_richness + 1e-9\n\n        # 6. Calculate the feature for each of our posts in the group\n        for idx, row in our_posts.iterrows():\n            our_morphemes = set(row['morpheme_words'].split())\n            our_derivative_morphemes = set()\n            for core_word in core_words:\n                for morpheme in our_morphemes:\n                    if core_word in morpheme and core_word != morpheme:\n                        our_derivative_morphemes.add(morpheme)\n            our_richness = len(our_derivative_morphemes)\n\n            # Calculate ratio\n            ratio = our_richness / avg_competitor_richness_safe\n            results.append({'post_identifier': row['post_identifier'], 'derivative_morpheme_richness_ratio': ratio})\n\n    # 7. Merge the calculated feature back into the original DataFrame\n    if results:\n        feature_df = pd.DataFrame(results)\n        df = df.merge(feature_df, on='post_identifier', how='left')\n    else:\n        df['derivative_morpheme_richness_ratio'] = np.nan\n\n    return df"
}{
  "timestamp": "2025-07-22T06:50:57.237479",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'derivative_morpheme_richness_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\n\ndef safe_literal_eval(val):\n    \"\"\"Safely evaluate a string representation of a list, handling non-string/NaN values.\"\"\"\n    if isinstance(val, str):\n        try:\n            return ast.literal_eval(val)\n        except (ValueError, SyntaxError):\n            return []\n    return []\n\ndef get_derivative_morphemes(morphemes, core_morphemes):\n    \"\"\"Find morphemes that contain a core morpheme but are not the core morpheme itself.\"\"\"\n    if not morphemes or not core_morphemes:\n        return set()\n    \n    derivatives = set()\n    for morpheme in morphemes:\n        for core in core_morphemes:\n            if core in morpheme and core != morpheme:\n                derivatives.add(morpheme)\n    return derivatives\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of derivative morpheme richness for 'our' posts compared to the \n    average of competitor posts for the same representative query.\n    \n    1.  Core morphemes are extracted from the representative query.\n    2.  Derivative morphemes are defined as post morphemes that contain a core morpheme.\n    3.  Richness is the count of unique derivative morphemes.\n    4.  The ratio is calculated as (our_richness + 1) / (competitor_avg_richness + 1) to handle zeros gracefully.\n    \"\"\"\n    if not df.empty:\n        # Initialize the result column with a neutral value (1.0 indicates parity)\n        df['derivative_morpheme_richness_ratio'] = 1.0\n\n        # Ensure correct data types\n        temp_df = df[['representative_query', 'source', 'morpheme_words']].copy()\n        temp_df['morpheme_words'] = temp_df['morpheme_words'].apply(safe_literal_eval)\n\n        # Store results with original index to ensure correct assignment\n        results = {}\n\n        for query, group in temp_df.groupby('representative_query'):\n            if pd.isna(query):\n                continue\n\n            # 1. Define core morphemes from the query\n            core_morphemes = set(str(query).split())\n\n            # 2. Separate our posts from competitor posts\n            our_posts = group[group['source'] == 'ours']\n            competitor_posts = group[group['source'] == 'competitor']\n\n            # Skip if there's nothing to compare\n            if our_posts.empty or competitor_posts.empty:\n                continue\n\n            # 3. Calculate average derivative morpheme richness for competitors\n            competitor_richness_scores = [\n                len(get_derivative_morphemes(morphemes, core_morphemes)) \n                for morphemes in competitor_posts['morpheme_words']\n            ]\n            avg_competitor_richness = np.mean(competitor_richness_scores) if competitor_richness_scores else 0\n\n            # 4. Calculate the ratio for each of our posts\n            for idx, row in our_posts.iterrows():\n                our_morphemes = row['morpheme_words']\n                our_richness = len(get_derivative_morphemes(our_morphemes, core_morphemes))\n                \n                # Use smoothing (add 1) to prevent division by zero and handle 0/0 case gracefully\n                ratio = (our_richness + 1) / (avg_competitor_richness + 1)\n                results[idx] = ratio\n        \n        # 5. Assign the calculated ratios back to the original DataFrame\n        if results:\n            # Create a Series from the results dictionary\n            result_series = pd.Series(results, name='derivative_morpheme_richness_ratio')\n            # Update the DataFrame column where the index matches\n            df.update(result_series)\n            # Ensure no NaNs remain from the update process, default to 1.0\n            df['derivative_morpheme_richness_ratio'].fillna(1.0, inplace=True)\n\n    return df\n"
}{
  "timestamp": "2025-07-22T06:52:10.188503",
  "attempt": 4,
  "status": "execution_error",
  "error": "코드 실행 실패:\n  File \"/Users/min/codes/medilawyer_sales/blog_automation/agents/_temp_feature_generator.py\", line 42\n    \"\"\"\n    ^\nSyntaxError: unterminated triple-quoted string literal (detected at line 123)\n",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef safe_literal_eval(val):\n    \"\"\"'['a', 'b']'와 같은 문자열을 실제 리스트 객체로 안전하게 변환합니다.\"\"\"\n    if pd.isna(val):\n        return []\n    if isinstance(val, list):\n        return val\n    if isinstance(val, str):\n        try:\n            return ast.literal_eval(val)\n        except (ValueError, SyntaxError):\n            # 단순 문자열이거나 파싱할 수 없는 경우 빈 리스트 반환\n            return []\n    return []\n\ndef get_derivative_diversity(morphemes: list, core_morphemes: list) -> int:\n    \"\"\"주어진 형태소 리스트에서 핵심 형태소를 포함하는 파생 형태소의 고유 개수를 계산합니다.\"\"\"\n    if not morphemes or not core_morphemes:\n        return 0\n    \n    # 핵심 형태소 중 하나라도 포함하는 모든 형태소를 찾습니다.\n    derivative_morphemes = {\n        morpheme for morpheme in morphemes \n        if any(core in morpheme for core in core_morphemes)\n    }\n    return len(derivative_morphemes)\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대해, 대표 쿼리의 핵심 형태소로부터 파생된 형태소의 다양성(고유 개수)을 계산하고,\n    동일 쿼리의 경쟁자 그룹 평균과 비교하여 비율을 산출합니다.\n    이전 시도에서 모든 행에 동일한 값이 할당되던 문제를 해결하기 위해, 각 'ours' 포스트별로 독립적인 값을 계산하고,\n    쿼리별로 그룹화하여 올바른 벤치마크와 비교하도록 수정했습니다.\n    \"\n    if df.empty:\n        return df\n\n    # SettingWithCopyWarning을 피하기 위해 명시적으로 복사본 생성\n    df_copy = df.copy()\n    feature_name = 'derivative_morpheme_richness_ratio'\n    # 기본값을 1.0(경쟁자와 동일)으로 설정\n    df_copy[feature_name] = 1.0\n\n    # 'morpheme_words' 컬럼을 안전하게 리스트로 변환하여 임시 컬럼 생성\n    df_copy['morpheme_list'] = df_copy['morpheme_words'].apply(safe_literal_eval)\n\n    # 대표 쿼리별로 그룹화하여 벤치마킹 수행\n    grouped = df_copy.groupby('representative_query')\n\n    for query, group_df in grouped:\n        if not isinstance(query, str) or not query:\n            continue\n\n        # 쿼리 문자열을 공백 기준으로 분리하여 핵심 형태소 리스트 생성\n        core_morphemes = query.split()\n        if not core_morphemes:\n            continue\n\n        # 그룹 내에서 'ours'와 'competitor' 포스트 분리\n        ours_indices = group_df[group_df['source'] == 'ours'].index\n        competitors_df = group_df[group_df['source'] == 'competitor']\n\n        # 'ours' 포스트나 경쟁자 포스트가 없으면 비교 불가, 기본값(1.0) 유지\n        if competitors_df.empty or ours_indices.empty:\n            continue\n\n        # 경쟁자 그룹의 평균 파생 형태소 다양성 계산\n        competitor_diversities = [\n            get_derivative_diversity(morphemes, core_morphemes)\n            for morphemes in competitors_df['morpheme_list']\n        ]\n        \n        avg_competitor_diversity = np.mean(competitor_diversities) if competitor_diversities else 0.0\n        \n        # 0으로 나누는 것을 방지. 경쟁자 다양성이 0이면 벤치마크 분모를 1로 설정하여\n        # 우리 포스트의 다양성 점수가 그대로 비율이 되도록 함.\n        benchmark_denominator = avg_competitor_diversity if avg_competitor_diversity > 0 else 1.0\n\n        # 각 'ours' 포스트에 대해 개별적으로 비율 계산 및 할당\n        for idx in ours_indices:\n            # .loc를 사용하여 특정 행의 'morpheme_list'에 접근\n            our_morphemes = df_copy.loc[idx, 'morpheme_list']\n            our_diversity = get_derivative_diversity(our_morphemes, core_morphemes)\n            \n            ratio = our_diversity / benchmark_denominator\n            # 원본 DataFrame의 인덱스를 사용하여 정확한 위치에 값 할당\n            df_copy.loc[idx, feature_name] = ratio\n\n    # 임시로 사용한 컬럼 제거\n    df_copy = df_copy.drop(columns=['morpheme_list'])\n\n    return df_copy\n"
}{
  "timestamp": "2025-07-22T06:53:14.345878",
  "attempt": 5,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹보다 대표 쿼리의 핵심 형태소와 관련된 파생 형태소를 더 다양하게 포함할수록, 즉 형태소 확장성이 좋을수록 검색 유입량이 많을 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 검색어(representative_query)의 핵심 형태소를 기반으로 '파생 형태소 풍부도'를 계산하고,\n    이를 경쟁자 그룹의 평균과 비교하여 비율(ratio)을 산출합니다.\n\n    - 핵심 형태소: 대표 검색어를 공백으로 분리하여 얻은 형태소 집합.\n    - 파생 형태소: 포스트의 형태소 중 핵심 형태소를 포함하지만, 핵심 형태소 자체는 아닌 다른 형태소.\n      (예: 핵심 형태소가 '치과'일 때, '동탄치과'는 파생 형태소)\n    - 풍부도: 포스트 내 고유한 파생 형태소의 개수.\n\n    피처 값은 (우리 포스트의 풍부도) / (경쟁자 포스트들의 평균 풍부도 + 1)로 계산됩니다.\n    분모에 1을 더하여 0으로 나누는 것을 방지하고 극단적인 값을 완화합니다.\n    \"\"\"\n    feature_name = 'derivative_morpheme_richness_ratio'\n\n    if df.empty or 'morpheme_words' not in df.columns or 'representative_query' not in df.columns:\n        df[feature_name] = np.nan\n        return df\n\n    # 원본 데이터프레임의 인덱스를 보존하기 위해 복사본에서 작업합니다.\n    df_copy = df.copy()\n\n    # 형태소 문자열을 리스트로 변환하고, 빈 문자열이나 공백을 제거합니다.\n    df_copy['morpheme_list'] = df_copy['morpheme_words'].fillna('').str.split(',').apply(\n        lambda x: [m.strip() for m in x if m.strip()]\n    )\n\n    # 대표 검색어를 기준으로 그룹화합니다.\n    grouped = df_copy.groupby('representative_query')\n    \n    # 각 'ours' 포스트에 대한 계산 결과를 담을 리스트입니다.\n    results_list = []\n\n    for query, group_df in grouped:\n        # 유효한 검색어 그룹에 대해서만 연산을 수행합니다.\n        if not query or pd.isna(query):\n            continue\n\n        ours_mask = group_df['source'] == 'ours'\n        competitors_mask = group_df['source'] == 'competitor'\n        \n        # 우리 포스트와 경쟁자 포스트가 모두 존재해야 벤치마킹이 가능합니다.\n        if not ours_mask.any() or not competitors_mask.any():\n            # 벤치마킹이 불가능한 경우, 해당 그룹의 'ours' 포스트에는 중립적인 값 1.0을 할당합니다.\n            if ours_mask.any():\n                group_results = pd.Series(1.0, index=group_df.index[ours_mask])\n                results_list.append(group_results)\n            continue\n\n        # 1. 대표 검색어에서 핵심 형태소를 추출합니다.\n        core_morphemes = set(query.split())\n\n        # 2. 파생 형태소의 풍부도를 계산하는 함수를 정의합니다.\n        def get_derivative_richness(morpheme_list: list) -> int:\n            if not morpheme_list: return 0\n            derivatives = set()\n            for morpheme in morpheme_list:\n                for core in core_morphemes:\n                    # 파생 형태소는 핵심 형태소를 포함하지만 동일하지 않아야 합니다.\n                    if core in morpheme and core != morpheme:\n                        derivatives.add(morpheme)\n            return len(derivatives)\n\n        # 3. 경쟁자 그룹의 평균 파생 형태소 풍부도를 계산합니다.\n        competitor_richness = group_df.loc[competitors_mask, 'morpheme_list'].apply(get_derivative_richness)\n        avg_competitor_richness = competitor_richness.mean()\n\n        # 4. 우리 포스트의 파생 형태소 풍부도 및 최종 비율을 계산합니다.\n        our_richness = group_df.loc[ours_mask, 'morpheme_list'].apply(get_derivative_richness)\n        \n        # 분모에 1을 더해 ZeroDivisionError를 방지하고 비율을 안정화합니다.\n        ratio = our_richness / (avg_competitor_richness + 1.0)\n        \n        # 원본 인덱스를 유지한 Series 형태로 결과를 저장합니다.\n        results_list.append(ratio)\n\n    # 모든 그룹의 결과를 합치고 원본 DataFrame에 새로운 피처 컬럼을 추가합니다.\n    if results_list:\n        final_ratios = pd.concat(results_list)\n        df[feature_name] = final_ratios\n    else:\n        # 처리된 그룹이 없는 경우, 모든 행에 대해 중립적인 값으로 채웁니다.\n        df[feature_name] = 1.0\n\n    # 'ours' 포스트 중 계산되지 않은 값(NaN)이나 경쟁자 행의 NaN을 중립값 1.0으로 채웁니다.\n    df[feature_name].fillna(1.0, inplace=True)\n    \n    return df",
  "analysis": {
    "correlation": 0.011929294612354861,
    "p_value": 0.9086534228543669,
    "interpretation": "약한 양의 상관관계(0.0119)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.9087)."
  }
}{
  "timestamp": "2025-07-22T07:09:16.652615",
  "attempt": 1,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 대표 검색어의 핵심 형태소를 제외한 '파생 형태소'를 경쟁자 그룹의 평균보다 더 풍부하게 사용할수록, 사용자의 더 넓은 탐색 의도를 충족시켜 비브랜드 유입(non_brand_inflow)이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef safe_literal_eval(val):\n    \"\"\"\n    Safely evaluates a string that should be a list.\n    Returns an empty list if the input is not a valid string literal,\n    is NaN, or causes an error.\n    \"\"\"\n    if isinstance(val, str):\n        try:\n            # A basic check to prevent memory errors with overly long strings\n            if len(val) > 10000:\n                 return []\n            return ast.literal_eval(val)\n        except (ValueError, SyntaxError, MemoryError, TypeError):\n            return []\n    return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the derivative morpheme richness ratio for each 'ours' post\n    compared to the average of its competitor group.\n\n    The ratio is defined as:\n    (Number of our post's derivative morphemes) / (Average number of competitor posts' derivative morphemes)\n\n    'Derivative morphemes' are those in the post's morpheme list that are not in the representative query itself.\n    \"\"\"\n    feature_name = 'derivative_morpheme_richness_ratio'\n    df[feature_name] = np.nan\n\n    if not isinstance(df, pd.DataFrame) or df.empty:\n        return df\n\n    # Preserve the original index to ensure correct assignment later\n    original_index_df = df.copy()\n\n    # Group by the representative query to handle each benchmark set\n    for query, group_df in original_index_df.groupby('representative_query'):\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitor']\n\n        if ours_df.empty or competitors_df.empty:\n            continue\n\n        # --- Define Core Morphemes from the Query ---\n        # A simple but effective method is to split the query string\n        core_morphemes = set(str(query).split())\n\n        # --- Calculate Derivative Morphemes for Competitors ---\n        competitor_derivative_counts = []\n        for _, row in competitors_df.iterrows():\n            competitor_morphemes_list = safe_literal_eval(row.get('morpheme_words'))\n            if not competitor_morphemes_list:\n                competitor_derivative_counts.append(0)\n                continue\n\n            competitor_morphemes = set(competitor_morphemes_list)\n            competitor_derivative_morphemes = competitor_morphemes - core_morphemes\n            competitor_derivative_counts.append(len(competitor_derivative_morphemes))\n\n        # Calculate the average benchmark value\n        avg_comp_derivative_count = np.mean(competitor_derivative_counts) if competitor_derivative_counts else 0\n\n        # --- Calculate and Assign Feature for Our Post(s) in the Group ---\n        for index, row in ours_df.iterrows():\n            our_morphemes_list = safe_literal_eval(row.get('morpheme_words'))\n            our_derivative_count = 0\n            if our_morphemes_list:\n                our_morphemes = set(our_morphemes_list)\n                our_derivative_morphemes = our_morphemes - core_morphemes\n                our_derivative_count = len(our_derivative_morphemes)\n\n            # Calculate the ratio, handling division by zero\n            ratio = 1.0  # Default to 1.0 (on par)\n            if avg_comp_derivative_count > 0:\n                ratio = our_derivative_count / avg_comp_derivative_count\n            elif our_derivative_count > 0:\n                # Competitors have 0 derivative morphemes, but we do.\n                # This indicates high richness. We cap it at 2.0 to avoid infinities.\n                ratio = 2.0\n            \n            # Assign the value back to the original dataframe using its preserved index\n            df.loc[index, feature_name] = ratio\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T10:20:38.317670",
  "attempt": 1,
  "status": "success",
  "feature_name": "authoritative_morpheme_coverage_ratio",
  "hypothesis": "우리 포스트가 해당 주제의 '권위 있는 형태소'(상위 경쟁자들이 공통적으로 사용하는 핵심 어휘)를 평균적인 상위 경쟁자보다 더 잘 커버할수록, 주제 전문성을 효과적으로 입증하여 비브랜드 유입이 증가할 것이다. 이 '권위 커버리지 비율'이 1을 초과하면 경쟁 우위를, 1 미만이면 열위를 나타낸다.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\nfrom collections import Counter\n\ndef safe_literal_eval(val):\n    \"\"\"Safely evaluate a string that should be a list, handling errors.\"\"\"\n    try:\n        if isinstance(val, list):\n            return val\n        if isinstance(val, str) and val.startswith('[') and val.endswith(']'):\n            return ast.literal_eval(val)\n        return []\n    except (ValueError, SyntaxError, TypeError):\n        return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of our post's coverage of 'authoritative morphemes' \n    compared to the average high-performing competitor.\n\n    1.  Defines 'high-performing competitors' as those in the top 50% of exposure_score.\n    2.  For each query, an 'authoritative vocabulary' is built from its high-performing competitors,\n        with morpheme weights based on frequency.\n    3.  A fallback 'global' authority vocabulary is created from all high-performing competitors in the dataset.\n        This is used when a query has no competitors, preventing a constant feature value.\n    4.  Each 'ours' post is scored based on the sum of weights of its morphemes.\n    5.  The final feature is the ratio of our post's score to the average high-performing competitor's score.\n    \"\"\"\n    feature_name = 'authoritative_morpheme_coverage_ratio'\n    df[feature_name] = 1.0\n\n    if df.empty or 'morpheme_words' not in df.columns or 'source' not in df.columns or 'representative_query' not in df.columns:\n        return df\n\n    df_copy = df.copy()\n    df_copy['morphemes'] = df_copy['morpheme_words'].apply(safe_literal_eval)\n\n    ours_df = df_copy[df_copy['source'] == 'ours']\n    competitors_df = df_copy[df_copy['source'] == 'competitors']\n\n    if ours_df.empty:\n        return df\n\n    # --- Create a global fallback benchmark --- #\n    # This is critical to avoid constant values when a query lacks competitors.\n    global_authority_weights = Counter()\n    global_avg_authority_score = 1.0\n\n    if not competitors_df.empty and 'exposure_score' in competitors_df.columns:\n        # Use a percentile to define \"high-performing\"\n        threshold = competitors_df['exposure_score'].quantile(0.50, interpolation='lower')\n        high_perf_competitors_global = competitors_df[competitors_df['exposure_score'] >= threshold]\n\n        if not high_perf_competitors_global.empty:\n            all_competitor_morphemes = [m for sublist in high_perf_competitors_global['morphemes'] for m in sublist]\n            if all_competitor_morphemes:\n                global_authority_weights = Counter(all_competitor_morphemes)\n                \n                global_scores = []\n                for _, row in high_perf_competitors_global.iterrows():\n                    score = sum(global_authority_weights.get(m, 0) for m in set(row['morphemes']))\n                    global_scores.append(score)\n                \n                if global_scores:\n                    global_avg_authority_score = np.mean(global_scores)\n\n    if global_avg_authority_score == 0:\n        global_avg_authority_score = 1.0\n\n    # --- Calculate per-query benchmarks --- #\n    query_benchmarks = {}\n    if not competitors_df.empty and 'exposure_score' in competitors_df.columns:\n        for query, group in competitors_df.groupby('representative_query'):\n            threshold = group['exposure_score'].quantile(0.50, interpolation='lower')\n            high_perf_group = group[group['exposure_score'] >= threshold]\n            \n            if high_perf_group.empty:\n                continue\n\n            group_morphemes = [m for sublist in high_perf_group['morphemes'] for m in sublist]\n            if not group_morphemes:\n                continue\n                \n            authority_weights = Counter(group_morphemes)\n            \n            scores = []\n            for _, row in high_perf_group.iterrows():\n                score = sum(authority_weights.get(m, 0) for m in set(row['morphemes']))\n                scores.append(score)\n            \n            if scores and np.mean(scores) > 0:\n                avg_score = np.mean(scores)\n                query_benchmarks[query] = {'weights': authority_weights, 'avg_score': avg_score}\n\n    # --- Calculate feature for 'ours' posts --- #\n    our_scores = {}\n    for index, row in ours_df.iterrows():\n        query = row['representative_query']\n        our_morphemes = set(row['morphemes'])\n        \n        benchmark = query_benchmarks.get(query)\n        \n        authority_weights = benchmark['weights'] if benchmark else global_authority_weights\n        avg_competitor_score = benchmark['avg_score'] if benchmark else global_avg_authority_score\n        \n        our_authority_score = sum(authority_weights.get(m, 0) for m in our_morphemes)\n        \n        if avg_competitor_score > 0:\n            ratio = our_authority_score / avg_competitor_score\n        else:\n            ratio = 1.0\n        \n        our_scores[index] = ratio\n\n    # --- Assign results back to the original DataFrame using the original index --- #\n    if our_scores:\n        df.loc[our_scores.keys(), feature_name] = pd.Series(our_scores)\n\n    df[feature_name].replace([np.inf, -np.inf], np.nan, inplace=True)\n    df[feature_name].fillna(1.0, inplace=True)\n        \n    return df\n",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}