{
  "timestamp": "2025-07-22T04:08:25.739709",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'morpheme_differentiation_score'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef _parse_morphemes_to_set(text):\n    \"\"\"Helper function to safely parse a comma-separated string of morphemes into a set.\"\"\"\n    if not isinstance(text, str) or not text.strip():\n        return set()\n    return set(morpheme.strip() for morpheme in text.split(',') if morpheme.strip())\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates a morpheme differentiation score for 'ours' posts against their competitors.\n\n    The score is defined as:\n    (Number of morphemes unique to our post) / (Number of morphemes shared with competitors + 1)\n    \n    This measures the unique lexical value our post provides relative to its common ground with competitors.\n    \"\"\"\n    feature_name = 'morpheme_differentiation_score'\n    df[feature_name] = np.nan\n\n    if df.empty:\n        return df\n\n    # Use .get() for safety in case the column is missing\n    if 'morpheme_words' not in df.columns:\n        return df\n\n    # Create a temporary column with morpheme sets for efficient processing\n    # This is a safe and efficient use of .apply() for a simple string operation.\n    df_copy = df.copy()\n    df_copy['morpheme_sets'] = df_copy['morpheme_words'].apply(_parse_morphemes_to_set)\n\n    # Group by the representative query to establish the comparison context.\n    # Preserving the original index of the DataFrame is crucial.\n    grouped = df_copy.groupby('representative_query')\n\n    for _, group_df in grouped:\n        our_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitors']\n\n        # Proceed only if we have our post(s) and at least one competitor to compare against.\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # Create a single, unified set of all morphemes used by competitors.\n        competitor_morphemes_union = set().union(*competitor_posts['morpheme_sets'])\n\n        # Calculate the score for each of our posts in the group (handles multiple 'ours' posts per query).\n        for idx, our_post in our_posts.iterrows():\n            our_morphemes = our_post['morpheme_sets']\n\n            if not our_morphemes:\n                # If our post has no morphemes, its differentiation is 0.\n                df.loc[idx, feature_name] = 0.0\n                continue\n\n            # Calculate morphemes unique to our post vs. the competitor group.\n            unique_to_us = our_morphemes.difference(competitor_morphemes_union)\n            \n            # Calculate morphemes shared between our post and the competitor group.\n            common_morphemes = our_morphemes.intersection(competitor_morphemes_union)\n\n            # The score measures how many unique morphemes we provide for each shared one.\n            # Adding 1 to the denominator prevents division by zero and provides an intuitive score\n            # (equal to the count of unique morphemes) when there is no overlap.\n            score = len(unique_to_us) / (len(common_morphemes) + 1.0)\n            \n            # Assign the calculated score back to the original DataFrame using the preserved index.\n            df.loc[idx, feature_name] = score\n\n    return df"
}{
  "timestamp": "2025-07-22T04:09:34.616046",
  "attempt": 2,
  "status": "execution_error",
  "error": "코드 실행 실패:\n  File \"/Users/min/codes/medilawyer_sales/blog_automation/agents/_temp_feature_generator.py\", line 19\n    try\n       ^\nSyntaxError: expected ':'\n",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef parse_morphemes(morpheme_str: str) -> set:\n    \"\"\"문자열로 표현된 형태소 리스트를 파싱하여 집합(set)으로 반환합니다.\"\"\"\n    if not isinstance(morpheme_str, str) or not morpheme_str.strip():\n        return set()\n    try\n        # ast.literal_eval은 문자열 리터럴을 안전하게 평가하는 가장 좋은 방법입니다.\n        morphemes = ast.literal_eval(morpheme_str)\n        if isinstance(morphemes, list):\n            return set(morphemes)\n        return set()\n    except (ValueError, SyntaxError):\n        # 대괄호 없이 쉼표로만 구분된 단순 문자열에 대한 예외 처리\n        return set(s.strip().strip(\"'\\\"\") for s in morpheme_str.split(',') if s.strip())\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대한 '형태소 독창성 점수'를 계산합니다.\n    이 점수는 1에서 '우리 포스트의 형태소'와 '경쟁자 전체의 형태소 집합' 간의 어휘 중복 비율을 뺀 값입니다.\n    점수가 높을수록 경쟁자와 비교하여 독창적인 어휘를 사용했음을 의미합니다.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'morpheme_originality_score'\n    df[feature_name] = np.nan\n\n    # 'representative_query'로 그룹화하여 'ours' 포스트와 직접적인 경쟁자를 비교합니다.\n    for query, group in df.groupby('representative_query'):\n        \n        competitors_df = group[group['source'] == 'competitor']\n        ours_df = group[group['source'] == 'ours']\n        \n        # 비교할 경쟁자 또는 'ours' 포스트가 없는 경우 다음 그룹으로 넘어갑니다.\n        if competitors_df.empty or ours_df.empty:\n            continue\n            \n        # 1. 해당 쿼리에 대한 모든 경쟁자들이 사용한 형태소를 포괄하는 집합을 만듭니다.\n        competitor_morphemes = set()\n        for morpheme_list_str in competitors_df['morpheme_words'].dropna():\n            competitor_morphemes.update(parse_morphemes(morpheme_list_str))\n            \n        # 2. 각 'ours' 포스트에 대해 경쟁자 집합과 비교하여 독창성 점수를 계산합니다.\n        for idx, row in ours_df.iterrows():\n            our_morphemes = parse_morphemes(row['morpheme_words'])\n            \n            if not our_morphemes:\n                # 우리 포스트에 형태소가 없으면 독창성은 0입니다.\n                df.loc[idx, feature_name] = 0.0\n                continue\n\n            if not competitor_morphemes:\n                # 경쟁자 형태소가 없으면 우리 포스트의 모든 형태소는 독창적입니다.\n                df.loc[idx, feature_name] = 1.0\n                continue\n            \n            # 공통 형태소(교집합)를 계산합니다.\n            common_morphemes = our_morphemes.intersection(competitor_morphemes)\n            \n            # 우리 포스트의 어휘 중 얼마나 많은 비율이 경쟁자와 겹치는지 계산합니다.\n            overlap_ratio = len(common_morphemes) / len(our_morphemes)\n            \n            # 독창성 점수는 1에서 중복 비율을 뺀 값입니다.\n            originality_score = 1 - overlap_ratio\n            \n            # 계산된 점수를 원본 DataFrame의 올바른 위치에 할당합니다.\n            df.loc[idx, feature_name] = originality_score\n            \n    return df"
}{
  "timestamp": "2025-07-22T04:10:16.057380",
  "attempt": 3,
  "status": "success",
  "feature_name": "morpheme_expansion_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹의 평균보다 대표 쿼리의 핵심 형태소를 더 다양하고 풍부하게 확장하여 사용할수록, 사용자의 검색 의도에 대한 포괄적인 답변을 제공하여 비브랜드 평균 클릭률(CTR)을 높일 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 쿼리의 핵심 형태소 대비, 각 포스트의 형태소 확장성을 계산하고\n    이를 경쟁자 그룹의 평균과 비교하여 비율을 산출하는 피처를 생성합니다.\n\n    - '핵심 형태소': 대표 쿼리를 공백으로 분리하여 얻은 단어 집합.\n    - '확장 형태소': 포스트의 형태소 중 핵심 형태소에 포함되지 않는 형태소.\n    - '확장성 점수': 각 포스트의 고유한 확장 형태소의 개수.\n    - '피처 값': (우리 포스트의 확장성 점수) / (경쟁자 그룹의 평균 확장성 점수)\n    \"\"\"\n    feature_name = 'morpheme_expansion_ratio'\n    df[feature_name] = np.nan\n\n    if df.empty:\n        return df\n\n    required_cols = ['representative_query', 'source', 'morpheme_words']\n    if not all(col in df.columns for col in required_cols):\n        return df\n\n    def safe_parse_morphemes(morpheme_str):\n        \"\"\"문자열로 된 리스트를 안전하게 파싱하여 set으로 반환합니다.\"\"\"\n        if not isinstance(morpheme_str, str):\n            return set()\n        try:\n            return set(ast.literal_eval(morpheme_str))\n        except (ValueError, SyntaxError, TypeError):\n            return set()\n\n    # 원본 인덱스를 보존하기 위해 그룹바이 객체를 직접 순회합니다.\n    # reset_index()를 사용하지 않아 데이터 정렬 오류를 방지합니다.\n    grouped = df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        if not isinstance(query, str) or not query.strip():\n            continue\n\n        core_morphemes = set(query.split())\n\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        competitor_expansion_scores = []\n        for morphemes_str in competitor_posts['morpheme_words']:\n            post_morphemes = safe_parse_morphemes(morphemes_str)\n            expansion_morphemes = post_morphemes - core_morphemes\n            competitor_expansion_scores.append(len(expansion_morphemes))\n\n        avg_competitor_expansion = np.mean(competitor_expansion_scores) if competitor_expansion_scores else 0\n        \n        # 0으로 나누는 것을 방지하기 위해 작은 값(epsilon)을 사용합니다.\n        denominator = avg_competitor_expansion if avg_competitor_expansion > 0 else 1e-6\n\n        # 'ours' 포스트에 대해 피처 값을 계산하고 원본 DataFrame에 할당합니다.\n        for idx, row in ours_posts.iterrows():\n            our_morphemes = safe_parse_morphemes(row['morpheme_words'])\n            our_expansion_score = len(our_morphemes - core_morphemes)\n            ratio = our_expansion_score / denominator\n            \n            # .loc를 사용하여 정확한 인덱스에 값을 할당합니다.\n            df.loc[idx, feature_name] = ratio\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T04:28:41.391092",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_morpheme_richness'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the relative morpheme richness of 'our' posts compared to the average\n    of competitor posts for the same representative query.\n\n    The feature is defined as:\n    (Unique morpheme count of our post) / (Average unique morpheme count of competitor posts)\n\n    Args:\n        df (pd.DataFrame): The input DataFrame with columns 'post_identifier',\n                           'source', 'representative_query', and 'morpheme_words'.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the new 'relative_morpheme_richness' column added.\n    \"\"\"\n    # 1. Safety check for empty DataFrame.\n    if df.empty:\n        return df\n\n    feature_name = 'relative_morpheme_richness'\n    # 2. Initialize the feature column with a default value (NaN).\n    # This ensures rows without a valid calculation (e.g., no competitors) are handled.\n    df[feature_name] = np.nan\n\n    # 3. Create a temporary column for unique morpheme counts for calculation efficiency.\n    # This vectorized approach is much faster than calculating within a loop.\n    # Handles empty strings and NaNs gracefully.\n    temp_morpheme_series = df['morpheme_words'].fillna('').astype(str)\n    df['temp_unique_morpheme_count'] = temp_morpheme_series.apply(lambda x: len(set(x.split(', '))) if x else 0)\n\n    # 4. Group data by the representative query to create comparison benchmarks.\n    # 'observed=True' is an optimization for categorical-like group keys.\n    grouped = df.groupby('representative_query', observed=True)\n\n    # 5. Iterate through each query group to perform the benchmark calculation.\n    for _, group_df in grouped:\n        # Isolate our posts and competitor posts within the group.\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitors']\n\n        # Proceed only if both our post(s) and competitor posts exist for the query.\n        if not ours_posts.empty and not competitor_posts.empty:\n            # Correctly handle multiple 'ours' posts per query if they exist.\n            u_ours_counts = ours_posts['temp_unique_morpheme_count']\n\n            # Calculate the single average benchmark from all competitors in the group.\n            u_competitor_avg = competitor_posts['temp_unique_morpheme_count'].mean()\n\n            # Calculate the ratio, handling the division-by-zero edge case.\n            if u_competitor_avg > 0:\n                ratio = u_ours_counts / u_competitor_avg\n            else:\n                # If competitors have no morphemes, the ratio is undefined. Use NaN.\n                ratio = np.nan\n\n            # 6. [CRITICAL] Assign the calculated ratio back to the original DataFrame\n            # using the preserved index of 'ours_posts'. This prevents misalignment.\n            df.loc[ours_posts.index, feature_name] = ratio\n\n    # 7. Clean up the temporary column.\n    df = df.drop(columns=['temp_unique_morpheme_count'])\n\n    # 8. Return the full DataFrame with the new feature column.\n    return df"
}{
  "timestamp": "2025-07-22T04:29:32.393630",
  "attempt": 2,
  "status": "success",
  "feature_name": "core_morpheme_expansion_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹보다 대표 쿼리의 핵심 형태소와 관련된 파생/확장 형태소를 더 많이 포함할수록, 해당 쿼리에 대한 더 깊은 전문성을 보여주어 CTR이 높을 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef _find_expanded_morphemes_count(morphemes_str: str, core_morphemes: set) -> int:\n    \"\"\"Helper function to count unique morphemes that contain a core morpheme.\"\"\"\n    if not isinstance(morphemes_str, str) or not morphemes_str or not core_morphemes:\n        return 0\n    \n    post_morphemes = set(morphemes_str.split())\n    expanded_count = 0\n    for morpheme in post_morphemes:\n        for core in core_morphemes:\n            # A morpheme is 'expanded' if it contains a core morpheme but is not the core morpheme itself.\n            if core in morpheme and core != morpheme:\n                expanded_count += 1\n                break  # Count each unique post morpheme only once\n    return expanded_count\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of expanded core morphemes in our post compared to the competitor average.\n    \n    An 'expanded' morpheme is a morpheme from the post that contains a core morpheme \n    from the representative query but is not identical to it (e.g., query='치과', post has '치과치료').\n    This feature measures the richness of related terminology.\n    \"\"\"\n    if df.empty:\n        df['core_morpheme_expansion_ratio'] = np.nan\n        return df\n\n    # Ensure required columns are strings, handling potential NaN values.\n    df_copy = df.copy()\n    df_copy['representative_query'] = df_copy['representative_query'].fillna('').astype(str)\n    df_copy['morpheme_words'] = df_copy['morpheme_words'].fillna('').astype(str)\n\n    # Use the original index for the results to ensure alignment.\n    results = pd.Series(np.nan, index=df_copy.index)\n\n    # Group by the representative query to create competitor benchmarks.\n    grouped = df_copy.groupby('representative_query')\n\n    for query, group_df in grouped:\n        if not query:\n            continue\n\n        # Define core morphemes from the query itself.\n        core_morphemes = set(query.split())\n\n        # Separate our posts from competitors within the group.\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitor']\n\n        if competitors_df.empty or ours_df.empty:\n            continue\n\n        # Calculate the number of expanded morphemes for each competitor.\n        competitor_expanded_counts = competitors_df['morpheme_words'].apply(\n            lambda x: _find_expanded_morphemes_count(x, core_morphemes)\n        )\n\n        # Calculate the competitor benchmark: the average number of expanded morphemes.\n        competitor_avg_expansion = competitor_expanded_counts.mean()\n\n        # Calculate the feature for each of our posts in the group.\n        # This is a row-wise calculation that prevents the previous error of identical values.\n        for idx, row in ours_df.iterrows():\n            our_expansion_count = _find_expanded_morphemes_count(row['morpheme_words'], core_morphemes)\n\n            if competitor_avg_expansion > 0:\n                # Calculate the ratio against the competitor benchmark.\n                ratio = our_expansion_count / competitor_avg_expansion\n            else:\n                # If competitors have no expanded morphemes, any expansion by us is significant.\n                # Assign 1 if we also have 0, and a higher value (e.g., 2) if we have any.\n                ratio = 1.0 if our_expansion_count == 0 else 2.0\n            \n            results.loc[idx] = ratio\n\n    # Assign the calculated feature to the original DataFrame.\n    df['core_morpheme_expansion_ratio'] = results\n    return df",
  "analysis": {
    "correlation": 0.013247347669693474,
    "p_value": 0.8986115995368451,
    "interpretation": "약한 양의 상관관계(0.0132)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.8986)."
  }
}{
  "timestamp": "2025-07-22T04:46:11.225773",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'core_morpheme_structural_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef calculate_structural_focus(morpheme_string: str, core_morphemes: set) -> float:\n    \"\"\"\n    Calculates the ratio of bigrams containing a core morpheme.\n    This measures the structural focus on the query's topic.\n    A bigram is a pair of adjacent morphemes.\n    \"\"\"\n    if not isinstance(morpheme_string, str) or not morpheme_string:\n        return 0.0\n\n    morphemes = morpheme_string.split()\n    if len(morphemes) < 2:\n        return 0.0\n\n    # Generate bigrams: (morpheme_1, morpheme_2), (morpheme_2, morpheme_3), ...\n    bigrams = list(zip(morphemes, morphemes[1:]))\n    total_bigrams = len(bigrams)\n\n    if total_bigrams == 0:\n        return 0.0\n\n    # Count bigrams where at least one of the two morphemes is a core morpheme.\n    core_bigram_count = sum(1 for b in bigrams if b[0] in core_morphemes or b[1] in core_morphemes)\n\n    return core_bigram_count / total_bigrams\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    [PART 2, TASK 8]\n    Generates 'core_morpheme_structural_ratio'.\n\n    This feature benchmarks the structural focus of our post's morphemes against competitors.\n    \"Structural focus\" is defined as the proportion of morpheme pairs (bigrams) that\n    contain at least one core morpheme from the representative query.\n    A ratio > 1 indicates our post's content is more structurally centered around the\n    query topic than the average competitor.\n    \"\"\"\n    feature_name = 'core_morpheme_structural_ratio'\n\n    # 1. Safety check for empty DataFrame and required columns\n    if df.empty or not all(col in df.columns for col in ['representative_query', 'source', 'morpheme_words']):\n        df[feature_name] = np.nan\n        return df\n\n    # 2. Initialize the feature column in the original DataFrame\n    df[feature_name] = np.nan\n\n    # 3. Group by the representative query to create benchmark groups\n    # Iterating over group indices is a safe way to modify the original df via .loc\n    for query, group_idx in df.groupby('representative_query').groups.items():\n        if not isinstance(query, str) or not query:\n            continue\n\n        # Select the group using .loc to work on a view, but assignments will be safe\n        group = df.loc[group_idx]\n        \n        # Identify core morphemes from the query string\n        core_morphemes = set(query.split())\n\n        # Calculate the structural focus score for every post in the group\n        group_focus_scores = group['morpheme_words'].fillna('').apply(\n            lambda x: calculate_structural_focus(x, core_morphemes)\n        )\n\n        # Separate our posts from competitors using boolean indexing on the group\n        is_ours = group['source'] == 'ours'\n        is_competitors = group['source'] == 'competitors'\n\n        ours_indices = group.index[is_ours]\n        competitor_indices = group.index[is_competitors]\n\n        if ours_indices.empty or competitor_indices.empty:\n            continue\n\n        # Calculate the benchmark (average focus score of competitors)\n        competitor_avg_focus = group_focus_scores[is_competitors].mean()\n\n        # Calculate the ratio for our posts and assign it back to the original DataFrame\n        # This assignment is safe because we use .loc with the original indices\n        if competitor_avg_focus > 0:\n            our_scores = group_focus_scores[is_ours]\n            ratios = our_scores / competitor_avg_focus\n            df.loc[ours_indices, feature_name] = ratios\n        else:\n            # Handle case where competitors have 0 focus. A positive score for us is infinitely better.\n            # Assign 1.0 if our score is also 0 (parity), and 2.0 (a high value) if our score is > 0.\n            our_scores = group_focus_scores[is_ours]\n            ratios = our_scores.apply(lambda s: 2.0 if s > 0 else 1.0)\n            df.loc[ours_indices, feature_name] = ratios\n\n    return df"
}{
  "timestamp": "2025-07-22T04:47:33.881995",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_morpheme_richness'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nimport re\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    우리 포스트와 경쟁자 포스트 그룹 간의 형태소 풍부함을 비교하는 피처를 생성합니다.\n\n    피처 로직:\n    1. 각 포스트에 대해 '형태소 풍부함 점수'를 계산합니다. 이 점수는 (대표 쿼리의 핵심 형태소 빈도) * log(총 고유 형태소 수 + 1) 입니다.\n    2. 각 대표 쿼리 그룹별로 경쟁자 포스트들의 평균 '형태소 풍부함 점수'를 계산하여 벤치마크로 설정합니다.\n    3. 우리 포스트의 '형태소 풍부함 점수'를 해당 쿼리의 경쟁자 평균 점수로 나누어 최종 비율을 계산합니다.\n    4. 이 비율은 우리 포스트가 경쟁자 대비 얼마나 더 풍부한 형태소 구조를 갖는지를 나타내며, 값이 클수록 긍정적입니다.\n    \"\"\"\n    feature_name = 'relative_morpheme_richness'\n    df[feature_name] = np.nan\n\n    if df.empty or 'morpheme_words' not in df.columns or 'representative_query' not in df.columns:\n        return df\n\n    # 1. 전처리: morpheme_words를 리스트로 변환\n    temp_df = df.copy()\n    temp_df['morpheme_list'] = temp_df['morpheme_words'].fillna('').astype(str).apply(lambda x: re.split(r',\\s*', x) if x else [])\n\n    # 2. 형태소 풍부함 점수 계산 로직 정의\n    def calculate_richness(morpheme_list, core_morphemes):\n        if not morpheme_list or not core_morphemes:\n            return 0\n        core_freq = sum(1 for m in morpheme_list if m in core_morphemes)\n        diversity = len(set(morpheme_list))\n        # 핵심 형태소의 빈도와 전체 형태소의 다양성을 모두 반영\n        richness_score = core_freq * np.log1p(diversity)\n        return richness_score\n\n    # 각 행의 대표 쿼리를 기반으로 핵심 형태소 리스트 생성\n    temp_df['core_morphemes'] = temp_df['representative_query'].fillna('').str.split()\n\n    # 모든 포스트에 대해 풍부함 점수 계산\n    temp_df['richness_score'] = temp_df.apply(\n        lambda row: calculate_richness(row['morpheme_list'], row['core_morphemes']),\n        axis=1\n    )\n\n    # 3. 경쟁자 그룹의 벤치마크 점수 계산\n    competitor_scores = temp_df[temp_df['source'] == 'competitors']\n    if not competitor_scores.empty:\n        competitor_avg_richness_map = competitor_scores.groupby('representative_query')['richness_score'].mean()\n        temp_df['competitor_avg_richness'] = temp_df['representative_query'].map(competitor_avg_richness_map)\n    else:\n        temp_df['competitor_avg_richness'] = np.nan\n\n    # 4. 우리 포스트에 대한 최종 피처 값 계산\n    our_posts_mask = temp_df['source'] == 'ours'\n    denominator = temp_df['competitor_avg_richness']\n    \n    # 0으로 나누는 것을 방지. 0이나 NaN인 경우 결과를 NaN으로 만들어 후처리에서 일괄 처리\n    denominator = denominator.replace(0, np.nan)\n\n    # 우리 포스트에 대해서만 비율 계산\n    feature_values = temp_df.loc[our_posts_mask, 'richness_score'] / denominator.loc[our_posts_mask]\n    df.loc[our_posts_mask, feature_name] = feature_values\n\n    # 5. 후처리: 경쟁자가 없거나 점수가 0인 경우 발생하는 NaN/inf 값을 중립적인 값 1.0으로 대체\n    df[feature_name] = df[feature_name].replace([np.inf, -np.inf], np.nan)\n    df[feature_name].fillna(1.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T04:48:31.116187",
  "attempt": 3,
  "status": "success",
  "feature_name": "relative_morpheme_coverage",
  "hypothesis": "우리 포스트가 동일 대표 검색어에 대한 경쟁자 그룹 전체가 사용하는 고유 형태소 집합의 더 넓은 범위를 포괄할수록, 내용의 포괄성과 관련성이 높다고 판단되어 클릭률이 증가할 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef _parse_morphemes_to_set(series: pd.Series) -> pd.Series:\n    \"\"\"Helper function to safely parse a string of morphemes into a set.\"\"\"\n    def split_and_clean(morpheme_str):\n        if pd.isna(morpheme_str) or not isinstance(morpheme_str, str) or not morpheme_str.strip():\n            return set()\n        # Split by comma, strip whitespace from each item, and return as a set\n        return set(item.strip() for item in morpheme_str.split(','))\n    return series.apply(split_and_clean)\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates how much of the competitors' total morpheme vocabulary is covered by our post.\n    This feature fixes the previous error by ensuring a unique value is calculated for each\n    'ours' post based on its specific content, thus creating variance for correlation analysis.\n    \"\"\"\n    feature_name = 'relative_morpheme_coverage'\n\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # Work on a copy to avoid SettingWithCopyWarning\n    df_copy = df.copy()\n\n    # Initialize the feature column with a neutral default value (1.0)\n    # This value will be used for posts in query groups without competitors.\n    df_copy[feature_name] = 1.0\n\n    # Pre-process the morpheme strings into sets for efficient operations\n    df_copy['morpheme_set'] = _parse_morphemes_to_set(df_copy['morpheme_words'])\n\n    # Group by representative query to compare 'ours' vs 'competitors'\n    grouped = df_copy.groupby('representative_query')\n\n    for query, group_df in grouped:\n        ours_indices = group_df[group_df['source'] == 'ours'].index\n        competitor_indices = group_df[group_df['source'] == 'competitor'].index\n\n        # Skip if there are no 'ours' posts or no 'competitors' for this query\n        if ours_indices.empty or competitor_indices.empty:\n            continue\n\n        # Create the benchmark: a single set of all unique morphemes used by all competitors for this query\n        competitor_morphemes_list = group_df.loc[competitor_indices, 'morpheme_set'].tolist()\n        competitor_benchmark_set = set.union(*competitor_morphemes_list) if competitor_morphemes_list else set()\n\n        # If the competitor benchmark set is empty, we cannot calculate a ratio.\n        # The default value of 1.0 will be kept, implying parity with non-existent vocabulary.\n        if not competitor_benchmark_set:\n            continue\n        \n        # For each of our posts, calculate its coverage of the competitor benchmark vocabulary\n        for idx in ours_indices:\n            our_post_set = df_copy.loc[idx, 'morpheme_set']\n            \n            if not our_post_set:\n                # If our post has no morphemes, its coverage is 0\n                coverage = 0.0\n            else:\n                # Find the common morphemes\n                common_morphemes = our_post_set.intersection(competitor_benchmark_set)\n                \n                # Calculate the coverage ratio\n                coverage = len(common_morphemes) / len(competitor_benchmark_set)\n\n            # Assign the specific, calculated value back to the DataFrame using the original index\n            df_copy.loc[idx, feature_name] = coverage\n            \n    # Assign the calculated feature column back to the original DataFrame to ensure its integrity\n    df[feature_name] = df_copy[feature_name]\n    \n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T05:07:46.279878",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'core_morpheme_structural_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef safe_literal_eval(val):\n    \"\"\"Safely evaluate a string that looks like a Python literal (e.g., a list).\n    Returns an empty list if parsing fails.\n    \"\"\"\n    if isinstance(val, str):\n        try:\n            return ast.literal_eval(val)\n        except (ValueError, SyntaxError):\n            return []\n    return val if isinstance(val, list) else []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of structural morphemes to core morphemes for our posts,\n    benchmarked against the same ratio from top-performing competitors.\n\n    - Core morphemes: Morphemes present in the 'representative_query'.\n    - Structural morphemes: All other morphemes in the post.\n    - The feature value is (Our Ratio) / (Competitor Benchmark Ratio).\n    - A value > 1 suggests a richer morpheme structure than competitors.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'core_morpheme_structural_ratio'\n    # Preserve original index by assigning to a new column in the input df\n    df[feature_name] = np.nan\n\n    # Safely parse the morpheme words string into a list\n    df['morpheme_list'] = df['morpheme_words'].apply(safe_literal_eval)\n\n    # Ensure required columns are present\n    required_cols = ['representative_query', 'source', 'total_views', 'morpheme_list']\n    if not all(col in df.columns for col in required_cols):\n        # Drop the temporary column before returning\n        df.drop(columns=['morpheme_list'], inplace=True)\n        return df\n\n    # Group by query to create per-query benchmarks\n    for query, group_df in df.groupby('representative_query'):\n        if not isinstance(query, str) or not query:\n            continue\n\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitor']\n\n        if ours_df.empty or competitors_df.empty:\n            continue\n\n        # 1. Identify top competitors (using total_views as a performance proxy)\n        # Avoids the mistake of treating all competitors as high-performing\n        top_competitors = competitors_df.nlargest(5, 'total_views')\n        if top_competitors.empty:\n            continue\n\n        # 2. Define core morphemes from the query\n        query_morphemes = set(query.split())\n\n        # 3. Calculate competitor benchmark ratio\n        all_comp_morphemes = [morpheme for sublist in top_competitors['morpheme_list'] for morpheme in sublist]\n        \n        if not all_comp_morphemes:\n            continue # Skip if competitors have no morphemes\n\n        core_count_comp = sum(1 for m in all_comp_morphemes if m in query_morphemes)\n        structural_count_comp = len(all_comp_morphemes) - core_count_comp\n\n        # Handle division by zero for competitor ratio\n        if core_count_comp == 0:\n            # If competitors have no core morphemes, the concept of a structural ratio is undefined.\n            # We can't form a meaningful benchmark.\n            competitor_ratio = 0\n        else:\n            competitor_ratio = structural_count_comp / core_count_comp\n\n        # 4. Calculate ratio for each 'ours' post and the final feature value\n        for index, row in ours_df.iterrows():\n            our_morphemes = row['morpheme_list']\n            if not our_morphemes:\n                df.loc[index, feature_name] = 0 # No morphemes, so ratio is 0\n                continue\n\n            core_count_our = sum(1 for m in our_morphemes if m in query_morphemes)\n            structural_count_our = len(our_morphemes) - core_count_our\n            \n            if core_count_our == 0:\n                our_ratio = 0\n            else:\n                our_ratio = structural_count_our / core_count_our\n\n            # Final benchmarked ratio\n            if competitor_ratio > 0:\n                final_ratio = our_ratio / competitor_ratio\n            elif our_ratio > 0:\n                # We have a structural ratio, but the benchmark is 0 (competitors are 100% core morphemes).\n                # This indicates high relative performance, so we cap it at a high value.\n                final_ratio = 5.0 \n            else:\n                # Both our_ratio and competitor_ratio are 0. They are structurally identical.\n                final_ratio = 1.0\n            \n            # Assign the calculated feature to the correct row using its original index\n            df.loc[index, feature_name] = final_ratio\n\n    # Clean up the temporary column\n    df.drop(columns=['morpheme_list'], inplace=True)\n    \n    return df"
}{
  "timestamp": "2025-07-22T05:08:34.457872",
  "attempt": 2,
  "status": "success",
  "feature_name": "morpheme_exclusivity_score",
  "hypothesis": "우리 포스트가 경쟁자 그룹에서 사용하지 않는 고유한 형태소를 더 많이 포함할수록 (즉, 형태소 배타성 점수가 높을수록), 주제에 대한 차별화된 관점이나 깊이를 제공하는 것으로 인식되어 CTR이 높아질 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the morpheme exclusivity score for each 'ours' post.\n\n    The score represents the ratio of morphemes in an 'ours' post that do not appear\n    in any of the competitor posts for the same representative query. A higher score\n    indicates greater lexical originality compared to the competition.\n\n    This addresses the previous logical error where a generated feature had a constant\n    value for all rows. This implementation ensures a unique score for each 'ours' post\n    based on its specific morpheme content, thus creating variance for correlation analysis.\n    \"\"\"\n    feature_name = 'morpheme_exclusivity_score'\n\n    # 1. Handle empty DataFrame\n    if df.empty:\n        df[feature_name] = pd.Series(dtype=float)\n        return df\n\n    # 2. Initialize the feature column with a default value\n    df[feature_name] = 0.0\n\n    # 3. Pre-process 'morpheme_words' to ensure it's a string and handle NaNs\n    df_copy = df.copy()\n    df_copy['morpheme_words'] = df_copy['morpheme_words'].fillna('').astype(str)\n\n    # 4. Dictionary to store results, keyed by the original DataFrame index\n    # This is a safe method to prevent index misalignment issues.\n    results = {}\n\n    # 5. Group by representative_query to process each benchmark set\n    for query, group in df_copy.groupby('representative_query'):\n        if not query or pd.isna(query):\n            continue\n\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        if competitor_posts.empty or ours_posts.empty:\n            continue\n\n        # 6. Create a single, unified set of all morphemes from all competitor posts\n        all_competitor_morphemes = set()\n        competitor_morpheme_lists = competitor_posts['morpheme_words'].str.split().tolist()\n        for morpheme_list in competitor_morpheme_lists:\n            all_competitor_morphemes.update(morpheme_list)\n\n        # 7. Calculate score for each 'ours' post individually\n        for index, row in ours_posts.iterrows():\n            our_morphemes_list = row['morpheme_words'].split()\n            if not our_morphemes_list:\n                results[index] = 0.0\n                continue\n\n            our_morphemes_set = set(our_morphemes_list)\n            \n            # 8. Find morphemes exclusive to the 'ours' post\n            exclusive_morphemes = our_morphemes_set.difference(all_competitor_morphemes)\n            \n            # 9. Calculate and store the normalized exclusivity score\n            # This normalization prevents bias from post length and ensures variance.\n            score = len(exclusive_morphemes) / len(our_morphemes_set)\n            results[index] = score\n\n    # 10. Safely map the calculated scores back to the original DataFrame\n    if results:\n        # Create a Series from the results dictionary, which aligns by index\n        feature_series = pd.Series(results, name=feature_name)\n        df[feature_name] = feature_series\n        # Fill any posts that were not processed (e.g., no competitors) with 0\n        df[feature_name] = df[feature_name].fillna(0.0)\n\n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T05:27:54.157582",
  "attempt": 1,
  "status": "execution_error",
  "error": "코드 실행 실패:\nError during script execution: [Errno 2] JVM DLL not found: /Library/Java/JavaVirtualMachines/jdk-21.0.2.jdk/Contents/MacOS/libjli.dylib\n",
  "code": "import pandas as pd\nimport numpy as np\nfrom konlpy.tag import Okt\n\n# 1. Lazy-load the morpheme analyzer to avoid re-initializing it on every call.\n_okt = None\n\ndef get_okt():\n    \"\"\"Initializes and returns a singleton Okt instance.\"\"\"\n    global _okt\n    if _okt is None:\n        _okt = Okt()\n    return _okt\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the relative morpheme expansion score for our posts compared to competitors.\n\n    This feature measures how much a post expands on the core query morphemes relative\n    to the collective expansion of all competitors for the same query.\n    The ratio is smoothed to prevent division by zero.\n    \"\"\"\n    # 2. Check for an empty DataFrame to prevent errors.\n    if df.empty:\n        return df\n\n    okt = get_okt()\n    feature_name = 'relative_morpheme_expansion'\n    df[feature_name] = np.nan  # Initialize the feature column\n\n    # 3. Pre-process the morpheme_words string into a list of clean morphemes.\n    def clean_morphemes(morpheme_string):\n        if not isinstance(morpheme_string, str) or morpheme_string == '':\n            return []\n        # Split by comma and strip whitespace to handle variations like 'a,b' and 'a, b'\n        return [m.strip() for m in morpheme_string.split(',') if m.strip()]\n\n    # Use a temporary column to store the lists for efficient processing.\n    df['morpheme_words_list'] = df['morpheme_words'].apply(clean_morphemes)\n\n    results = {}  # Use a dictionary to map results to the original DataFrame index.\n\n    # 4. Group by 'representative_query' to create a per-query benchmark.\n    for query, group_df in df.groupby('representative_query'):\n        if not isinstance(query, str) or not query:\n            continue\n\n        our_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitors']\n\n        # Proceed only if both our posts and competitor posts exist for the query.\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # Step A: Get core morphemes from the representative query.\n        query_morphemes = set(okt.morphs(query))\n\n        # Step B: Get the collective set of unique morphemes from all competitors.\n        # .explode() is efficient for creating a single Series from lists.\n        all_competitor_morphemes = set(competitor_posts['morpheme_words_list'].explode().unique())\n\n        # Step C: Calculate the competitor group's morpheme expansion beyond the core query.\n        competitor_expansion_morphemes = all_competitor_morphemes - query_morphemes\n        competitor_expansion_size = len(competitor_expansion_morphemes)\n\n        # Step D: For each of our posts, calculate its expansion and the ratio.\n        for idx, row in our_posts.iterrows():\n            our_morphemes = set(row['morpheme_words_list'])\n            our_expansion_morphemes = our_morphemes - query_morphemes\n            our_expansion_size = len(our_expansion_morphemes)\n\n            # Use Laplace smoothing (add-1) to create a stable ratio and avoid division by zero.\n            ratio = (our_expansion_size + 1) / (competitor_expansion_size + 1)\n\n            # Store the result with the original index to ensure correct assignment.\n            results[idx] = ratio\n\n    # 5. Assign the calculated values back to the DataFrame using the original index.\n    if results:\n        df.loc[list(results.keys()), feature_name] = list(results.values())\n\n    # Clean up the temporary column.\n    df.drop(columns=['morpheme_words_list'], inplace=True)\n\n    # 6. Return the full DataFrame with the new feature column.\n    return df"
}{
  "timestamp": "2025-07-22T05:29:20.439064",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'relative_morpheme_coverage'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nimport re\n\n# Java(konlpy) 의존성을 제거하고, 이미 전처리된 morpheme_words 컬럼을 직접 활용합니다.\n\ndef _parse_morphemes(morpheme_str):\n    \"\"\"문자열 형태의 형태소 리스트를 파싱하여 set으로 반환합니다.\"\"\"\n    if not isinstance(morpheme_str, str) or not morpheme_str.strip():\n        return set()\n    # 쉼표로 구분하고, 각 형태소의 앞뒤 공백을 제거합니다.\n    return set(token.strip() for token in morpheme_str.split(',') if token.strip())\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 검색어의 핵심 형태소에 대한 우리 포스트와 경쟁자 포스트의 커버리지 비율을 계산합니다.\n    이전 시도의 JVM DLL not found 오류를 회피하기 위해 Java 의존성 라이브러리를 사용하지 않습니다.\n    \"\"\"\n    if df.empty:\n        return df\n\n    # 피처 컬럼을 NaN으로 초기화하여, 처리되지 않은 그룹은 비워둡니다.\n    feature_name = 'relative_morpheme_coverage'\n    df[feature_name] = np.nan\n\n    # 대표 검색어를 기준으로 그룹화\n    grouped = df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        if not isinstance(query, str) or not query:\n            continue\n\n        our_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # 벤치마크가 될 '핵심 형태소' 집합을 정의합니다.\n        # 경쟁자 포스트 전체의 형태소 중, 실제 대표 검색어 문자열에 포함된 것들만 핵심으로 간주합니다.\n        all_competitor_morphemes = set().union(*competitor_posts['morpheme_words'].apply(_parse_morphemes))\n        core_query_morphemes = {m for m in all_competitor_morphemes if m in query}\n\n        if not core_query_morphemes:\n            continue # 비교 기준이 되는 핵심 형태소가 없으면 계산 불가\n\n        # 경쟁자 그룹의 평균 커버리지 계산\n        competitor_coverages = [\n            len(_parse_morphemes(morphemes).intersection(core_query_morphemes))\n            for morphemes in competitor_posts['morpheme_words']\n        ]\n        \n        # competitor_coverages 리스트가 비어있지 않은 경우에만 평균을 계산합니다.\n        if not competitor_coverages:\n            avg_competitor_coverage = 0\n        else:\n            avg_competitor_coverage = np.mean(competitor_coverages)\n\n        # 우리 각 포스트의 커버리지 및 비율 계산\n        for idx, our_post in our_posts.iterrows():\n            our_morphemes = _parse_morphemes(our_post['morpheme_words'])\n            our_coverage = len(our_morphemes.intersection(core_query_morphemes))\n            \n            # 0으로 나누는 것을 방지하기 위해 분모에 작은 값을 더합니다.\n            ratio = our_coverage / (avg_competitor_coverage + 1e-6)\n            \n            # 원본 DataFrame의 올바른 위치에 값을 할당합니다.\n            df.loc[idx, feature_name] = ratio\n\n    # NaN 값을 가진 행들을 1.0 (중립)으로 채워 후속 분석에 영향을 주지 않도록 합니다.\n    df[feature_name].fillna(1.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:30:55.575874",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'core_morpheme_expansion_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef parse_morphemes(series: pd.Series) -> pd.Series:\n    \"\"\"Safely parses a string of comma-separated morphemes into a set of morphemes.\"\"\"\n    # 공백, NaN 값 등을 처리하고, 각 행을 형태소 집합(set)으로 변환합니다.\n    return series.fillna('').astype(str).str.split(',\\s*').apply(lambda x: set(s.strip() for s in x if s.strip()))\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    '핵심 형태소 확장 비율 (Core Morpheme Expansion Ratio)' 피처를 계산합니다.\n\n    이 피처는 '우리' 포스트가 대표 검색어의 핵심 형태소를 경쟁자 평균에 비해\n    얼마나 더 확장하여 사용했는지를 측정합니다. 점수가 1보다 높으면 우리 포스트가\n    핵심 주제에 대해 더 심층적으로 파생된 관련 용어를 사용했음을 의미합니다.\n\n    점수 계산 방식:\n    (우리 포스트의 고유 확장 형태소 수) / (경쟁사 포스트당 평균 고유 확장 형태소 수 + epsilon)\n\n    '확장 형태소'란, 포스트의 형태소 중 대표 검색어를 구성하는 핵심 단어(예: '송곳니 충치'의 '송곳니', '충치')를\n    포함하지만, 핵심 단어 자체는 아닌 형태소(예: '송곳니치료', '충치증상')를 의미합니다.\n    \"\"\"\n    if df.empty:\n        return df\n\n    # 최종 피처 값을 저장할 딕셔너리 {DataFrame 인덱스: 점수}\n    feature_scores = {}\n    \n    # 원본 DataFrame 수정을 피하기 위해 작업용 복사본 생성\n    df_work = df.copy()\n    \n    # 반복문 내에서 중복 작업을 피하기 위해 모든 행의 형태소를 미리 파싱하여 집합으로 만듭니다.\n    df_work['morpheme_set'] = parse_morphemes(df_work['morpheme_words'])\n\n    # 각 대표 검색어별로 컨텍스트를 분리하여 그룹화합니다.\n    grouped = df_work.groupby('representative_query')\n\n    for query, group in grouped:\n        # 유효한 문자열 쿼리인지 확인합니다.\n        if not isinstance(query, str) or not query:\n            continue\n\n        # 현재 그룹 내에서 '우리' 포스트와 '경쟁사' 포스트를 분리합니다.\n        our_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitors']\n\n        # '우리' 포스트나 비교할 '경쟁사' 포스트가 없으면 계산을 건너뜁니다.\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # 1. 대표 검색어 문자열을 공백 기준으로 분리하여 핵심 형태소를 정의합니다.\n        core_morphemes = set(query.split())\n\n        # 2. 경쟁사 그룹의 평균 형태소 확장 수를 계산합니다.\n        competitor_expansion_counts = []\n        for _, comp_row in competitor_posts.iterrows():\n            comp_morphemes_set = comp_row['morpheme_set']\n            # 핵심 형태소를 포함하지만, 그 자체는 아닌 '확장 형태소'를 찾습니다.\n            expanded_morphemes = {\n                morpheme for morpheme in comp_morphemes_set\n                if any(core in morpheme for core in core_morphemes) and morpheme not in core_morphemes\n            }\n            competitor_expansion_counts.append(len(expanded_morphemes))\n        \n        # np.mean은 빈 리스트에 대해 NaN을 반환하며, 이 경우 0으로 처리합니다.\n        avg_competitor_expansion = np.mean(competitor_expansion_counts) if competitor_expansion_counts else 0\n        \n        # 0으로 나누기 오류를 방지하기 위해 분모에 작은 값(epsilon)을 더합니다.\n        denominator = avg_competitor_expansion + 1e-6\n\n        # 3. '우리'의 각 포스트에 대해 확장 비율을 계산하고 저장합니다.\n        for idx, our_row in our_posts.iterrows():\n            our_morphemes_set = our_row['morpheme_set']\n            # 우리 포스트의 확장 형태소를 찾습니다.\n            our_expanded_morphemes = {\n                morpheme for morpheme in our_morphemes_set\n                if any(core in morpheme for core in core_morphemes) and morpheme not in core_morphemes\n            }\n            our_expansion_count = len(our_expanded_morphemes)\n            \n            # 최종 점수는 우리 포스트의 확장 수와 경쟁사 평균의 비율입니다.\n            expansion_ratio = our_expansion_count / denominator\n            \n            # 원본 DataFrame의 인덱스를 키로 사용하여 결과를 저장합니다.\n            feature_scores[idx] = expansion_ratio\n            \n    # 계산된 점수들을 원본 DataFrame의 새 피처 컬럼에 할당합니다.\n    # .map을 사용하면 인덱스를 기준으로 정확하게 값이 매핑됩니다.\n    df['core_morpheme_expansion_ratio'] = df.index.map(feature_scores)\n    \n    # 점수를 계산하지 못한 행(예: 그룹 내 경쟁사가 없는 경우)은\n    # 경쟁사와 동등하다는 의미의 중립적인 값 1.0으로 채웁니다.\n    df['core_morpheme_expansion_ratio'].fillna(1.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:32:32.722442",
  "attempt": 4,
  "status": "execution_error",
  "error": "코드 실행 실패:\nError during script execution: [Errno 2] JVM DLL not found: /Library/Java/JavaVirtualMachines/jdk-21.0.2.jdk/Contents/MacOS/libjli.dylib\n",
  "code": "import pandas as pd\nimport numpy as np\nfrom konlpy.tag import Okt\nimport ast\n\n# 1. Lazy-load the morpheme analyzer to avoid re-initializing it on every call.\n_okt_model = None\n\ndef get_okt_model():\n    global _okt_model\n    if _okt_model is None:\n        _okt_model = Okt()\n    return _okt_model\n\ndef _safe_literal_eval(val):\n    \"\"\"Safely evaluate a string representation of a list, or return the list if it's already one.\"\"\"\n    if isinstance(val, list):\n        return val\n    if isinstance(val, str):\n        try:\n            # Use ast.literal_eval for safe evaluation\n            evaluated = ast.literal_eval(val)\n            if isinstance(evaluated, list):\n                return evaluated\n        except (ValueError, SyntaxError):\n            # If it's not a list-like string, return an empty list\n            return []\n    # Handle other types like float (NaN) by returning an empty list\n    return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates how well our post covers the 'expansion' morphemes used by competitors.\n    Expansion morphemes are those used in content but not present in the core query itself.\n    This feature measures topical depth and breadth beyond simple query matching.\n    \"\"\"\n    feature_name = 'relative_morpheme_expansion'\n    # Initialize the feature column with a default value (e.g., NaN or 0)\n    df[feature_name] = 0.0\n\n    if df.empty:\n        return df\n\n    # Get the morpheme analyzer\n    okt = get_okt_model()\n\n    # Create a temporary column with guaranteed set format for morphemes.\n    # This is more efficient as it avoids repeated type checking and conversion inside the loop.\n    # Using a set directly is also more efficient for vocabulary operations.\n    df['morpheme_set'] = df['morpheme_words'].apply(lambda x: set(_safe_literal_eval(x)))\n\n    # Store results in a dictionary mapping original index to feature value for safe assignment.\n    # This prevents potential index misalignment issues.\n    results = {}\n    \n    # Process data in groups based on the representative query\n    for query_str, group_df in df.groupby('representative_query'):\n        # Skip groups with no valid query string\n        if pd.isna(query_str) or not query_str.strip():\n            continue\n\n        # Separate 'ours' from 'competitor' posts for the current group\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitor']\n\n        # Calculation requires both our posts and competitor posts to exist in the group\n        if ours_df.empty or competitors_df.empty:\n            continue\n\n        # 1. Define Core Morphemes: Extract nouns from the query string\n        try:\n            core_morphemes = set(okt.nouns(query_str))\n        except Exception:\n            # In case of an error with the tokenizer, skip this group\n            continue\n        \n        # If the query has no identifiable core morphemes, expansion is not meaningful\n        if not core_morphemes:\n            continue\n\n        # 2. Define Competitor Expansion Vocabulary\n        # Aggregate all unique morphemes from all competitor posts in the group\n        competitor_morpheme_pool = set.union(*competitors_df['morpheme_set'])\n        # The benchmark is the set of morphemes used by competitors that are NOT in the core query\n        competitor_expansion_vocab = competitor_morpheme_pool - core_morphemes\n\n        # If competitors don't use any expansion morphemes, the ratio is undefined.\n        # We set it to 0 for our posts in this group, as there's no expansion vocabulary to match.\n        if not competitor_expansion_vocab:\n            for index in ours_df.index:\n                results[index] = 0.0\n            continue\n\n        # 3. Calculate feature for each of our posts in the group\n        for index, row in ours_df.iterrows():\n            our_post_morphemes = row['morpheme_set']\n            # Our expansion is the set of morphemes we use that are NOT in the core query\n            our_expansion_vocab = our_post_morphemes - core_morphemes\n            \n            # Calculate the overlap between our expansion and the competitor's expansion\n            # This measures how well we cover the relevant, non-query vocabulary\n            intersection_size = len(our_expansion_vocab.intersection(competitor_expansion_vocab))\n            benchmark_size = len(competitor_expansion_vocab)\n            \n            # The feature is the ratio of our coverage of the benchmark expansion vocabulary\n            expansion_ratio = intersection_size / benchmark_size if benchmark_size > 0 else 0.0\n            \n            # Store the result using the original DataFrame index to prevent misalignment\n            results[index] = expansion_ratio\n\n    # Assign all calculated values to the DataFrame in a single, efficient operation\n    if results:\n        # Using .loc with the dictionary keys ensures values are assigned to the correct rows\n        df.loc[list(results.keys()), feature_name] = list(results.values())\n    \n    # Clean up the temporary column\n    df.drop(columns=['morpheme_set'], inplace=True)\n    \n    return df"
}{
  "timestamp": "2025-07-22T05:33:21.289996",
  "attempt": 5,
  "status": "success",
  "feature_name": "query_morpheme_expansion_score",
  "hypothesis": "우리 포스트가 대표 검색어의 핵심 형태소를 기반으로 관련 파생/확장 형태소를 경쟁자 그룹의 평균보다 더 많이 포함할수록, 검색 의도의 다각적인 측면을 더 잘 충족시켜 클릭률(CTR)이 높을 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nimport re\n\n# JVM-dependent libraries are NOT used to prevent execution errors.\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 검색어에 포함된 형태소를 기반으로, 본문에서 관련 파생/확장 형태소의 사용량을\n    경쟁사 그룹과 비교하여 상대적인 확장성 점수를 계산합니다.\n\n    이 피처는 Konlpy와 같은 JVM 의존성 라이브러리 없이, 사전 계산된 'morpheme_words' 열을\n    활용하여 JVM 관련 실행 오류를 원천적으로 방지합니다.\n    \"\"\"\n    feature_name = 'query_morpheme_expansion_score'\n\n    if df.empty:\n        df[feature_name] = np.nan\n        return df\n\n    # 필수 컬럼 존재 여부 및 데이터 유효성 확인\n    required_cols = ['source', 'representative_query', 'morpheme_words']\n    if not all(col in df.columns for col in required_cols):\n        df[feature_name] = np.nan\n        return df\n\n    # morpheme_words 컬럼이 모두 NaN인 경우 처리\n    if df['morpheme_words'].isnull().all():\n        df[feature_name] = np.nan\n        return df\n\n    # 결과를 저장할 컬럼 초기화\n    df[feature_name] = np.nan\n\n    # 데이터 복사본 생성하여 SettingWithCopyWarning 방지\n    temp_df = df.copy()\n\n    # 전처리 함수 정의\n    def parse_morphemes(morpheme_string):\n        if pd.isna(morpheme_string):\n            return set()\n        # 쉼표와 공백을 기준으로 분리하고, 빈 문자열 제거\n        return set(re.split(r'[\\s,]+', str(morpheme_string).strip())) - {''}\n\n    # 형태소 문자열을 집합(Set)으로 변환\n    temp_df['morpheme_set'] = temp_df['morpheme_words'].apply(parse_morphemes)\n\n    # 대표 검색어를 공백 기준으로 분리하여 형태소 집합 생성\n    temp_df['query_morpheme_set'] = temp_df['representative_query'].fillna('').apply(lambda x: set(x.split()))\n\n    # 대표 검색어별로 그룹화하여 계산\n    for query, group in temp_df.groupby('representative_query'):\n        if not query:\n            continue\n\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        # 'ours' 포스트나 경쟁사 포스트가 없는 경우 건너뛰기\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        query_morphemes = ours_posts.iloc[0]['query_morpheme_set']\n        if not query_morphemes:\n            continue\n\n        # 경쟁사들의 평균 확장 형태소 개수 계산\n        competitor_expansion_counts = []\n        for _, competitor in competitor_posts.iterrows():\n            competitor_morphemes = competitor['morpheme_set']\n            # 파생/확장 형태소: 본문 형태소가 검색어 형태소로 시작하는 경우\n            expanded_morphemes = {m for m in competitor_morphemes for q in query_morphemes if m.startswith(q)}\n            competitor_expansion_counts.append(len(expanded_morphemes))\n        \n        if not competitor_expansion_counts:\n            avg_competitor_expansion = 0\n        else:\n            avg_competitor_expansion = np.mean(competitor_expansion_counts)\n\n        # 'ours' 포스트 각각에 대해 점수 계산 및 할당\n        for idx, our_post in ours_posts.iterrows():\n            our_morphemes = our_post['morpheme_set']\n            our_expanded_morphemes = {m for m in our_morphemes for q in query_morphemes if m.startswith(q)}\n            our_expansion_count = len(our_expanded_morphemes)\n\n            # 분모가 0이 되는 것을 방지 (경쟁사 확장 형태소가 0개일 경우 1로 처리)\n            denominator = avg_competitor_expansion if avg_competitor_expansion > 0 else 1\n            score = our_expansion_count / denominator\n            \n            # 원본 DataFrame의 인덱스를 사용하여 정확한 위치에 값 할당\n            df.loc[idx, feature_name] = score\n\n    return df",
  "analysis": {
    "correlation": 0.10615962754717156,
    "p_value": 0.3058753989604366,
    "interpretation": "약한 양의 상관관계(0.1062)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.3059)."
  }
}{
  "timestamp": "2025-07-22T05:49:06.782356",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'morpheme_exclusivity_score'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    각 'ours' 포스트에 대해, 동일한 'representative_query'를 가진 경쟁자 그룹과 비교하여\n    'morpheme_exclusivity_score'를 계산합니다.\n    이 점수는 우리 포스트의 형태소 중 경쟁자들이 사용하지 않은 고유한 형태소의 비율을 나타냅니다.\n\n    - 1.0: 우리 포스트의 모든 형태소가 경쟁자 포스트에는 전혀 나타나지 않음 (완전한 차별성).\n    - 0.0: 우리 포스트의 모든 형태소가 경쟁자 포스트 중 하나 이상에 이미 존재함 (차별성 없음).\n    \"\"\"\n    # 1. 입력 DataFrame이 비어 있는지 확인합니다.\n    if df.empty:\n        return df\n\n    feature_name = 'morpheme_exclusivity_score'\n    # 피처 열을 NaN으로 초기화하여 비교 대상이 없는 경우를 대비합니다.\n    df[feature_name] = np.nan\n\n    # 2. 'morpheme_words' 문자열을 집합(set)으로 변환하는 전처리 작업을 수행합니다.\n    # .apply를 사용하는 것보다 리스트 컴프리헨션이 훨씬 효율적입니다.\n    # str()로 감싸고 공백을 제거하여 NaN 값이나 비정상적인 데이터에 대한 안정성을 확보합니다.\n    df['morpheme_set'] = [\n        set(s.strip() for s in str(morphemes).split(',') if s.strip())\n        for morphemes in df['morpheme_words']\n    ]\n\n    # 계산된 결과를 저장할 딕셔너리. {인덱스: 점수} 형태로 저장하여 나중에 한 번에 할당합니다.\n    results_to_assign = {}\n\n    # 3. 'representative_query'를 기준으로 그룹화하여 각 쿼리별로 경쟁 분석을 수행합니다.\n    for query, group_df in df.groupby('representative_query'):\n        our_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitors']\n\n        # 우리 포스트가 없거나 벤치마킹할 경쟁자 포스트가 없는 그룹은 건너뜁니다.\n        if our_posts.empty or competitor_posts.empty:\n            continue\n\n        # 4. 해당 쿼리 그룹 내 모든 경쟁자 포스트의 형태소를 통합하여 하나의 거대한 집합을 만듭니다.\n        # set.union(*iterable_of_sets)는 여러 집합을 효율적으로 합치는 방법입니다.\n        competitor_morpheme_union = set().union(*competitor_posts['morpheme_set'])\n\n        # 5. 그룹 내 각 'ours' 포스트에 대해 개별적으로 점수를 계산합니다.\n        # 원본 DataFrame의 인덱스를 보존하기 위해 iterrows를 사용합니다.\n        for idx, our_post in our_posts.iterrows():\n            our_morphemes = our_post['morpheme_set']\n\n            # 우리 포스트에 형태소가 없는 경우 0으로 처리하여 0으로 나누는 오류를 방지합니다.\n            if not our_morphemes:\n                results_to_assign[idx] = 0.0\n                continue\n\n            # 우리 포스트의 형태소 집합에서 경쟁자 형태소 집합을 빼서 고유한 형태소만 남깁니다.\n            exclusive_morphemes = our_morphemes.difference(competitor_morpheme_union)\n\n            # 고유 형태소의 비율을 계산합니다.\n            score = len(exclusive_morphemes) / len(our_morphemes)\n            results_to_assign[idx] = score\n\n    # 6. 계산된 점수들을 원본 DataFrame에 .loc를 사용하여 정확한 인덱스에 일괄 할당합니다.\n    # 이 방법은 SettingWithCopyWarning을 방지하고 데이터 정합성을 보장합니다.\n    if results_to_assign:\n        df.loc[list(results_to_assign.keys()), feature_name] = list(results_to_assign.values())\n\n    # 7. 임시로 사용했던 'morpheme_set' 열을 삭제합니다.\n    df.drop(columns=['morpheme_set'], inplace=True)\n\n    # 8. 점수가 계산되지 않은 나머지 NaN 값들(경쟁자가 없었던 경우 등)을 0으로 채웁니다.\n    df[feature_name].fillna(0.0, inplace=True)\n\n    return df"
}{
  "timestamp": "2025-07-22T05:49:55.042188",
  "attempt": 2,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 대표 검색어의 핵심 형태소를 기반으로 파생된 형태소를 경쟁자 그룹보다 더 풍부하고 다양하게 사용할수록, 사용자의 탐색 의도를 더 폭넓게 만족시켜 `non_brand_average_ctr`이 높아질 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef _get_derivative_morphemes_count(morpheme_list, core_morphemes):\n    \"\"\"Helper function to count unique derivative morphemes.\"\"\"\n    if not core_morphemes or not morpheme_list:\n        return 0\n    \n    derivative_morphemes = set()\n    for m in morpheme_list:\n        for core_m in core_morphemes:\n            # A morpheme is derivative if it starts with a core morpheme but isn't identical.\n            if m.startswith(core_m) and m != core_m:\n                derivative_morphemes.add(m)\n    return len(derivative_morphemes)\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    [CTR / 핵심 형태소 구조 벤치마킹]\n    대표 검색어의 핵심 형태소로부터 파생된 고유 형태소의 수를 계산하고, \n    이를 경쟁자 그룹의 평균과 비교하여 비율을 산출합니다.\n\n    - 파생 형태소: 대표 검색어의 형태소를 포함하여 확장된 형태소 (예: '치료' -> '치료법', '치료시기')\n    - 풍부함 (Richness): 고유한 파생 형태소의 개수\n\n    이 피처는 우리 포스트가 핵심 주제를 얼마나 더 깊이 있고 다양하게 다루는지를 측정하며,\n    이는 사용자에게 더 높은 가치를 제공하여 클릭률(CTR)을 높일 수 있다는 가설에 기반합니다.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'derivative_morpheme_richness_ratio'\n    df[feature_name] = np.nan\n\n    # 1. Pre-process morpheme strings into lists of strings, handling NaNs.\n    # This prevents repeated splitting inside the loop.\n    temp_morpheme_col = df['morpheme_words'].fillna('').str.split(',')\n\n    # 2. Iterate over each unique query group.\n    # Preserving the original index is critical to avoid data misalignment.\n    for query, group_indices in df.groupby('representative_query').groups.items():\n        if not isinstance(query, str) or not query.strip():\n            continue\n\n        group_df = df.loc[group_indices]\n        core_morphemes = set(query.split()) # Use query words as core morphemes.\n\n        # 3. Separate 'ours' and 'competitor' posts within the group.\n        ours_mask = group_df['source'] == 'ours'\n        competitors_mask = group_df['source'] == 'competitor'\n        \n        our_indices = group_df[ours_mask].index\n        competitor_indices = group_df[competitors_mask].index\n\n        if our_indices.empty or competitor_indices.empty:\n            continue\n        \n        # 4. Calculate the benchmark: average derivative richness of competitors.\n        competitor_richness_scores = [\n            _get_derivative_morphemes_count(temp_morpheme_col.loc[idx], core_morphemes)\n            for idx in competitor_indices\n        ]\n        avg_competitor_richness = np.mean(competitor_richness_scores) if competitor_richness_scores else 0\n\n        # 5. Calculate and assign the feature for each 'ours' post individually.\n        # This ensures that each post gets a unique value, preventing the previous error of a constant feature value.\n        for idx in our_indices:\n            our_post_richness = _get_derivative_morphemes_count(temp_morpheme_col.loc[idx], core_morphemes)\n            \n            # Use Laplace smoothing (add 1) to prevent division by zero and stabilize the ratio.\n            ratio = (our_post_richness + 1) / (avg_competitor_richness + 1)\n            df.loc[idx, feature_name] = ratio\n            \n    return df",
  "analysis": {
    "correlation": 0.01591528373776902,
    "p_value": 0.8783358826960201,
    "interpretation": "약한 양의 상관관계(0.0159)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.8783)."
  }
}{
  "timestamp": "2025-07-22T06:07:54.941483",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'derivative_morpheme_richness_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom konlpy.tag import Okt\nimport re\n\n# 1. Lazy-load the model to avoid re-initializing it on every call.\n_okt = None\n\ndef get_okt_model():\n    \"\"\"Initializes and returns a singleton Okt model instance.\"\"\"\n    global _okt\n    if _okt is None:\n        _okt = Okt()\n    return _okt\n\ndef _calculate_richness(morpheme_str: str, core_morphemes: set) -> int:\n    \"\"\"Calculates the richness of derivative morphemes in a post.\"\"\"\n    if not isinstance(morpheme_str, str) or not morpheme_str or not core_morphemes:\n        return 0\n    \n    # Split the morpheme string into a list of morphemes\n    post_morphemes = set(m.strip() for m in morpheme_str.split(',') if m.strip())\n    \n    derivative_morphemes = set()\n    for post_morph in post_morphemes:\n        for core_morph in core_morphemes:\n            # A morpheme is derivative if it starts with a core morpheme but is longer\n            if len(post_morph) > len(core_morph) and post_morph.startswith(core_morph):\n                derivative_morphemes.add(post_morph)\n    \n    return len(derivative_morphemes)\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\" \n    Calculates the ratio of derivative morpheme richness of 'our' posts compared to \n    the average of competitor posts for the same representative query.\n    \"\"\"\n    if df.empty:\n        return df\n\n    # Ensure the new column exists with a default neutral value.\n    df['derivative_morpheme_richness_ratio'] = 1.0\n\n    try:\n        okt = get_okt_model()\n    except Exception as e:\n        # If Okt fails to initialize (e.g., Java not found), return df with default values.\n        print(f\"Error initializing Okt: {e}. Skipping feature generation.\")\n        return df\n        \n    # Filter for posts that can be benchmarked.\n    query_df = df[df['representative_query'].notna()].copy()\n\n    if query_df.empty:\n        return df\n\n    # Use a dictionary to store results before assigning to prevent SettingWithCopyWarning\n    results = {}\n\n    for query, group in query_df.groupby('representative_query'):\n        if not query or not isinstance(query, str):\n            continue\n\n        # Tokenize the query to find core morphemes.\n        # Use nouns for higher relevance, fallback to all morphs if none found.\n        core_morphemes_nouns = set(okt.nouns(query))\n        if not core_morphemes_nouns:\n            core_morphemes = set(okt.morphs(query))\n        else:\n            core_morphemes = core_morphemes_nouns\n\n        # Filter out short/common morphemes that might create noise.\n        core_morphemes = {m for m in core_morphemes if len(m) > 1}\n\n        if not core_morphemes:\n            continue\n\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitor']\n\n        if ours_posts.empty:\n            continue\n\n        avg_competitor_richness = 0.0\n        if not competitor_posts.empty:\n            competitor_richness_scores = competitor_posts['morpheme_words'].apply(\n                lambda x: _calculate_richness(x, core_morphemes)\n            )\n            if not competitor_richness_scores.empty:\n                 avg_competitor_richness = competitor_richness_scores.mean()\n\n        # Calculate richness for our posts and compute the ratio.\n        for index, row in ours_posts.iterrows():\n            our_richness = _calculate_richness(row['morpheme_words'], core_morphemes)\n            \n            # Smoothed ratio to prevent division by zero and handle 0/0 case.\n            ratio = (1 + our_richness) / (1 + avg_competitor_richness)\n            results[index] = ratio\n\n    # Safely assign the calculated values to the original DataFrame.\n    if results:\n        df['derivative_morpheme_richness_ratio'] = pd.Series(results)\n        # Fill any posts that weren't processed with the default neutral value.\n        df['derivative_morpheme_richness_ratio'].fillna(1.0, inplace=True)\n\n    return df\n"
}{
  "timestamp": "2025-07-22T06:08:47.140459",
  "attempt": 2,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 경쟁사 그룹 전체보다 대표 검색어의 핵심 형태소로부터 파생된 형태소를 더 다양하게 사용할수록, 더 깊이 있는 정보를 제공하여 사용자 만족도를 높이고 결과적으로 CTR이 향상될 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef get_core_morphemes_from_query(query_str: str) -> list:\n    \"\"\"Extracts core morphemes from a query string by splitting it.\"\"\"\n    if not isinstance(query_str, str):\n        return []\n    return query_str.split()\n\ndef find_derivative_morphemes(post_morphemes: set, core_morphemes: list) -> set:\n    \"\"\"\n    Finds derivative morphemes. A morpheme is derivative if it starts with a\n    core morpheme but is not the core morpheme itself.\n    \"\"\"\n    derivatives = set()\n    if not core_morphemes:\n        return derivatives\n        \n    for core in core_morphemes:\n        for post_morph in post_morphemes:\n            # Ensure both are strings before calling startswith\n            if isinstance(post_morph, str) and post_morph.startswith(core) and post_morph != core:\n                derivatives.add(post_morph)\n    return derivatives\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of derivative morpheme richness in 'our' posts compared to competitors.\n\n    This feature fixes a previous logical error where all generated values were identical.\n    It now calculates a unique score for each 'ours' post by comparing its individual morpheme\n    set against the aggregated set of all competitors for the same query. This ensures the\n    resulting feature has variance, making it suitable for correlation analysis.\n\n    A 'derivative morpheme' is a morpheme from the post body that contains a 'core morpheme'\n    from the representative query (e.g., '치료법' is a derivative of '치료').\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'derivative_morpheme_richness_ratio'\n    # Initialize the column with a default neutral value\n    df[feature_name] = 1.0\n\n    # Ensure 'morpheme_words' is a string before processing to prevent errors\n    df['morpheme_words'] = df['morpheme_words'].fillna('').astype(str)\n\n    grouped = df.groupby('representative_query')\n\n    for query, group in grouped:\n        if not isinstance(query, str) or not query:\n            continue\n\n        core_morphemes = get_core_morphemes_from_query(query)\n        if not core_morphemes:\n            continue\n\n        ours_df = group[group['source'] == 'ours']\n        competitors_df = group[group['source'] == 'competitor']\n\n        if competitors_df.empty or ours_df.empty:\n            continue\n\n        # 3. Create a benchmark by analyzing all competitor morphemes together\n        all_competitor_morphemes_str = ' '.join(competitors_df['morpheme_words'].str.replace(',', ''))\n        competitor_morphemes_set = set(all_competitor_morphemes_str.split())\n        \n        competitor_derivatives = find_derivative_morphemes(competitor_morphemes_set, core_morphemes)\n        competitor_derivative_count = len(competitor_derivatives)\n\n        # 4. CRITICAL FIX: Iterate over each 'ours' post to calculate a unique score\n        for index, row in ours_df.iterrows():\n            our_post_morphemes_list = row['morpheme_words'].replace(',', ' ').split()\n            our_post_morphemes_set = set(our_post_morphemes_list)\n            \n            our_derivatives = find_derivative_morphemes(our_post_morphemes_set, core_morphemes)\n            our_derivative_count = len(our_derivatives)\n\n            # Calculate a stable ratio, adding 1 to avoid division by zero\n            ratio = (our_derivative_count + 1) / (competitor_derivative_count + 1)\n            \n            # Safely assign the calculated value back to the original DataFrame using its index\n            df.loc[index, feature_name] = ratio\n\n    return df",
  "analysis": {
    "correlation": -0.02800960382304046,
    "p_value": 0.7875890940827998,
    "interpretation": "약한 음의 상관관계(-0.0280)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.7876)."
  }
}{
  "timestamp": "2025-07-22T06:28:30.970362",
  "attempt": 1,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹보다 대표 쿼리의 핵심 형태소에서 파생된 형태소를 더 다양하게 사용할수록(파생 형태소 풍부도 비율이 높을수록) 비브랜드 평균 CTR이 높을 것이다.",
  "code": "import pandas as pd\nimport numpy as np\nimport ast\n\ndef _safe_parse_list(series_val):\n    \"\"\"Safely parse a string representation of a list.\"\"\"\n    if pd.isna(series_val) or not isinstance(series_val, str):\n        return []\n    try:\n        parsed_list = ast.literal_eval(series_val)\n        if isinstance(parsed_list, list):\n            return parsed_list\n        return []\n    except (ValueError, SyntaxError):\n        return []\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of derivative morpheme richness for our posts compared to competitors.\n\n    A \"derivative morpheme\" is a morpheme from the post that contains a core word from the representative query.\n    \"Richness\" is the count of unique derivative morphemes.\n    The feature is the ratio of our post's richness to the average richness of its competitor group.\n    \"\"\"\n    feature_name = 'derivative_morpheme_richness_ratio'\n    # Initialize with a neutral value of 1.0, assuming no difference as a default.\n    df[feature_name] = 1.0\n\n    if df.empty:\n        return df\n\n    # Ensure required columns are present to avoid KeyErrors\n    required_cols = ['representative_query', 'morpheme_words', 'source']\n    if not all(col in df.columns for col in required_cols):\n        return df\n\n    # Group by the representative query to create comparison sets\n    for query, group_df in df.groupby('representative_query'):\n        if pd.isna(query):\n            continue\n\n        # Define core morphemes by splitting the query string. This is a practical heuristic.\n        core_morphemes = set(str(query).split())\n\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        # A comparison is only possible if both 'ours' and 'competitor' posts exist for the query.\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        # --- Calculate competitor benchmark: average derivative morpheme richness ---\n        competitor_richness_scores = []\n        for _, comp_row in competitor_posts.iterrows():\n            morphemes = _safe_parse_list(comp_row['morpheme_words'])\n            # Find morphemes that contain any of the core query words\n            derivative_morphemes = {\n                morph for morph in morphemes\n                if any(core in str(morph) for core in core_morphemes)\n            }\n            competitor_richness_scores.append(len(derivative_morphemes))\n        \n        avg_competitor_richness = np.mean(competitor_richness_scores) if competitor_richness_scores else 0\n\n        # To prevent division by zero, if the average richness of competitors is 0, \n        # we set the denominator to 1.0. In this case, the ratio becomes our post's own richness score.\n        denominator = avg_competitor_richness if avg_competitor_richness > 0 else 1.0\n\n        # --- Calculate and assign the feature for each of 'ours' posts ---\n        for index, our_row in ours_posts.iterrows():\n            morphemes = _safe_parse_list(our_row['morpheme_words'])\n            derivative_morphemes = {\n                morph for morph in morphemes\n                if any(core in str(morph) for core in core_morphemes)\n            }\n            our_richness = len(derivative_morphemes)\n            \n            ratio = our_richness / denominator\n            \n            # Use the original DataFrame's index (preserved by .iterrows()) to assign the value, preventing misalignment.\n            df.loc[index, feature_name] = ratio\n            \n    return df",
  "analysis": {
    "correlation": null,
    "p_value": null,
    "interpretation": "상관관계를 계산할 수 없습니다 (예: 피처의 분산이 0)."
  }
}{
  "timestamp": "2025-07-22T06:54:10.249578",
  "attempt": 1,
  "status": "success",
  "feature_name": "derivative_morpheme_richness_ratio",
  "hypothesis": "우리 포스트가 경쟁자 그룹에 비해 대표 쿼리의 핵심 형태소를 포함하는 파생/조합 형태소를 더 풍부하게(다양하게) 사용할수록, 사용자의 구체적인 검색 의도를 더 폭넓게 충족시켜 CTR이 높아질 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    대표 쿼리의 핵심 형태소를 기준으로, 'ours' 포스트와 'competitor' 포스트 그룹 간의\n    파생/조합 형태소의 다양성(richness)을 비교하여 비율을 계산합니다.\n\n    1.  각 'representative_query'를 기준으로 데이터를 그룹화합니다.\n    2.  쿼리에서 핵심 형태소(단어)를 추출합니다.\n    3.  각 포스트의 'morpheme_words'에서 핵심 형태소를 포함하는 모든 파생/조합 형태소의 **고유한 개수**를 계산합니다.\n    4.  'competitor' 그룹의 평균 고유 파생 형태소 개수를 계산합니다.\n    5.  'ours' 포스트의 고유 파생 형태소 개수를 경쟁사 평균으로 나누어 비율(ratio)을 계산합니다.\n    6.  경쟁사 평균이 0일 경우, 우리 포스트가 1개 이상이면 2.0(우위), 둘 다 0이면 1.0(동등)을 부여합니다.\n    \"\"\"\n    feature_name = 'derivative_morpheme_richness_ratio'\n\n    if df.empty:\n        df[feature_name] = pd.Series(dtype='float64')\n        return df\n\n    # Helper function to parse morpheme strings into a list of unique morphemes\n    def parse_morphemes(morpheme_string):\n        if not isinstance(morpheme_string, str) or morpheme_string.strip() == '':\n            return []\n        return [m.strip() for m in morpheme_string.split(',') if m.strip()]\n\n    # Helper function to calculate the richness of derivative morphemes\n    def get_derivative_richness(morphemes_list, core_morphemes_set):\n        if not morphemes_list or not core_morphemes_set:\n            return 0\n        \n        # Find all unique morphemes that contain any of the core morphemes\n        derivative_morphemes = {m for m in morphemes_list if any(core in m for core in core_morphemes_set)}\n        return len(derivative_morphemes)\n\n    results = {}\n    # Group by representative query to perform benchmark calculations\n    grouped = df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        if not isinstance(query, str) or not query.strip():\n            continue\n\n        # Extract core morphemes from the query itself\n        core_morphemes = set(query.split())\n\n        ours_posts = group_df[group_df['source'] == 'ours']\n        competitor_posts = group_df[group_df['source'] == 'competitor']\n\n        # Proceed only if both 'ours' and 'competitor' posts exist for the query\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        # --- Calculate Competitor Benchmark ---\n        competitor_morphemes = competitor_posts['morpheme_words'].apply(parse_morphemes)\n        competitor_richness_scores = competitor_morphemes.apply(get_derivative_richness, core_morphemes_set=core_morphemes)\n        avg_competitor_richness = competitor_richness_scores.mean()\n\n        # --- Calculate Ratio for Our Posts ---\n        our_morphemes = ours_posts['morpheme_words'].apply(parse_morphemes)\n        our_richness_scores = our_morphemes.apply(get_derivative_richness, core_morphemes_set=core_morphemes)\n        \n        # Calculate ratio with safe division to avoid ZeroDivisionError\n        if avg_competitor_richness > 0:\n            ratios = our_richness_scores / avg_competitor_richness\n        else:\n            # Handle case where competitors have no derivative morphemes\n            # If our post has derivatives, it's superior (assign 2.0).\n            # If our post also has none, it's parity (assign 1.0).\n            ratios = our_richness_scores.apply(lambda x: 2.0 if x > 0 else 1.0)\n        \n        # Store results with the original DataFrame index to ensure correct alignment\n        results.update(ratios.to_dict())\n\n    # Map the calculated results back to the original DataFrame\n    df[feature_name] = pd.Series(results)\n    \n    # Fill NaNs with a neutral value of 1.0 for posts that couldn't be benchmarked\n    df[feature_name].fillna(1.0, inplace=True)\n    \n    return df",
  "analysis": {
    "correlation": 0.013247347669693474,
    "p_value": 0.8986115995368451,
    "interpretation": "약한 양의 상관관계(0.0132)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.8986)."
  }
}{
  "timestamp": "2025-07-22T07:10:50.574588",
  "attempt": 1,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'derivative_morpheme_richness_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef _calculate_expansion_score(morphemes_str: str, core_terms: list) -> int:\n    \"\"\"\n    Calculates the number of unique morphemes that contain any of the core terms.\n    Helper function for generate_feature.\n    \"\"\"\n    if not isinstance(morphemes_str, str) or not morphemes_str:\n        return 0\n    # Use a set for unique morphemes\n    post_morphemes = set(morphemes_str.split())\n    derivative_morphemes = set()\n    for morpheme in post_morphemes:\n        for term in core_terms:\n            if term in morpheme:\n                derivative_morphemes.add(morpheme)\n                break  # Move to the next morpheme once a match is found\n    return len(derivative_morphemes)\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Generates a feature that measures the richness of derivative morphemes in our post\n    relative to the average of competitor posts for the same query. A higher ratio\n    suggests our post expands on the core topic more comprehensively than competitors.\n    \"\"\"\n    feature_name = \"derivative_morpheme_richness_ratio\"\n\n    if df.empty:\n        return df\n\n    required_cols = ['source', 'representative_query', 'morpheme_words']\n    for col in required_cols:\n        if col not in df.columns:\n            df[feature_name] = np.nan\n            return df\n\n    # Initialize the feature column to a neutral value (1.0) or NaN for unprocessed rows\n    df[feature_name] = np.nan\n\n    # Create a working copy to avoid SettingWithCopyWarning\n    df_copy = df.copy()\n    df_copy['morpheme_words'] = df_copy['morpheme_words'].fillna('')\n\n    # Filter out rows where representative_query is NaN or empty before grouping\n    valid_df = df_copy[df_copy['representative_query'].notna() & (df_copy['representative_query'] != '')]\n    grouped = valid_df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        # Get core terms from the query string\n        core_terms = query.split()\n        if not core_terms:\n            continue\n\n        # Separate 'ours' and 'competitors'\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitors']\n\n        # Skip if there are no 'ours' posts or no 'competitors' to compare against\n        if ours_df.empty or competitors_df.empty:\n            continue\n\n        # Calculate average expansion score for competitors\n        competitor_scores = competitors_df['morpheme_words'].apply(lambda x: _calculate_expansion_score(x, core_terms))\n        avg_competitor_score = competitor_scores.mean()\n\n        # Calculate score for each 'ours' post and the final ratio\n        for idx, row in ours_df.iterrows():\n            our_score = _calculate_expansion_score(row['morpheme_words'], core_terms)\n\n            # Calculate Ratio with robust division logic\n            if avg_competitor_score > 0:\n                ratio = our_score / avg_competitor_score\n            elif our_score > 0:  # Our score is positive, competitor avg is 0\n                ratio = 2.0  # Assign a high value for outperforming a zero-effort baseline\n            else:  # Both our_score and avg_competitor_score are 0\n                ratio = 1.0  # Assign a neutral value as there is no difference\n\n            # Assign the result back to the original DataFrame using the correct index\n            df.loc[idx, feature_name] = ratio\n\n    return df"
}{
  "timestamp": "2025-07-22T07:12:29.191393",
  "attempt": 2,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'core_morpheme_cohesion_vs_competitors'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport itertools\nimport re\n\ndef parse_morphemes(morpheme_str):\n    \"\"\"Helper function to parse a comma-separated string of morphemes into a set.\"\"\"\n    if pd.isna(morpheme_str) or not isinstance(morpheme_str, str):\n        return set()\n    return set(m.strip() for m in morpheme_str.split(',') if m.strip())\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the Core Morpheme Cohesion score for our posts relative to competitors.\n\n    This feature measures how densely our posts utilize the \"morpheme neighborhood\"\n    (frequently co-occurring morphemes) established by competitors for a given query.\n    The logic ensures that each 'ours' post gets a unique score based on its own content,\n    thus preventing the generation of a constant value for all rows.\n    \"\"\"\n    feature_name = 'core_morpheme_cohesion_vs_competitors'\n    \n    # Initialize with a neutral value (1.0) indicating parity with competitors.\n    df[feature_name] = 1.0\n\n    if df.empty:\n        return df\n\n    # Create a temporary copy to safely add the 'morpheme_set' column\n    temp_df = df.copy()\n    temp_df['morpheme_set'] = temp_df['morpheme_words'].apply(parse_morphemes)\n    \n    # Use a dictionary to store results, mapping original index to feature value.\n    # This prevents misalignment issues when assigning back to the DataFrame.\n    results = {}\n\n    # Group by 'representative_query' to create a specific benchmark for each query.\n    for query, group in temp_df.groupby('representative_query'):\n        if pd.isna(query):\n            continue\n\n        ours_posts = group[group['source'] == 'ours']\n        competitor_posts = group[group['source'] == 'competitors']\n\n        if ours_posts.empty or competitor_posts.empty:\n            continue\n\n        # 1. Identify core morphemes from the query itself by splitting it.\n        query_morphemes = set(re.split(r'\\s+', query.strip()))\n\n        # 2. Build the \"competitor neighborhood\" of frequently co-occurring morphemes.\n        all_competitor_morphemes = list(itertools.chain.from_iterable(competitor_posts['morpheme_set']))\n        if not all_competitor_morphemes:\n            continue\n\n        morpheme_freq = Counter(all_competitor_morphemes)\n        \n        # Exclude the query's own morphemes to focus on surrounding contextual terms.\n        for qm in query_morphemes:\n            if qm in morpheme_freq:\n                del morpheme_freq[qm]\n        \n        # Define the neighborhood as the top 20% most common morphemes (clamped to a reasonable size).\n        num_unique_morphemes = len(morpheme_freq)\n        top_n = int(num_unique_morphemes * 0.20)\n        top_n = min(max(top_n, 10), 50)\n\n        competitor_neighborhood = set([m for m, freq in morpheme_freq.most_common(top_n)])\n        \n        if not competitor_neighborhood:\n            continue\n\n        # 3. Calculate the average cohesion score for competitors.\n        competitor_scores = []\n        for _, row in competitor_posts.iterrows():\n            post_morphemes = row['morpheme_set']\n            if not post_morphemes:\n                continue\n            intersection_count = len(post_morphemes.intersection(competitor_neighborhood))\n            # Score is the density of neighborhood morphemes in the post.\n            score = intersection_count / len(post_morphemes)\n            competitor_scores.append(score)\n\n        avg_competitor_cohesion_score = np.mean(competitor_scores) if competitor_scores else 0.0\n        \n        if avg_competitor_cohesion_score == 0:\n            continue\n\n        # 4. Calculate the score for each 'ours' post and the final ratio.\n        for index, row in ours_posts.iterrows():\n            post_morphemes = row['morpheme_set']\n            if not post_morphemes:\n                # If our post has no morphemes, its score is 0.\n                our_score = 0.0\n            else:\n                intersection_count = len(post_morphemes.intersection(competitor_neighborhood))\n                our_score = intersection_count / len(post_morphemes)\n            \n            final_ratio = our_score / avg_competitor_cohesion_score\n            # Store with original index for correct assignment.\n            results[index] = final_ratio\n\n    # 5. Assign the calculated values back to the original DataFrame using the preserved indices.\n    if results:\n        feature_series = pd.Series(results)\n        df.loc[feature_series.index, feature_name] = feature_series\n        \n    df[feature_name] = df[feature_name].replace([np.inf, -np.inf], np.nan)\n    df[feature_name] = df[feature_name].fillna(1.0)\n\n    return df"
}{
  "timestamp": "2025-07-22T07:15:43.063591",
  "attempt": 3,
  "status": "logical_error",
  "error": "논리적 오류: 생성된 피처 'derivative_morpheme_richness_ratio'의 값이 모두 동일하여 상관관계를 계산할 수 없습니다. 모든 행에 대해 다른 값을 생성하도록 코드를 수정해주세요.",
  "code": "import pandas as pd\nimport numpy as np\nfrom konlpy.tag import Okt\n\n# 1. Lazy-load the morpheme analyzer to avoid re-initializing it on every call.\n_okt = None\n\ndef get_okt():\n    global _okt\n    if _okt is None:\n        # Okt may not be thread-safe depending on the environment.\n        # For this execution model, lazy-loading is sufficient.\n        _okt = Okt()\n    return _okt\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of derivative morpheme diversity in our posts compared to the competitor average for a given query.\n\n    The feature 'derivative_morpheme_richness_ratio' is created by:\n    1. Identifying core morphemes from the 'representative_query'.\n    2. For each query group, calculating the average number of unique 'derivative' \n       (non-core) morphemes used by competitors.\n    3. For each of our posts, calculating its own number of unique derivative morphemes.\n    4. Computing the ratio of our post's count to the competitor average.\n       This ensures each of our posts gets a unique value, enabling correlation analysis.\n    \"\"\"\n    feature_name = 'derivative_morpheme_richness_ratio'\n    \n    # 2. Safety check for empty DataFrame or missing required columns.\n    if df.empty or 'morpheme_words' not in df.columns or 'representative_query' not in df.columns:\n        if feature_name not in df.columns:\n            df[feature_name] = np.nan\n        return df\n\n    # Initialize the feature column with NaN.\n    df[feature_name] = np.nan\n    \n    try:\n        okt = get_okt()\n    except Exception as e:\n        # Handle cases where konlpy might not be properly installed or configured.\n        print(f\"Could not initialize Okt: {e}. Skipping feature generation.\")\n        return df\n\n    # Helper function to parse the morpheme string and count derivatives.\n    def get_derivative_count(text, core_morphemes_set):\n        if not isinstance(text, str) or not text:\n            return 0\n        # Parse comma-separated string into a clean set of morphemes.\n        morphemes = set(word.strip() for word in text.split(',') if word.strip())\n        # A derivative morpheme is one that is not in the core query set.\n        derivative_morphemes = morphemes - core_morphemes_set\n        return len(derivative_morphemes)\n\n    # 3. Group by the representative query to create a distinct benchmark for each query.\n    grouped = df.groupby('representative_query')\n\n    for query, group_df in grouped:\n        ours_df = group_df[group_df['source'] == 'ours']\n        competitors_df = group_df[group_df['source'] == 'competitor']\n\n        # Skip groups that lack either our posts or competitor posts.\n        if ours_df.empty or competitors_df.empty:\n            continue\n\n        # 4. Extract core morphemes (nouns) from the query itself.\n        core_morphemes = set()\n        if isinstance(query, str) and query:\n            try:\n                core_morphemes = set(okt.nouns(query))\n            except Exception:\n                # Handle potential errors in the tagging process for unusual queries.\n                pass\n\n        # 5. Calculate the baseline: average derivative richness of competitors.\n        competitor_derivative_counts = competitors_df['morpheme_words'].apply(\n            lambda x: get_derivative_count(x, core_morphemes)\n        )\n        \n        avg_competitor_richness = competitor_derivative_counts.mean()\n\n        # Avoid division by zero. If competitors have no derivatives, the baseline is 1.\n        if pd.isna(avg_competitor_richness) or avg_competitor_richness == 0:\n            avg_competitor_richness = 1.0\n\n        # 6. Calculate and assign the feature value for each of our posts.\n        # This loop ensures each 'ours' post gets a unique value based on its own content,\n        # preventing the feature from being constant across all rows.\n        for index, row in ours_df.iterrows():\n            our_derivative_count = get_derivative_count(row['morpheme_words'], core_morphemes)\n            \n            ratio = our_derivative_count / avg_competitor_richness\n            \n            # CRITICAL: Assign the value back to the original DataFrame using its index.\n            df.loc[index, feature_name] = ratio\n            \n    return df"
}{
  "timestamp": "2025-07-22T07:16:40.211388",
  "attempt": 4,
  "status": "success",
  "feature_name": "core_morpheme_coverage_ratio_vs_competitors",
  "hypothesis": "우리 포스트가 경쟁사 그룹의 평균보다 대표 검색어의 핵심 형태소를 더 많이 포함하고 있을수록(커버리지 비율이 높을수록), 검색 의도의 여러 측면을 충족시켜 클릭률(non_brand_average_ctr)이 높을 것이다.",
  "code": "import pandas as pd\nimport numpy as np\n\ndef get_morpheme_set(morpheme_string):\n    \"\"\"Helper function to safely convert a comma-separated string of morphemes into a set.\"\"\"\n    if not isinstance(morpheme_string, str) or morpheme_string.strip() == '':\n        return set()\n    return set(filter(None, [m.strip() for m in morpheme_string.split(',')]))\n\ndef generate_feature(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Calculates the ratio of core morpheme coverage in our post compared to the competitor average for the same query.\n    This feature has variance because each 'ours' post's coverage is calculated individually.\n\n    The logic is as follows:\n    1. For each representative_query, identify the core morphemes (by splitting the query string).\n    2. Group all posts (ours and competitors) by this query.\n    3. For each group:\n       a. Calculate the average core morpheme coverage for the competitor posts.\n          - Coverage for a single post is the count of unique core morphemes found in its 'morpheme_words'.\n       b. For each of our posts in the group:\n          - Calculate its own core morpheme coverage based on its unique content.\n          - Compute the ratio: (our_post_coverage / competitor_avg_coverage).\n    4. This per-post ratio is the new feature, ensuring variance across different 'ours' posts.\n    \"\"\"\n    if df.empty:\n        return df\n\n    feature_name = 'core_morpheme_coverage_ratio_vs_competitors'\n    df[feature_name] = np.nan\n\n    if 'morpheme_words' not in df.columns or 'representative_query' not in df.columns:\n        # Fill with neutral value if required columns are missing\n        df.loc[df['source'] == 'ours', feature_name] = 1.0\n        return df\n\n    # Group the entire dataframe by query to get access to competitors for each 'ours' post\n    grouped = df.groupby('representative_query')\n\n    # Dictionary to store the calculated feature values, keyed by the original DataFrame index\n    results = {}\n\n    for query, group_df in grouped:\n        if not isinstance(query, str) or not query.strip():\n            continue\n\n        # 1. Identify core morphemes from the query string\n        core_morphemes = set(filter(None, [m.strip() for m in query.split()]))\n        if not core_morphemes:\n            continue\n        \n        # Separate our posts from competitors within the group\n        competitors_in_group = group_df[group_df['source'] == 'competitor']\n        ours_in_group = group_df[group_df['source'] == 'ours']\n\n        # 3a. Calculate the competitor benchmark (average coverage)\n        avg_competitor_coverage = 0.0\n        if not competitors_in_group.empty:\n            competitor_coverages = []\n            for morpheme_str in competitors_in_group['morpheme_words'].dropna():\n                post_morphemes = get_morpheme_set(morpheme_str)\n                coverage = len(core_morphemes.intersection(post_morphemes))\n                competitor_coverages.append(coverage)\n            \n            if competitor_coverages:\n                avg_competitor_coverage = np.mean(competitor_coverages)\n\n        # 3b. Calculate the feature for each of our posts individually\n        if not ours_in_group.empty:\n            for idx, row in ours_in_group.iterrows():\n                our_morphemes = get_morpheme_set(row['morpheme_words'])\n                our_coverage = len(core_morphemes.intersection(our_morphemes))\n                \n                # Calculate ratio, preventing division by zero and handling edge cases\n                if avg_competitor_coverage > 0:\n                    ratio = our_coverage / avg_competitor_coverage\n                elif our_coverage > 0:\n                    # Competitors have 0 coverage, but we have some. This is superior.\n                    ratio = 2.0 \n                else:\n                    # Both our post and competitors have 0 coverage. A neutral outcome.\n                    ratio = 1.0\n                \n                results[idx] = ratio\n\n    # 4. Safely assign results back to the original DataFrame using the preserved index\n    if results:\n        feature_series = pd.Series(results, name=feature_name)\n        df.update(feature_series)\n    \n    # Fill any remaining NaNs for 'ours' posts (e.g., those with no valid query) with a neutral value\n    df.loc[(df['source'] == 'ours') & (df[feature_name].isna()), feature_name] = 1.0\n\n    return df",
  "analysis": {
    "correlation": 0.03840489554006754,
    "p_value": 0.7117509100035307,
    "interpretation": "약한 양의 상관관계(0.0384)를 발견했습니다. 하지만 통계적으로 유의미하지 않습니다(p-value: 0.7118)."
  }
}