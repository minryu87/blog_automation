#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ì›”ë³„ í†µê³„ ë°ì´í„° ìˆ˜ì§‘ ë° í†µí•© ìŠ¤í¬ë¦½íŠ¸
2025ë…„ 7ì›” 1ì¼ë¶€í„° 31ì¼ê¹Œì§€ì˜ ì¼ìë³„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í†µí•© í…Œì´ë¸” ìƒì„±
"""

import sys
import os
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from scripts.util.logger import logger
from scripts.util.config import ClientInfo, AuthConfig, get_config_manager
from scripts.crawler.naver_place_pv_stat_crawler import NaverStatCrawler
from scripts.crawler.naver_place_pv_crawler_base import ApiCallError

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MonthlyStatisticsCrawler:
    """ì›”ë³„ í†µê³„ ë°ì´í„° ìˆ˜ì§‘ ë° í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, client_info: ClientInfo, auth_config: AuthConfig):
        """
        Args:
            client_info: ì‚¬ìš©í•  í´ë¼ì´ì–¸íŠ¸ì˜ ì •ë³´
            auth_config: ì¸ì¦ ê´€ë ¨ ì„¤ì • ì •ë³´
        """
        self.client = client_info
        self.crawler = NaverStatCrawler(client_info, auth_config)
        
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ
        self.base_dir = Path(__file__).resolve().parents[2]
        self.raw_data_dir = self.base_dir / 'data' / 'raw'
        self.processed_data_dir = self.base_dir / 'data' / 'processed'
        self.raw_data_dir.mkdir(parents=True, exist_ok=True)
        self.processed_data_dir.mkdir(parents=True, exist_ok=True)

        self.column_order = [
            'date', 'year', 'month', 'day', 'day_of_week', 'data_type', 'name',
            'pv', 'total_pv', 'channel_id', 'channel_type', 'channel_category',
            'keyword', 'keyword_id', 'keyword_type', 'keyword_category'
        ]
        
        # ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥ì†Œ
        self.daily_channel_data = {}  # {date: [{channel, pv, ...}]}
        self.daily_keyword_data = {}  # {date: [{keyword, pv, ...}]}
        self.daily_total_pv = {}      # {date: total_pv}
    
    def collect_monthly_data(self, year: int, month: int):
        """ì§€ì •ëœ ë…„ì›”ì˜ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info(f"ğŸš€ {year}ë…„ {month}ì›” ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        # ì›”ì˜ ì‹œì‘ì¼ê³¼ ë§ˆì§€ë§‰ì¼ ê³„ì‚°
        start_date = datetime(year, month, 1)
        if month == 12:
            end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
        else:
            end_date = datetime(year, month + 1, 1) - timedelta(days=1)
        
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')
        
        logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date_str} ~ {end_date_str}")
        
        # ì¼ìë³„ ë°ì´í„° ìˆ˜ì§‘
        current_date = start_date
        while current_date <= end_date:
            date_str = current_date.strftime('%Y-%m-%d')
            logger.info(f"ğŸ“Š {date_str} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            try:
                # ì±„ë„ë³„ ë°ì´í„° ìˆ˜ì§‘
                channel_data = self.crawler.fetch_channel_data_for_date(date_str)
                self.daily_channel_data[date_str] = channel_data
                
                # í‚¤ì›Œë“œë³„ ë°ì´í„° ìˆ˜ì§‘
                keyword_data = self.crawler.fetch_keyword_data_for_date(date_str)
                self.daily_keyword_data[date_str] = keyword_data
                
                # ì¼ìë³„ ì´ PV ê³„ì‚° (ëª¨ë“  ì±„ë„ì˜ PV í•©ê³„)
                total_pv = sum(item.get('pv', 0) for item in channel_data)
                self.daily_total_pv[date_str] = total_pv
                
                logger.info(f"âœ… {date_str} ì™„ë£Œ - ì±„ë„: {len(channel_data)}ê°œ, í‚¤ì›Œë“œ: {len(keyword_data)}ê°œ, ì´ PV: {total_pv}")
                
            except Exception as e:
                logger.error(f"âŒ {date_str} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                # ë¹ˆ ë°ì´í„°ë¡œ ì„¤ì •
                self.daily_channel_data[date_str] = []
                self.daily_keyword_data[date_str] = []
                self.daily_total_pv[date_str] = 0
            
            current_date += timedelta(days=1)
        
        logger.info(f"ğŸ‰ {year}ë…„ {month}ì›” ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ë§ˆì§€ë§‰ì— ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
        return {
            "channel_data": self.daily_channel_data,
            "keyword_data": self.daily_keyword_data,
            "total_pv": self.daily_total_pv,
        }

    def save_raw_data(self, collected_data: Dict, year: int, month: int, client_name: str):
        """ìˆ˜ì§‘í•œ ì›ë³¸ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        logger.info("ğŸ’¾ ì›ë³¸ ë°ì´í„° ì €ì¥ ì¤‘...")
        month_str = f"{month:02d}"

        data_to_save = {
            "channel_data": collected_data["channel_data"],
            "keyword_data": collected_data["keyword_data"],
            "total_pv": collected_data["total_pv"],
        }

        saved_files = []
        for data_type, data in data_to_save.items():
            file_path = self.raw_data_dir / f"{client_name}_{data_type}_{year}_{month_str}.json"
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    import json
                    json.dump(data, f, ensure_ascii=False, indent=4, default=str)
                saved_files.append(str(file_path))
            except (IOError, TypeError) as e:
                logger.error(f"âŒ {file_path} ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        
        if saved_files:
            logger.info(f"âœ… ì›ë³¸ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {', '.join(saved_files)}")

    def create_integrated_table(self, collected_data: Dict[str, Dict]) -> pd.DataFrame:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í†µí•© í…Œì´ë¸” ìƒì„±"""
        logger.info("ğŸ“Š í†µí•© í…Œì´ë¸” ìƒì„± ì¤‘...")

        all_rows = []
        # total_pvì— ìˆëŠ” ëª¨ë“  ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°˜ë³µ
        all_dates = sorted(collected_data.get('total_pv', {}).keys())

        for date_str in all_dates:
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
            total_pv = collected_data.get('total_pv', {}).get(date_str, 0)
            
            base_row = {
                'date': date_str,
                'year': date_obj.year,
                'month': date_obj.month,
                'day': date_obj.day,
                'day_of_week': date_obj.strftime('%A'),
                'total_pv': total_pv
            }
            
            # ì±„ë„ ë°ì´í„° ì²˜ë¦¬
            channel_items = collected_data.get('channel_data', {}).get(date_str, [])
            if channel_items:
                for item in channel_items:
                    row = base_row.copy()
                    row.update({'data_type': 'channel', 'name': item.get('mapped_channel_name'), 'pv': item.get('pv')})
                    # API ì‘ë‹µì˜ ë‹¤ë¥¸ ëª¨ë“  í‚¤ë„ ì¶”ê°€
                    row.update(item)
                    all_rows.append(row)
            
            # í‚¤ì›Œë“œ ë°ì´í„° ì²˜ë¦¬
            keyword_items = collected_data.get('keyword_data', {}).get(date_str, [])
            if keyword_items:
                for item in keyword_items:
                    row = base_row.copy()
                    row.update({'data_type': 'keyword', 'name': item.get('ref_keyword'), 'pv': item.get('pv')})
                    # API ì‘ë‹µì˜ ë‹¤ë¥¸ ëª¨ë“  í‚¤ë„ ì¶”ê°€
                    row.update(item)
                    all_rows.append(row)
            
            # í•´ë‹¹ ë‚ ì§œì— ì±„ë„/í‚¤ì›Œë“œ ë°ì´í„°ê°€ ëª¨ë‘ ì—†ëŠ” ê²½ìš°
            if not channel_items and not keyword_items:
                row = base_row.copy()
                row.update({'data_type': 'summary_only', 'name': None, 'pv': 0})
                all_rows.append(row)

        if not all_rows:
            logger.warning("í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df = pd.DataFrame(all_rows)
        
        # ëª¨ë“  ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì¶”ê°€
        for col in self.column_order:
            if col not in df.columns:
                df[col] = None
        
        logger.info(f"âœ… í†µí•© í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {len(df)}í–‰")
        return df[self.column_order] # ì •ì˜ëœ ìˆœì„œë¡œ ì»¬ëŸ¼ ì •ë ¬
    
    def save_processed_data(self, df: pd.DataFrame, year: int, month: int, client_name: str):
        """ê°€ê³µëœ í†µí•© ë°ì´í„°ë¥¼ CSV ë° Excel íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        logger.info("ğŸ’¾ ê°€ê³µ ë°ì´í„° ì €ì¥ ì¤‘...")
        month_str = f"{month:02d}"

        # CSV ì €ì¥
        csv_file = self.processed_data_dir / f"{client_name}_{year}_{month_str}_integrated_statistics.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')

        # Excel ì €ì¥
        excel_file = self.processed_data_dir / f"{client_name}_{year}_{month_str}_daily_summary.xlsx"
        try:
            self._create_daily_summary_excel(df, excel_file, client_name, year, month)
            logger.info(f"âœ… ê°€ê³µ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {csv_file}, {excel_file}")
        except Exception as e:
            logger.error(f"âŒ Excel íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
    
    def _create_daily_summary_excel(self, df: pd.DataFrame, excel_file: Path, client_name: str, year: int, month: int):
        """ì¼ìë³„ ìš”ì•½ ì—‘ì…€ íŒŒì¼ ìƒì„±"""
        logger.info("ğŸ“Š ì¼ìë³„ ìš”ì•½ ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘...")
        
        # ë‚ ì§œë³„ ë°ì´í„° ê·¸ë£¹í™”
        daily_summary = []
        
        for date_str in sorted(df['date'].unique()):
            date_data = df[df['date'] == date_str]
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
            
            # ê¸°ë³¸ í–‰ ë°ì´í„°
            row = {
                'ë‚ ì§œ': date_str,
                'ë…„': date_obj.year,
                'ì›”': date_obj.month,
                'ì¼': date_obj.day,
                'ìš”ì¼': date_obj.strftime('%A'),
                'í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„': date_data['total_pv'].iloc[0]  # ëª¨ë“  í–‰ì´ ë™ì¼í•œ ê°’
            }
            
            # ì±„ë„ë³„ ë°ì´í„° ì¶”ê°€
            channel_data = date_data[date_data['data_type'] == 'channel']
            for _, channel_row in channel_data.iterrows():
                channel_name = channel_row['name']
                pv = channel_row['pv']
                row[f'ì±„ë„_{channel_name}'] = pv
            
            # í‚¤ì›Œë“œë³„ ë°ì´í„° ì¶”ê°€
            keyword_data = date_data[date_data['data_type'] == 'keyword']
            for _, keyword_row in keyword_data.iterrows():
                keyword_name = keyword_row['name']
                pv = keyword_row['pv']
                row[f'í‚¤ì›Œë“œ_{keyword_name}'] = pv
            
            daily_summary.append(row)
        
        # DataFrame ìƒì„±
        summary_df = pd.DataFrame(daily_summary)
        
        # ì±„ë„ë³„ ì´ PV ê³„ì‚°í•˜ì—¬ ì •ë ¬
        channel_columns = [col for col in summary_df.columns if col.startswith('ì±„ë„_')]
        channel_totals = {}
        for col in channel_columns:
            channel_name = col.replace('ì±„ë„_', '')
            total_pv = summary_df[col].sum()
            channel_totals[col] = total_pv
        
        # ì±„ë„ ì»¬ëŸ¼ì„ ì´ PV ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        sorted_channel_columns = sorted(channel_columns, key=lambda x: channel_totals[x], reverse=True)
        
        # í‚¤ì›Œë“œë³„ ì´ PV ê³„ì‚°í•˜ì—¬ ì •ë ¬
        keyword_columns = [col for col in summary_df.columns if col.startswith('í‚¤ì›Œë“œ_')]
        keyword_totals = {}
        for col in keyword_columns:
            keyword_name = col.replace('í‚¤ì›Œë“œ_', '')
            total_pv = summary_df[col].sum()
            keyword_totals[col] = total_pv
        
        # í‚¤ì›Œë“œ ì»¬ëŸ¼ì„ ì´ PV ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        sorted_keyword_columns = sorted(keyword_columns, key=lambda x: keyword_totals[x], reverse=True)
        
        # ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        all_columns = ['ë‚ ì§œ', 'ë…„', 'ì›”', 'ì¼', 'ìš”ì¼', 'í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„']
        all_columns.extend(sorted_channel_columns)
        all_columns.extend(sorted_keyword_columns)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        summary_df = summary_df[all_columns]
        
        # ì—‘ì…€ íŒŒì¼ ì €ì¥
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            # ì¼ìë³„ ìš”ì•½ ì‹œíŠ¸
            summary_df.to_excel(writer, sheet_name='ì¼ìë³„ ìš”ì•½', index=False)
            
            # í†µê³„ ìš”ì•½ ì‹œíŠ¸
            self._create_statistics_sheet(writer, summary_df, client_name, year, month)
            
            # ì±„ë„ë³„ í†µê³„ ì‹œíŠ¸
            self._create_channel_statistics_sheet(writer, summary_df, year, month)
            
            # í‚¤ì›Œë“œë³„ í†µê³„ ì‹œíŠ¸
            self._create_keyword_statistics_sheet(writer, summary_df, year, month)
        
        logger.info(f"âœ… ì—‘ì…€ íŒŒì¼ ìƒì„± ì™„ë£Œ: {excel_file}")
        logger.info(f"  - ì´ {len(summary_df)}ì¼ ë°ì´í„°")
        logger.info(f"  - ì±„ë„ ìˆ˜: {len(sorted_channel_columns)}ê°œ")
        logger.info(f"  - í‚¤ì›Œë“œ ìˆ˜: {len(sorted_keyword_columns)}ê°œ")
        
        # ìƒìœ„ ì±„ë„ê³¼ í‚¤ì›Œë“œ ì •ë³´ ì¶œë ¥
        top_channels = [(col.replace('ì±„ë„_', ''), channel_totals[col]) for col in sorted_channel_columns[:5]]
        top_keywords = [(col.replace('í‚¤ì›Œë“œ_', ''), keyword_totals[col]) for col in sorted_keyword_columns[:5]]
        
        logger.info(f"  - ìƒìœ„ 5ê°œ ì±„ë„: {[f'{name}({pv:.0f})' for name, pv in top_channels]}")
        logger.info(f"  - ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ: {[f'{name}({pv:.0f})' for name, pv in top_keywords]}")
    
    def _create_statistics_sheet(self, writer, summary_df: pd.DataFrame, client_name: str, year: int, month: int):
        """í†µê³„ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        stats_data = []
        
        # ê¸°ë³¸ í†µê³„
        total_pv = summary_df['í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„'].sum()
        avg_daily_pv = summary_df['í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„'].mean()
        max_daily_pv = summary_df['í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„'].max()
        min_daily_pv = summary_df['í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„'].min()
        
        stats_data.append([f'{client_name} {year}ë…„ {month}ì›” í†µê³„ ìš”ì•½', ''])
        stats_data.append(['', ''])
        stats_data.append(['ê¸°ë³¸ í†µê³„', ''])
        stats_data.append(['ì´ PV', f"{total_pv:,.0f}"])
        stats_data.append(['ì¼í‰ê·  PV', f"{avg_daily_pv:.1f}"])
        stats_data.append(['ìµœëŒ€ ì¼ PV', f"{max_daily_pv:,.0f}"])
        stats_data.append(['ìµœì†Œ ì¼ PV', f"{min_daily_pv:,.0f}"])
        stats_data.append(['', ''])
        
        # ìƒìœ„ 10ì¼
        top_days = summary_df.nlargest(10, 'í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„')[['ë‚ ì§œ', 'ìš”ì¼', 'í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„']]
        stats_data.append(['ìƒìœ„ 10ì¼ (PV ê¸°ì¤€)', ''])
        stats_data.append(['ë‚ ì§œ', 'ìš”ì¼', 'ì´ PV'])
        for _, row in top_days.iterrows():
            stats_data.append([row['ë‚ ì§œ'], row['ìš”ì¼'], f"{row['í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ í•©ê³„']:,.0f}"])
        
        stats_df = pd.DataFrame(stats_data)
        stats_df.to_excel(writer, sheet_name='í†µê³„ ìš”ì•½', index=False, header=False)
    
    def _create_channel_statistics_sheet(self, writer, summary_df: pd.DataFrame, year: int, month: int):
        """ì±„ë„ë³„ í†µê³„ ì‹œíŠ¸ ìƒì„±"""
        channel_columns = [col for col in summary_df.columns if col.startswith('ì±„ë„_')]
        
        if not channel_columns:
            return
        
        channel_stats = []
        for col in channel_columns:
            channel_name = col.replace('ì±„ë„_', '')
            total_pv = summary_df[col].sum()
            avg_pv = summary_df[col].mean()
            max_pv = summary_df[col].max()
            days_with_data = (summary_df[col] > 0).sum()
            
            channel_stats.append({
                'ì±„ë„ëª…': channel_name,
                'ì´ PV': total_pv,
                'ì¼í‰ê·  PV': avg_pv,
                'ìµœëŒ€ ì¼ PV': max_pv,
                'ë°ì´í„° ìˆëŠ” ì¼ìˆ˜': days_with_data
            })
        
        channel_stats_df = pd.DataFrame(channel_stats)
        channel_stats_df = channel_stats_df.sort_values('ì´ PV', ascending=False)
        channel_stats_df.to_excel(writer, sheet_name='ì±„ë„ë³„ í†µê³„', index=False)
    
    def _create_keyword_statistics_sheet(self, writer, summary_df: pd.DataFrame, year: int, month: int):
        """í‚¤ì›Œë“œë³„ í†µê³„ ì‹œíŠ¸ ìƒì„±"""
        keyword_columns = [col for col in summary_df.columns if col.startswith('í‚¤ì›Œë“œ_')]
        
        if not keyword_columns:
            return
        
        keyword_stats = []
        for col in keyword_columns:
            keyword_name = col.replace('í‚¤ì›Œë“œ_', '')
            total_pv = summary_df[col].sum()
            avg_pv = summary_df[col].mean()
            max_pv = summary_df[col].max()
            days_with_data = (summary_df[col] > 0).sum()
            
            keyword_stats.append({
                'í‚¤ì›Œë“œëª…': keyword_name,
                'ì´ PV': total_pv,
                'ì¼í‰ê·  PV': avg_pv,
                'ìµœëŒ€ ì¼ PV': max_pv,
                'ë°ì´í„° ìˆëŠ” ì¼ìˆ˜': days_with_data
            })
        
        keyword_stats_df = pd.DataFrame(keyword_stats)
        keyword_stats_df = keyword_stats_df.sort_values('ì´ PV', ascending=False)
        keyword_stats_df.to_excel(writer, sheet_name='í‚¤ì›Œë“œë³„ í†µê³„', index=False)
    
    def run_monthly_analysis(self, year: int, month: int, client_name: str):
        """ì›”ë³„ ë¶„ì„ ì‹¤í–‰"""
        try:
            logger.info(f"ğŸš€ {year}ë…„ {month}ì›” í”Œë ˆì´ìŠ¤ PV í†µê³„ ë¶„ì„ ì‹œì‘")
            
            # 1. ë°ì´í„° ìˆ˜ì§‘
            collected_data = self.collect_monthly_data(year, month)
            if not collected_data.get("total_pv"):
                logger.warning(f"{year}ë…„ {month}ì›” ìˆ˜ì§‘ëœ í”Œë ˆì´ìŠ¤ PV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # 2. ì›ë³¸ ë°ì´í„° ì €ì¥
            self.save_raw_data(collected_data, year, month, client_name)
            
            # 3. í†µí•© í…Œì´ë¸” ìƒì„±
            df = self.create_integrated_table(collected_data)
            if df.empty:
                logger.warning(f"{year}ë…„ {month}ì›” ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ê°€ê³µ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return

            # 4. ê°€ê³µ ë°ì´í„° ì €ì¥
            self.save_processed_data(df, year, month, client_name)
            
            logger.info(f"ğŸ‰ {year}ë…„ {month}ì›” ë¶„ì„ ì™„ë£Œ!")

        except ApiCallError as e:
            logger.error(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ {year}ë…„ {month}ì›” ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {e}")
            logger.error("   .env íŒŒì¼ì˜ AUTH_TOKENê³¼ COOKIE ê°’ì„ ìµœì‹ ìœ¼ë¡œ ê°±ì‹ í•´ì£¼ì„¸ìš”.")
            # sys.exit(1) # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨
            raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ìƒìœ„ í˜¸ì¶œì(run_crawler.py)ê°€ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        except Exception as e:
            logger.error(f"âŒ {year}ë…„ {month}ì›” ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)


def main_test():
    """ìŠ¤í¬ë¦½íŠ¸ ê°œë³„ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜"""
    config_manager = get_config_manager()
    client = config_manager.get_selected_client_config()
    if not client:
        print("âŒ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    auth_config = config_manager.get_auth_config()
    
    crawler = MonthlyStatisticsCrawler(client, auth_config)
    crawler.run_monthly_analysis(2024, 9, client.name)

if __name__ == "__main__":
    # ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì´ì œ run_crawler.pyë¥¼ í†µí•´ ì‹¤í–‰ë˜ëŠ” ê²ƒì´ ê¸°ë³¸ì…ë‹ˆë‹¤.
    # ë‹¨ë…ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì„ ê²½ìš° ì•„ë˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.
    # main_test()
    print("ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¨ë… ì‹¤í–‰ìš©ì´ ì•„ë‹™ë‹ˆë‹¤. scripts/run_crawler.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
