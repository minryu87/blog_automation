import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path
import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[3]
sys.path.append(str(project_root))

from blog_automation.place_stat_crawler.scripts.util.logger import logger

class PerformanceAnalyzer:
    def __init__(self, client_name: str, start_year: int, start_month: int, end_year: int, end_month: int):
        self.client_name = client_name
        self.start_year = start_year
        self.start_month = start_month
        self.end_year = end_year
        self.end_month = end_month
        self.base_path = Path(__file__).resolve().parents[2]
        self.processed_data_path = self.base_path / 'data' / 'processed'
        self.analysis_results_path = self.base_path / 'analysis_results' / client_name
        self.analysis_results_path.mkdir(parents=True, exist_ok=True)
        
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = 'AppleGothic'
        plt.rcParams['axes.unicode_minus'] = False


    def load_data(self) -> pd.DataFrame:
        """ì§€ì •ëœ ê¸°ê°„ì˜ í”Œë ˆì´ìŠ¤ PV ë° ì˜ˆì•½ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë³‘í•©í•©ë‹ˆë‹¤."""
        logger.info("ë°ì´í„° ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        all_place_pv_df = []
        all_booking_df = []

        for year in range(self.start_year, self.end_year + 1):
            s_month = self.start_month if year == self.start_year else 1
            e_month = self.end_month if year == self.end_year else 12

            for month in range(s_month, e_month + 1):
                month_str = f"{month:02d}"
                
                # í”Œë ˆì´ìŠ¤ PV ë°ì´í„° ë¡œë“œ
                pv_file = self.processed_data_path / f"{self.client_name}_{year}_{month_str}_integrated_statistics.csv"
                if pv_file.exists():
                    logger.info(f"ë¡œë”© (PV): {pv_file.name}")
                    all_place_pv_df.append(pd.read_csv(pv_file))
                else:
                    logger.warning(f"íŒŒì¼ ì—†ìŒ (PV): {pv_file.name}")

                # ì˜ˆì•½ ë°ì´í„° ë¡œë“œ
                booking_file = self.processed_data_path / f"{self.client_name}_{year}_{month_str}_booking_integrated_statistics.csv"
                if booking_file.exists():
                    logger.info(f"ë¡œë”© (Booking): {booking_file.name}")
                    all_booking_df.append(pd.read_csv(booking_file))
                else:
                    logger.warning(f"íŒŒì¼ ì—†ìŒ (Booking): {booking_file.name}")

        if not all_place_pv_df or not all_booking_df:
            raise FileNotFoundError("ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„° íŒŒì¼ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        place_pv_df = pd.concat(all_place_pv_df, ignore_index=True)
        booking_df = pd.concat(all_booking_df, ignore_index=True)

        # ë‚ ì§œ íƒ€ì… ë³€í™˜
        place_pv_df['date'] = pd.to_datetime(place_pv_df['date'])
        booking_df['date'] = pd.to_datetime(booking_df['date'])

        # ì¼ë³„ ì´ í”Œë ˆì´ìŠ¤ ì¡°íšŒìˆ˜ ì§‘ê³„
        daily_total_pv = place_pv_df.groupby('date')['total_count'].sum().reset_index()
        daily_total_pv.rename(columns={'total_count': 'total_place_pv'}, inplace=True)

        # ì˜ˆì•½ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        booking_summary_df = booking_df.groupby('date')[['page_visits', 'booking_requests']].first().reset_index()
        
        # ë°ì´í„° ë³‘í•©
        merged_df = pd.merge(daily_total_pv, booking_summary_df, on='date', how='inner')
        logger.info("ë°ì´í„° ë³‘í•© ì™„ë£Œ. ìµœì¢… ë°ì´í„°í”„ë ˆì„ Shape: %s", merged_df.shape)
        
        # í‚¤ì›Œë“œ ë°ì´í„° ì¶”ê°€
        keyword_df = self.extract_keyword_data(place_pv_df)
        merged_df = pd.merge(merged_df, keyword_df, on='date', how='left').fillna(0)
        
        return merged_df

    def extract_keyword_data(self, place_pv_df: pd.DataFrame) -> pd.DataFrame:
        """í”Œë ˆì´ìŠ¤ PV ë°ì´í„°ì—ì„œ ë¸Œëœë“œ/ë…¼ë¸Œëœë“œ í‚¤ì›Œë“œ PVë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        keyword_df = place_pv_df[place_pv_df['data_type'] == 'keyword'].copy()
        
        # ë¸Œëœë“œ í‚¤ì›Œë“œ ì‹ë³„ (ë³‘ì› ì´ë¦„ì˜ ì¼ë¶€ê°€ í¬í•¨ëœ ê²½ìš°)
        # client_nameì—ì„œ ì˜ì–´ ì œì™¸í•˜ê³  í•œê¸€ë§Œ ì¶”ì¶œí•˜ì—¬ ë¸Œëœë“œ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        brand_name = ''.join(filter(str.isalpha, self.client_name.replace("GOODMORNINGHANIGURO", "ì¢‹ì€ì•„ì¹¨í•œì˜ì›êµ¬ë¡œ")))
        
        brand_keywords = [brand_name]
        # 'ì¢‹ì€ì•„ì¹¨í•œì˜ì›' ê³¼ ê°™ì´ client_nameì˜ ì¼ë¶€ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°ë„ ë¸Œëœë“œ í‚¤ì›Œë“œë¡œ ê°„ì£¼
        if "í•œì˜ì›" in brand_name:
            brand_keywords.append(brand_name.replace("í•œì˜ì›", ""))

        keyword_df['is_brand'] = keyword_df['keyword'].apply(lambda x: any(brand in str(x) for brand in brand_keywords))
        
        brand_pv = keyword_df[keyword_df['is_brand']].groupby('date')['total_count'].sum()
        non_brand_pv = keyword_df[~keyword_df['is_brand']].groupby('date')['total_count'].sum()
        
        keyword_summary = pd.DataFrame({
            'brand_keyword_pv': brand_pv,
            'non_brand_keyword_pv': non_brand_pv
        }).reset_index()

        return keyword_summary

    def analyze_correlation(self, df: pd.DataFrame):
        """ì£¼ìš” ì§€í‘œ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        logger.info("ìƒê´€ê´€ê³„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        metrics = ['total_place_pv', 'page_visits', 'booking_requests', 'brand_keyword_pv', 'non_brand_keyword_pv']
        corr_matrix = df[metrics].corr()

        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('ì£¼ìš” ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ')
        
        save_path = self.analysis_results_path / 'correlation_heatmap.png'
        plt.savefig(save_path)
        plt.close()
        
        logger.info(f"ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì €ì¥ ì™„ë£Œ: {save_path}")
        logger.info("\nìƒê´€ê³„ìˆ˜ í–‰ë ¬:\n%s", corr_matrix)

    def analyze_conversion_rate(self, df: pd.DataFrame):
        """ë‹¨ê³„ë³„ ì „í™˜ìœ¨ì„ ì‹œê³„ì—´ë¡œ ë¶„ì„í•˜ê³  ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        logger.info("ì „í™˜ìœ¨ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        df['cvr_place_to_booking_page'] = (df['page_visits'] / df['total_place_pv']).replace([np.inf, -np.inf], 0) * 100
        df['cvr_booking_page_to_request'] = (df['booking_requests'] / df['page_visits']).replace([np.inf, -np.inf], 0) * 100
        
        df.set_index('date', inplace=True)
        
        plt.figure(figsize=(15, 10))
        
        plt.subplot(2, 1, 1)
        df['cvr_place_to_booking_page'].plot(title='ì „í™˜ìœ¨: í”Œë ˆì´ìŠ¤ ì¡°íšŒ â†’ ì˜ˆì•½ í˜ì´ì§€ ìœ ì… (%)')
        plt.grid(True)
        
        plt.subplot(2, 1, 2)
        df['cvr_booking_page_to_request'].plot(title='ì „í™˜ìœ¨: ì˜ˆì•½ í˜ì´ì§€ ìœ ì… â†’ ì˜ˆì•½ ì‹ ì²­ (%)', color='orange')
        plt.grid(True)
        
        plt.tight_layout()
        save_path = self.analysis_results_path / 'conversion_rate_timeseries.png'
        plt.savefig(save_path)
        plt.close()
        
        logger.info(f"ì „í™˜ìœ¨ ì‹œê³„ì—´ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")
        logger.info("\nì›”ë³„ í‰ê·  ì „í™˜ìœ¨:\n%s", df[['cvr_place_to_booking_page', 'cvr_booking_page_to_request']].resample('M').mean())


    def analyze_keyword_impact(self, df: pd.DataFrame):
        """ë¸Œëœë“œ/ë…¼ë¸Œëœë“œ í‚¤ì›Œë“œ ìœ ì…ê³¼ ì˜ˆì•½ ì‹ ì²­ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        logger.info("í‚¤ì›Œë“œ ì˜í–¥ë ¥ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        plt.figure(figsize=(15, 12))

        # 1. ë¸Œëœë“œ/ë…¼ë¸Œëœë“œ í‚¤ì›Œë“œ PV ì‹œê³„ì—´
        plt.subplot(3, 1, 1)
        df[['brand_keyword_pv', 'non_brand_keyword_pv']].plot(ax=plt.gca(), title='ì¼ë³„ ë¸Œëœë“œ/ë…¼ë¸Œëœë“œ í‚¤ì›Œë“œ PV')
        plt.grid(True)

        # 2. ë¸Œëœë“œ í‚¤ì›Œë“œ PVì™€ ì˜ˆì•½ ì‹ ì²­ ìˆ˜
        plt.subplot(3, 1, 2)
        sns.regplot(x='brand_keyword_pv', y='booking_requests', data=df, scatter_kws={'alpha':0.3})
        plt.title('ë¸Œëœë“œ í‚¤ì›Œë“œ PVì™€ ì˜ˆì•½ ì‹ ì²­ ìˆ˜ì˜ ê´€ê³„')
        plt.grid(True)

        # 3. ë…¼ë¸Œëœë“œ í‚¤ì›Œë“œ PVì™€ ì˜ˆì•½ ì‹ ì²­ ìˆ˜
        plt.subplot(3, 1, 3)
        sns.regplot(x='non_brand_keyword_pv', y='booking_requests', data=df, scatter_kws={'alpha':0.3}, color='g')
        plt.title('ë…¼ë¸Œëœë“œ í‚¤ì›Œë“œ PVì™€ ì˜ˆì•½ ì‹ ì²­ ìˆ˜ì˜ ê´€ê³„')
        plt.grid(True)

        plt.tight_layout()
        save_path = self.analysis_results_path / 'keyword_impact_analysis.png'
        plt.savefig(save_path)
        plt.close()
        logger.info(f"í‚¤ì›Œë“œ ì˜í–¥ë ¥ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")

    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            merged_df = self.load_data()
            self.analyze_correlation(merged_df.copy())
            self.analyze_conversion_rate(merged_df.copy())
            self.analyze_keyword_impact(merged_df.set_index('date').copy())
            logger.info("ğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except FileNotFoundError as e:
            logger.error(e)
        except Exception as e:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)


if __name__ == '__main__':
    # ë¶„ì„í•  í´ë¼ì´ì–¸íŠ¸ì™€ ê¸°ê°„ ì„¤ì •
    analyzer = PerformanceAnalyzer(
        client_name='GOODMORNINGHANIGURO',
        start_year=2024,
        start_month=7,
        end_year=2025,
        end_month=7
    )
    analyzer.run_analysis()
