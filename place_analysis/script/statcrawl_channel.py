#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ ì±„ë„ë³„ PV ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
2025ë…„ 7ì›” í•œ ë‹¬ê°„ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í…Œì´ë¸”ë¡œ ì €ì¥
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
import json
import time
import os
from typing import Dict, List, Any

class NaverSmartPlaceCollector:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.base_url = "https://new.smartplace.naver.com/proxy/bizadvisor/api/v3/sites/sp_311b9ba993e974/report"
        
        # Authorization í—¤ë”
        self.auth_token = """Bearer slEQJHjSWy8/nh/Eeb+JT+sPFvVIbXGt1vgnCzgibRCQ1nbI99oQvX+4866WDnWohN6XEnKnxjcx5Gqlw08W80XrCTBzIkyQaYn39Yw/4DFGm00iJI5aj9TXvlacwUE+h8Q28V6gCtEjFULG5gieGkoNLtk6h87/O1pvOSstE2PQ6R5Hze8kPYn4FmIUJSP+73Me4z0RYWuzw1kCDaaQKnkqBrVdSMwj2X33q8J3MJe+Tnoxda2OezO0dy+fl/vDznV68RulT/sGcJhzxCOmVqEnjAHkp3x00s/fCubLG5oRPtXNtEjziiGwzQo9tPgWrX0LLk0nEbuNU0isIh6Y2RDBjsIRGEnE87LAoqKJ3Lw="""
        
        # Cookie
        self.cookie = """NNB=ZKHGWSJXM6SGO; NSCS=1; ASID=01dcd28c00000194f85124240000004f; NAC=LjaaBowe2zA0A; JSESSIONID=5260E43AD131D5D717A845CBEB327C63; nid_inf=1760525603; NID_AUT=GUytzV9XzHD04v3E4zcypSLif601MbzHbOIWXMj3Zr6vk6eVVOYrcNGnNWDjKdLf; page_uid=j5divlqo15VssTyVvJCssssstEZ-057330; csrf_token=39773df8ad4251958c25719ac5c7f46c06d86b2e5d22c5709ab225d8d9bf73ffde594d7935800c2cdac78bd95e33e66ee0facc523dca0cd7f0b414b1b4a07836; NACT=1; SRT30=1754554830; BUC=1H_paitS7sce4fyPW6Npbe9whz05C7MDpTHGgoVT1nQ=; NID_SES=AAABjEsr8/1iTsnCC3nrV3NJLx+w71fwztrvXYTekr0kjxb+Q42Wg2zR9BQS/UibrD35TRVc3dEmICRVD2lTnFv7bz/EGHFDmUqnPw/zTdNs57Asicu25U4ONiUGEWPA2eJHsdYvECiLDdchVDEt7Myzcr4Wjv51olROiCuxqiBrhhDwUU6rmkAw3maLUnX333S5ZyYcitpxGb0OSCcYugpihV0TJZVev41ttPEt10NCDfvxPWqkPfTflQZ/hLKmbcrVQExv457vsR9nn5io3X5SlLEj/ZBHIi/fV43SoZjoKUg/RVOoKyVCC1Qt+4EUSommRVtw84prIIHj0VseyB3O4lVVaZHUlxUe/wdQ5qcOVUtf2WAhyCqVqnfs3r9fo2RwC+yt3pLxvWbN4bCrFOdPu4ImQEtaEk7KQJl+3DXoNy5vUgAHBSgGbCGOQ51H2vWMJmaOX5TmwwWPUjEQwy2Kf73GSPMi3hjgIyNHK7960XqdpMIpsh+2rv2GMhShlVBuc3G/VH2/lNEfKmILtP/K9Tk=; ba_access_token=slEQJHjSWy8%2Fnh%2FEeb%2BJT%2BsPFvVIbXGt1vgnCzgibRCQ1nbI99oQvX%2B4866WDnWohN6XEnKnxjcx5Gqlw08W80XrCTBzIkyQaYn39Yw%2F4DFGm00iJI5aj9TXvlacwUE%2Bh8Q28V6gCtEjFULG5gieGkoNLtk6h87%2FO1pvOSstE2PQ6R5Hze8kPYn4FmIUJSP%2B73Me4z0RYWuzw1kCDaaQKnkqBrVdSMwj2X33q8J3MJe%2BTnoxda2OezO0dy%2Bfl%2FvDznV68RulT%2FsGcJhzxCOmVqEnjAHkp3x00s%2FfCubLG5oRPtXNtEjziiGwzQo9tPgWrX0LLk0nEbuNU0isIh6Y2RDBjsIRGEnE87LAoqKJ3Lw%3D"""
        
        self.headers = {
            'Authorization': self.auth_token,
            'Cookie': self.cookie,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': 'https://new.smartplace.naver.com/'
        }
        
        self.all_data = {}
        self.channels = set()

    def fetch_data_for_date(self, date: str) -> List[Dict]:
        """íŠ¹ì • ë‚ ì§œì˜ ì±„ë„ë³„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸°"""
        params = {
            'dimensions': 'mapped_channel_name',  # ì±„ë„ë³„ë¡œ ê·¸ë£¹í™”
            'startDate': date,
            'endDate': date,
            'metrics': 'pv',
            'sort': 'pv',
            'useIndex': 'revenue-all-channel-detail'  # ì „ì²´ ì±„ë„ ìƒì„¸
        }
        
        try:
            print(f"ğŸ“Š {date} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", end=' ')
            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # ìˆ˜ì§‘ëœ ì±„ë„ ëª©ë¡ í‘œì‹œ
                channels_found = [item['mapped_channel_name'] for item in data if 'mapped_channel_name' in item]
                print(f"âœ… {len(data)}ê°œ ì±„ë„ ({', '.join(channels_found[:3])}{'...' if len(channels_found) > 3 else ''})")
                
                # ì²« ë‚ ì§œì˜ ë°ì´í„° êµ¬ì¡° í™•ì¸
                if date == '2025-07-01' and data:
                    print(f"\nğŸ“Œ ë°ì´í„° êµ¬ì¡° í™•ì¸:")
                    for i, item in enumerate(data, 1):
                        print(f"   {i}. {json.dumps(item, ensure_ascii=False)}")
                    print()
                
                return data
            else:
                print(f"âš ï¸ HTTP {response.status_code} ì—ëŸ¬")
                return []
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ - {str(e)}")
            return []
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì—ëŸ¬ - {str(e)}")
            return []

    def collect_all_data(self):
        """2025ë…„ 7ì›” ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""
        print("=" * 60)
        print("ğŸš€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ ì±„ë„ë³„ PV ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print("ğŸ“… ê¸°ê°„: 2025ë…„ 7ì›” 1ì¼ ~ 31ì¼")
        print("=" * 60)
        
        start_date = datetime(2025, 7, 1)
        end_date = datetime(2025, 7, 31)
        
        # ë¨¼ì € ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
        current_date = start_date
        while current_date <= end_date:
            date_str = current_date.strftime('%Y-%m-%d')
            
            # API í˜¸ì¶œ
            data = self.fetch_data_for_date(date_str)
            
            # ë°ì´í„° ì €ì¥
            self.all_data[date_str] = data
            
            # ë‹¤ìŒ ë‚ ì§œë¡œ
            current_date += timedelta(days=1)
            
            # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
            time.sleep(0.5)
        
        # ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ í›„ ì „ì²´ ì±„ë„ ëª©ë¡ íŒŒì•…
        print("\nğŸ“Š ì „ì²´ ì±„ë„ ëª©ë¡ íŒŒì•… ì¤‘...")
        channel_appearances = {}  # ì±„ë„ë³„ ì¶œí˜„ íšŸìˆ˜
        
        for date_str, data_list in self.all_data.items():
            for item in data_list:
                if 'mapped_channel_name' in item and item['mapped_channel_name']:
                    channel_name = item['mapped_channel_name']
                    self.channels.add(channel_name)
                    
                    # ì±„ë„ë³„ ì¶œí˜„ íšŸìˆ˜ ì¹´ìš´íŠ¸
                    if channel_name not in channel_appearances:
                        channel_appearances[channel_name] = 0
                    channel_appearances[channel_name] += 1
        
        print(f"\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ {len(self.channels)}ê°œ ì±„ë„ ë°œê²¬:")
        
        # ì¶œí˜„ ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¶œë ¥
        sorted_channels = sorted(channel_appearances.items(), key=lambda x: x[1], reverse=True)
        for channel, count in sorted_channels:
            print(f"   - {channel}: {count}ì¼ ì¶œí˜„")

    def create_dataframe(self) -> pd.DataFrame:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.all_data:
            print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ì±„ë„ ëª©ë¡ì´ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ì‹œ ìŠ¤ìº”
        if not self.channels:
            print("\nğŸ”„ ì±„ë„ ì •ë³´ ì¬ìŠ¤ìº” ì¤‘...")
            for date_str, data_list in self.all_data.items():
                for item in data_list:
                    if 'mapped_channel_name' in item and item['mapped_channel_name']:
                        self.channels.add(item['mapped_channel_name'])
            print(f"   ì¬ìŠ¤ìº” ì™„ë£Œ: {len(self.channels)}ê°œ ì±„ë„ ë°œê²¬")
        
        if not self.channels:
            print("âš ï¸ ì±„ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì²« ë²ˆì§¸ ë‚ ì§œì˜ ë°ì´í„° êµ¬ì¡° ì¶œë ¥
            first_date = sorted(self.all_data.keys())[0] if self.all_data else None
            if first_date and self.all_data[first_date]:
                print(f"\nğŸ” {first_date} ë°ì´í„° ìƒ˜í”Œ:")
                for item in self.all_data[first_date][:3]:
                    print(f"   {json.dumps(item, ensure_ascii=False)}")
            return pd.DataFrame()
        
        # ë‚ ì§œë³„ë¡œ ì •ë ¬
        sorted_dates = sorted(self.all_data.keys())
        
        # DataFrame ìƒì„±
        print(f"\nğŸ“Š ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘... (ë‚ ì§œ: {len(sorted_dates)}ì¼, ì±„ë„: {len(self.channels)}ê°œ)")
        data_for_df = []
        
        for date in sorted_dates:
            row = {'ë‚ ì§œ': date}
            
            # ê° ì±„ë„ë³„ PV ê°’ ì„¤ì •
            for channel in self.channels:
                # í•´ë‹¹ ë‚ ì§œì˜ ì±„ë„ ë°ì´í„° ì°¾ê¸°
                channel_data = None
                for item in self.all_data[date]:
                    if item.get('mapped_channel_name') == channel:
                        channel_data = item
                        break
                
                # PV ê°’ ì¶”ì¶œ (float í˜•íƒœë¡œ ì €ì¥ëœ ê²½ìš° ì²˜ë¦¬)
                if channel_data:
                    pv_value = channel_data.get('pv', 0)
                    # floatì¸ ê²½ìš° ì •ìˆ˜ë¡œ ë³€í™˜
                    row[channel] = int(pv_value) if isinstance(pv_value, float) else pv_value
                else:
                    row[channel] = 0
            
            data_for_df.append(row)
        
        df = pd.DataFrame(data_for_df)
        
        # ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        df.set_index('ë‚ ì§œ', inplace=True)
        
        # ì±„ë„ì„ PV ì´í•© ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        channel_totals = df.sum().sort_values(ascending=False)
        df = df[channel_totals.index]
        
        print(f"   ìƒì„± ì™„ë£Œ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
        
        return df

    def calculate_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """í†µê³„ ìš”ì•½ ê³„ì‚°"""
        if df.empty:
            return pd.DataFrame()
        
        stats = pd.DataFrame({
            'ì´í•©': df.sum(),
            'ì¼í‰ê· ': df.mean().round(1),
            'ìµœëŒ€': df.max(),
            'ìµœì†Œ': df.min(),
            'í‘œì¤€í¸ì°¨': df.std().round(1)
        })
        
        # PV ì´í•© ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        stats = stats.sort_values('ì´í•©', ascending=False)
        
        return stats.T

    def save_to_files(self, df: pd.DataFrame, stats: pd.DataFrame):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # CSV íŒŒì¼ ì €ì¥
        csv_filename = f'channel_pv_data_2025_07_{timestamp}.csv'
        df.to_csv(csv_filename, encoding='utf-8-sig')
        print(f"\nğŸ“ CSV íŒŒì¼ ì €ì¥: {csv_filename}")
        
        # Excel íŒŒì¼ ì €ì¥
        try:
            excel_filename = f'channel_pv_data_2025_07_{timestamp}.xlsx'
            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='ì¼ë³„ ë°ì´í„°')
                stats.to_excel(writer, sheet_name='í†µê³„ ìš”ì•½')
                
                # ì›”ê°„ íŠ¸ë Œë“œ ì°¨íŠ¸ìš© ë°ì´í„° ì¶”ê°€
                monthly_trend = df.T
                monthly_trend.to_excel(writer, sheet_name='ì±„ë„ë³„ íŠ¸ë Œë“œ')
                
            print(f"ğŸ“ Excel íŒŒì¼ ì €ì¥: {excel_filename}")
        except ImportError:
            print("âš ï¸ Excel ì €ì¥ì„ ìœ„í•´ openpyxl ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openpyxl")
        except Exception as e:
            print(f"âš ï¸ Excel ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f'channel_pv_raw_data_2025_07_{timestamp}.json'
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(self.all_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ JSON ì›ë³¸ ë°ì´í„° ì €ì¥: {json_filename}")

    def display_results(self, df: pd.DataFrame, stats: pd.DataFrame):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š 2025ë…„ 7ì›” ì±„ë„ë³„ PV ë°ì´í„°")
        print("=" * 80)
        
        # DataFrame ì¶œë ¥ ì„¤ì •
        pd.set_option('display.max_rows', None)
        pd.set_option('display.max_columns', 10)
        pd.set_option('display.width', 1000)
        pd.set_option('display.max_colwidth', 20)
        pd.set_option('display.float_format', lambda x: '%.0f' % x)
        
        # ì²˜ìŒê³¼ ë§ˆì§€ë§‰ ì¼ë¶€ë§Œ ì¶œë ¥
        if len(df) > 15:
            print("\n[ì²˜ìŒ 7ì¼]")
            print(df.head(7))
            print("\n   ... ì¤‘ê°„ ìƒëµ ...\n")
            print("[ë§ˆì§€ë§‰ 7ì¼]")
            print(df.tail(7))
        else:
            print(df)
        
        print("\n" + "=" * 80)
        print("ğŸ“ˆ ì±„ë„ë³„ í†µê³„ ìš”ì•½")
        print("=" * 80)
        print(stats)
        
        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
        print("\n" + "=" * 80)
        print("ğŸ¯ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
        print("=" * 80)
        
        # ì´ PV í•©ê³„
        total_pv = df.sum().sum()
        print(f"ğŸ“ ì „ì²´ PV ì´í•©: {total_pv:,.0f}")
        
        # ì¼í‰ê·  PV
        daily_avg = total_pv / len(df)
        print(f"ğŸ“ ì¼í‰ê·  ì „ì²´ PV: {daily_avg:,.1f}")
        
        # ê°€ì¥ ë†’ì€ PV ì±„ë„
        if not df.empty and len(df.columns) > 0:
            best_channel = df.sum().idxmax()
            best_channel_pv = df.sum().max()
            best_channel_pct = (best_channel_pv / total_pv * 100)
            print(f"ğŸ“ ìµœê³  ì„±ê³¼ ì±„ë„: {best_channel} ({best_channel_pv:,.0f} PV, {best_channel_pct:.1f}%)")
            
            # ìƒìœ„ 3ê°œ ì±„ë„
            top3 = df.sum().nlargest(3)
            print(f"\nğŸ“ TOP 3 ì±„ë„:")
            for i, (channel, pv) in enumerate(top3.items(), 1):
                pct = (pv / total_pv * 100)
                print(f"   {i}. {channel}: {pv:,.0f} PV ({pct:.1f}%)")
        
        # ê°€ì¥ PVê°€ ë†’ì•˜ë˜ ë‚ 
        daily_totals = df.sum(axis=1)
        best_day = daily_totals.idxmax()
        best_day_pv = daily_totals.max()
        print(f"\nğŸ“ ìµœê³  PV ë‚ ì§œ: {best_day} ({best_day_pv:,.0f} PV)")
        
        # ê°€ì¥ PVê°€ ë‚®ì•˜ë˜ ë‚ 
        worst_day = daily_totals.idxmin()
        worst_day_pv = daily_totals.min()
        print(f"ğŸ“ ìµœì € PV ë‚ ì§œ: {worst_day} ({worst_day_pv:,.0f} PV)")

    def create_visual_report(self, df: pd.DataFrame):
        """ì‹œê°ì  ë¦¬í¬íŠ¸ ìƒì„± (ì„ íƒì‚¬í•­)"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.font_manager as fm
            
            # í•œê¸€ í°íŠ¸ ì„¤ì •
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
            
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('2025ë…„ 7ì›” ì±„ë„ë³„ PV ë¶„ì„ ë¦¬í¬íŠ¸', fontsize=16)
            
            # 1. ì¼ë³„ ì „ì²´ PV ì¶”ì´
            daily_totals = df.sum(axis=1)
            axes[0, 0].plot(range(len(daily_totals)), daily_totals.values, marker='o')
            axes[0, 0].set_title('ì¼ë³„ ì „ì²´ PV ì¶”ì´')
            axes[0, 0].set_xlabel('ë‚ ì§œ')
            axes[0, 0].set_ylabel('PV')
            axes[0, 0].grid(True, alpha=0.3)
            
            # 2. ì±„ë„ë³„ ì´ PV (íŒŒì´ ì°¨íŠ¸)
            channel_totals = df.sum().sort_values(ascending=False)
            axes[0, 1].pie(channel_totals.values, labels=channel_totals.index, autopct='%1.1f%%')
            axes[0, 1].set_title('ì±„ë„ë³„ PV ë¹„ì¤‘')
            
            # 3. ì±„ë„ë³„ ì¼ë³„ ì¶”ì´ (ìƒìœ„ 4ê°œ)
            top_channels = df.sum().nlargest(4).index
            for channel in top_channels:
                axes[1, 0].plot(range(len(df)), df[channel].values, marker='o', label=channel, alpha=0.7)
            axes[1, 0].set_title('ì£¼ìš” ì±„ë„ ì¼ë³„ ì¶”ì´')
            axes[1, 0].set_xlabel('ë‚ ì§œ')
            axes[1, 0].set_ylabel('PV')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
            
            # 4. ì±„ë„ë³„ í‰ê·  PV (ë§‰ëŒ€ ê·¸ë˜í”„)
            channel_means = df.mean().sort_values(ascending=False)
            axes[1, 1].bar(range(len(channel_means)), channel_means.values)
            axes[1, 1].set_xticks(range(len(channel_means)))
            axes[1, 1].set_xticklabels(channel_means.index, rotation=45, ha='right')
            axes[1, 1].set_title('ì±„ë„ë³„ ì¼í‰ê·  PV')
            axes[1, 1].set_ylabel('í‰ê·  PV')
            
            plt.tight_layout()
            
            # íŒŒì¼ë¡œ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            chart_filename = f'channel_pv_chart_2025_07_{timestamp}.png'
            plt.savefig(chart_filename, dpi=100, bbox_inches='tight')
            print(f"\nğŸ“ ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥: {chart_filename}")
            
            plt.close()
            
        except ImportError:
            print("\nğŸ’¡ ì°¨íŠ¸ ìƒì„±ì„ ì›í•˜ì‹œë©´ matplotlib ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install matplotlib")
        except Exception as e:
            print(f"\nâš ï¸ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        # 1. ë°ì´í„° ìˆ˜ì§‘
        self.collect_all_data()
        
        # 2. DataFrame ìƒì„±
        df = self.create_dataframe()
        
        if df.empty:
            print("\nâŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
            
            # ì›ë³¸ ë°ì´í„°ëŠ” ì €ì¥
            if self.all_data:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                json_filename = f'channel_pv_raw_data_2025_07_{timestamp}.json'
                with open(json_filename, 'w', encoding='utf-8') as f:
                    json.dump(self.all_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ“ ì›ë³¸ JSON ë°ì´í„°ëŠ” ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {json_filename}")
            return
        
        # 3. í†µê³„ ê³„ì‚°
        stats = self.calculate_statistics(df)
        
        # 4. ê²°ê³¼ ì¶œë ¥
        self.display_results(df, stats)
        
        # 5. íŒŒì¼ ì €ì¥
        self.save_to_files(df, stats)
        
        # 6. ì‹œê°ì  ë¦¬í¬íŠ¸ ìƒì„± (ì„ íƒì‚¬í•­)
        self.create_visual_report(df)
        
        print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ ì±„ë„ë³„ PV ë°ì´í„° ìˆ˜ì§‘ê¸°        â•‘
â•‘                    Version 2.0                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸
    try:
        import requests
        import pandas as pd
    except ImportError as e:
        print("âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("pip install requests pandas openpyxl")
        print("\nì°¨íŠ¸ ìƒì„±ì„ ì›í•˜ì‹œë©´ ì¶”ê°€ë¡œ:")
        print("pip install matplotlib")
        return
    
    # ìˆ˜ì§‘ê¸° ì‹¤í–‰
    collector = NaverSmartPlaceCollector()
    
    # ì‚¬ìš©ì í™•ì¸
    print("í˜„ì¬ ì„¤ì •ëœ ì¸ì¦ ì •ë³´ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print("(ìƒˆë¡œìš´ í† í°ì´ ìˆë‹¤ë©´ ì½”ë“œì˜ auth_tokenê³¼ cookieë¥¼ ìˆ˜ì • í›„ ì‹¤í–‰í•˜ì„¸ìš”)")
    response = input("\nì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    
    if response.lower() == 'y':
        collector.run()
    else:
        print("ğŸ›‘ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()