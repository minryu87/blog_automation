#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ ì±„ë„ë³„ PV ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
2025ë…„ 7ì›” í•œ ë‹¬ê°„ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í…Œì´ë¸”ë¡œ ì €ì¥
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
import json
import time
import os
from typing import Dict, List, Any

class NaverSmartPlaceCollector:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.base_url = "https://new.smartplace.naver.com/proxy/bizadvisor/api/v3/sites/sp_311b9ba993e974/report"
        
        # Authorization í—¤ë”
        self.auth_token = """Bearer slEQJHjSWy8/nh/Eeb+JT+sPFvVIbXGt1vgnCzgibRCQ1nbI99oQvX+4866WDnWohN6XEnKnxjcx5Gqlw08W80XrCTBzIkyQaYn39Yw/4DFGm00iJI5aj9TXvlacwUE+h8Q28V6gCtEjFULG5gieGkoNLtk6h87/O1pvOSstE2PQ6R5Hze8kPYn4FmIUJSP+73Me4z0RYWuzw1kCDaaQKnkqBrVdSMwj2X33q8J3MJe+Tnoxda2OezO0dy+fl/vDznV68RulT/sGcJhzxCOmVqEnjAHkp3x00s/fCubLG5oRPtXNtEjziiGwzQo9tPgWrX0LLk0nEbuNU0isIh6Y2RDBjsIRGEnE87LAoqKJ3Lw="""
        
        # Cookie
        self.cookie = """NNB=ZKHGWSJXM6SGO; NSCS=1; ASID=01dcd28c00000194f85124240000004f; NAC=LjaaBowe2zA0A; JSESSIONID=5260E43AD131D5D717A845CBEB327C63; nid_inf=1760525603; NID_AUT=GUytzV9XzHD04v3E4zcypSLif601MbzHbOIWXMj3Zr6vk6eVVOYrcNGnNWDjKdLf; page_uid=j5divlqo15VssTyVvJCssssstEZ-057330; csrf_token=39773df8ad4251958c25719ac5c7f46c06d86b2e5d22c5709ab225d8d9bf73ffde594d7935800c2cdac78bd95e33e66ee0facc523dca0cd7f0b414b1b4a07836; NACT=1; SRT30=1754554830; BUC=1H_paitS7sce4fyPW6Npbe9whz05C7MDpTHGgoVT1nQ=; NID_SES=AAABjEsr8/1iTsnCC3nrV3NJLx+w71fwztrvXYTekr0kjxb+Q42Wg2zR9BQS/UibrD35TRVc3dEmICRVD2lTnFv7bz/EGHFDmUqnPw/zTdNs57Asicu25U4ONiUGEWPA2eJHsdYvECiLDdchVDEt7Myzcr4Wjv51olROiCuxqiBrhhDwUU6rmkAw3maLUnX333S5ZyYcitpxGb0OSCcYugpihV0TJZVev41ttPEt10NCDfvxPWqkPfTflQZ/hLKmbcrVQExv457vsR9nn5io3X5SlLEj/ZBHIi/fV43SoZjoKUg/RVOoKyVCC1Qt+4EUSommRVtw84prIIHj0VseyB3O4lVVaZHUlxUe/wdQ5qcOVUtf2WAhyCqVqnfs3r9fo2RwC+yt3pLxvWbN4bCrFOdPu4ImQEtaEk7KQJl+3DXoNy5vUgAHBSgGbCGOQ51H2vWMJmaOX5TmwwWPUjEQwy2Kf73GSPMi3hjgIyNHK7960XqdpMIpsh+2rv2GMhShlVBuc3G/VH2/lNEfKmILtP/K9Tk=; ba_access_token=slEQJHjSWy8%2Fnh%2FEeb%2BJT%2BsPFvVIbXGt1vgnCzgibRCQ1nbI99oQvX%2B4866WDnWohN6XEnKnxjcx5Gqlw08W80XrCTBzIkyQaYn39Yw%2F4DFGm00iJI5aj9TXvlacwUE%2Bh8Q28V6gCtEjFULG5gieGkoNLtk6h87%2FO1pvOSstE2PQ6R5Hze8kPYn4FmIUJSP%2B73Me4z0RYWuzw1kCDaaQKnkqBrVdSMwj2X33q8J3MJe%2BTnoxda2OezO0dy%2Bfl%2FvDznV68RulT%2FsGcJhzxCOmVqEnjAHkp3x00s%2FfCubLG5oRPtXNtEjziiGwzQo9tPgWrX0LLk0nEbuNU0isIh6Y2RDBjsIRGEnE87LAoqKJ3Lw%3D"""
        
        self.headers = {
            'Authorization': self.auth_token,
            'Cookie': self.cookie,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': 'https://new.smartplace.naver.com/'
        }
        
        self.all_data = {}
        self.channels = set()

    def fetch_data_for_date(self, date: str) -> List[Dict]:
        """íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸°"""
        params = {
            'dimensions': 'ref_keyword',
            'startDate': date,
            'endDate': date,
            'metrics': 'pv',
            'sort': 'pv',
            'useIndex': 'revenue-search-channel-detail'
        }
        
        try:
            print(f"ğŸ“Š {date} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            response = requests.get(
                self.base_url,
                params=params,
                headers=self.headers,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… {date}: {len(data)}ê°œ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                return data
            else:
                print(f"âš ï¸ {date}: HTTP {response.status_code} ì—ëŸ¬")
                return []
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ {date}: ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ - {str(e)}")
            return []
        except json.JSONDecodeError:
            print(f"âŒ {date}: JSON íŒŒì‹± ì—ëŸ¬")
            return []

    def collect_all_data(self):
        """2025ë…„ 7ì›” ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""
        print("=" * 60)
        print("ğŸš€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print("ğŸ“… ê¸°ê°„: 2025ë…„ 7ì›” 1ì¼ ~ 31ì¼")
        print("=" * 60)
        
        start_date = datetime(2025, 7, 1)
        end_date = datetime(2025, 7, 31)
        
        current_date = start_date
        while current_date <= end_date:
            date_str = current_date.strftime('%Y-%m-%d')
            
            # API í˜¸ì¶œ
            data = self.fetch_data_for_date(date_str)
            
            # ë°ì´í„° ì €ì¥
            self.all_data[date_str] = data
            
            # ì±„ë„ ì´ë¦„ ìˆ˜ì§‘
            for item in data:
                if 'mapped_channel_name' in item:
                    self.channels.add(item['mapped_channel_name'])
            
            # ë‹¤ìŒ ë‚ ì§œë¡œ
            current_date += timedelta(days=1)
            
            # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
            time.sleep(0.5)
        
        print("\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ {len(self.channels)}ê°œ ì±„ë„ ë°œê²¬")

    def create_dataframe(self) -> pd.DataFrame:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.all_data:
            print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ë‚ ì§œë³„ë¡œ ì •ë ¬
        sorted_dates = sorted(self.all_data.keys())
        
        # DataFrame ìƒì„±
        data_for_df = []
        
        for date in sorted_dates:
            row = {'ë‚ ì§œ': date}
            
            # ê° ì±„ë„ë³„ PV ê°’ ì„¤ì •
            for channel in self.channels:
                # í•´ë‹¹ ë‚ ì§œì˜ ì±„ë„ ë°ì´í„° ì°¾ê¸°
                channel_data = next(
                    (item for item in self.all_data[date] 
                     if item.get('mapped_channel_name') == channel),
                    None
                )
                row[channel] = channel_data['pv'] if channel_data else 0
            
            data_for_df.append(row)
        
        df = pd.DataFrame(data_for_df)
        
        # ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        df.set_index('ë‚ ì§œ', inplace=True)
        
        return df

    def calculate_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """í†µê³„ ìš”ì•½ ê³„ì‚°"""
        if df.empty:
            return pd.DataFrame()
        
        stats = pd.DataFrame({
            'ì´í•©': df.sum(),
            'í‰ê· ': df.mean().round(1),
            'ìµœëŒ€': df.max(),
            'ìµœì†Œ': df.min(),
            'í‘œì¤€í¸ì°¨': df.std().round(1)
        })
        
        return stats.T

    def save_to_files(self, df: pd.DataFrame, stats: pd.DataFrame):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # CSV íŒŒì¼ ì €ì¥
        csv_filename = f'channel_pv_data_2025_07_{timestamp}.csv'
        df.to_csv(csv_filename, encoding='utf-8-sig')
        print(f"\nğŸ“ CSV íŒŒì¼ ì €ì¥: {csv_filename}")
        
        # Excel íŒŒì¼ ì €ì¥ (pandas ë²„ì „ì— ë”°ë¼ openpyxl í•„ìš”í•  ìˆ˜ ìˆìŒ)
        try:
            excel_filename = f'channel_pv_data_2025_07_{timestamp}.xlsx'
            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='ì¼ë³„ ë°ì´í„°')
                stats.to_excel(writer, sheet_name='í†µê³„ ìš”ì•½')
            print(f"ğŸ“ Excel íŒŒì¼ ì €ì¥: {excel_filename}")
        except ImportError:
            print("âš ï¸ Excel ì €ì¥ì„ ìœ„í•´ openpyxl ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openpyxl")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f'channel_pv_raw_data_2025_07_{timestamp}.json'
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(self.all_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ JSON ì›ë³¸ ë°ì´í„° ì €ì¥: {json_filename}")

    def display_results(self, df: pd.DataFrame, stats: pd.DataFrame):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š 2025ë…„ 7ì›” ì±„ë„ë³„ PV ë°ì´í„°")
        print("=" * 60)
        
        # DataFrame ì¶œë ¥ ì„¤ì •
        pd.set_option('display.max_rows', None)
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        pd.set_option('display.max_colwidth', None)
        
        print(df)
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ì±„ë„ë³„ í†µê³„ ìš”ì•½")
        print("=" * 60)
        print(stats)
        
        # ì´ PV í•©ê³„
        total_pv = df.sum().sum()
        print(f"\nğŸ¯ ì „ì²´ PV ì´í•©: {total_pv:,.0f}")
        
        # ê°€ì¥ ë†’ì€ PV ì±„ë„
        if not df.empty:
            best_channel = df.sum().idxmax()
            best_channel_pv = df.sum().max()
            print(f"ğŸ† ìµœê³  ì„±ê³¼ ì±„ë„: {best_channel} ({best_channel_pv:,.0f} PV)")

    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        # 1. ë°ì´í„° ìˆ˜ì§‘
        self.collect_all_data()
        
        # 2. DataFrame ìƒì„±
        df = self.create_dataframe()
        
        if df.empty:
            print("âŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
            return
        
        # 3. í†µê³„ ê³„ì‚°
        stats = self.calculate_statistics(df)
        
        # 4. ê²°ê³¼ ì¶œë ¥
        self.display_results(df, stats)
        
        # 5. íŒŒì¼ ì €ì¥
        self.save_to_files(df, stats)
        
        print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸í”Œë ˆì´ìŠ¤ ì±„ë„ë³„ PV ë°ì´í„° ìˆ˜ì§‘ê¸°        â•‘
â•‘                    Version 1.0                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸
    try:
        import requests
        import pandas as pd
    except ImportError as e:
        print("âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("pip install requests pandas openpyxl")
        return
    
    # ìˆ˜ì§‘ê¸° ì‹¤í–‰
    collector = NaverSmartPlaceCollector()
    
    # ì‚¬ìš©ì í™•ì¸
    print("í˜„ì¬ ì„¤ì •ëœ ì¸ì¦ ì •ë³´ë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print("(ìƒˆë¡œìš´ í† í°ì´ ìˆë‹¤ë©´ ì½”ë“œì˜ auth_tokenê³¼ cookieë¥¼ ìˆ˜ì • í›„ ì‹¤í–‰í•˜ì„¸ìš”)")
    response = input("\nì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    
    if response.lower() == 'y':
        collector.run()
    else:
        print("ğŸ›‘ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()